{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n",
    "# https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path as syspath\n",
    "from os import path as ospath\n",
    "syspath.append(ospath.join(ospath.expanduser(\"~\"), os.path.abspath(os.getcwd())+'SB3_f'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from SB3_f.sb3f import DQN\n",
    "from SB3_f.sb3f.common.vec_env import DummyVecEnv\n",
    "from SB3_f.sb3f.common.evaluation import evaluate_policy\n",
    "from SB3_f.sb3f.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "from SB3_f.sb3f.common.atari_wrappers import AtariWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"Pong-v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/gym/envs/atari/environment.py:267: UserWarning: \u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-21.0\n",
      "Episode:2 Score:-20.0\n",
      "Episode:3 Score:-21.0\n",
      "Episode:4 Score:-20.0\n",
      "Episode:5 Score:-21.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train an RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training','Logs Opt Atari','Pong')\n",
    "#training_log_path = os.path.join(log_path, 'DQN_Pong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = AtariWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=20, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=stop_callback, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=save_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# Pong Reward of -1 or +1 so Opt is +1\n",
    "opt_val = 1\n",
    "\n",
    "model_pong = DQN('CnnPolicy', env, opt_val, verbose = 1,\n",
    "            buffer_size = 100000,\n",
    "            learning_rate = 0.0001, \n",
    "            batch_size = 32,\n",
    "            learning_starts = 100000,\n",
    "            target_update_interval = 1000,\n",
    "            train_freq = 4,\n",
    "            gradient_steps =  1,\n",
    "            exploration_fraction = 0.1,\n",
    "            exploration_final_eps = 0.01,\n",
    "            optimize_memory_usage = False,\n",
    "            tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 16:25:37.276158: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs Opt Atari/Pong/Pong_Opt_10x0.1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hashemi/Freetime/Freetime-DQN/Deep-Freetime/SB3_f/sb3f/common/callbacks.py:388: UserWarning: Training and eval env are not of the same type<sb3f.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f7ca26e2ac0> != <sb3f.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f7ca8399640>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 294      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 239      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 1174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 291      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 2325     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 484      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 3550     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 551      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 4764     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 599      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 5931     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 643      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 7176     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 294      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 673      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 8246     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 703      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 9457     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hashemi/Freetime/Freetime-DQN/Deep-Freetime/SB3_f/sb3f/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=-20.80 +/- 0.40\n",
      "Episode length: 253.80 +/- 11.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 254      |\n",
      "|    mean_reward      | -20.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 482      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 10653    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 295      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 507      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 11798    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 295      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 531      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 12991    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 553      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 14188    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 573      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 15423    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 593      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 16736    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 609      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 17929    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 625      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 19160    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-20.80 +/- 0.40\n",
      "Episode length: 254.60 +/- 6.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 255      |\n",
      "|    mean_reward      | -20.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 603      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 20304    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 616      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 21544    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 628      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 22633    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 639      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 23775    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 649      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 24866    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 660      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 26117    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 669      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 27267    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 679      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 28477    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 687      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 29674    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-20.80 +/- 0.40\n",
      "Episode length: 245.80 +/- 12.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 246      |\n",
      "|    mean_reward      | -20.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 668      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 30835    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 675      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 31924    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 295      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 683      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 33056    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 295      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 690      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 34275    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 295      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 35476    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 295      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 705      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 36711    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.963    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 711      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 37836    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 39043    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-20.20 +/- 1.60\n",
      "Episode length: 238.40 +/- 21.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 238      |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 701      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 40356    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 41585    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 713      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 42737    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 718      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 43929    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 724      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 45218    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 728      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 46335    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 733      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 47493    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 295      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 738      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 48665    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 742      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 49901    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-19.20 +/- 3.12\n",
      "Episode length: 235.60 +/- 40.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 236      |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 728      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 51228    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 733      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 52422    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 737      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 53545    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 740      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 54615    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 744      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 55749    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 297      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 748      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 56973    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 296      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 751      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 58104    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 755      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 59430    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-20.60 +/- 0.80\n",
      "Episode length: 244.20 +/- 13.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 244      |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 742      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 60651    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 746      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 61830    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 749      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 63031    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 753      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 64299    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 756      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 65488    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 759      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 66671    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 763      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 67881    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 766      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 69022    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-20.60 +/- 0.80\n",
      "Episode length: 241.40 +/- 10.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 241      |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 754      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 70286    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 757      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 71472    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 760      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 72622    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 762      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 73764    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 765      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 75029    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 768      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 76262    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 771      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 77444    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 774      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 78626    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 776      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 79786    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=80000, episode_reward=-17.80 +/- 6.40\n",
      "Episode length: 212.00 +/- 78.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 212      |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 767      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 81223    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 770      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 82392    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 772      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 83594    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 301      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 774      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 84732    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 301      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 777      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 85855    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 301      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 779      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 87086    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 781      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 88321    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 301      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 784      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 89490    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-17.80 +/- 6.40\n",
      "Episode length: 211.40 +/- 78.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 211      |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 775      |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 90866    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 778      |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 91988    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 301      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 780      |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 93163    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 301      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 782      |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 94393    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 303      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 784      |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 95752    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 786      |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 96920    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 303      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 788      |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 98163    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 304      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 790      |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 99401    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-17.60 +/- 5.82\n",
      "Episode length: 224.20 +/- 79.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 224      |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100000   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 775      |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 100834   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0297   |\n",
      "|    n_updates        | 208      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 770      |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 102087   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 521      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 766      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 103161   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0289   |\n",
      "|    n_updates        | 790      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 763      |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 104391   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0294   |\n",
      "|    n_updates        | 1097     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 759      |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 105631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0688   |\n",
      "|    n_updates        | 1407     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 755      |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 106726   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0792   |\n",
      "|    n_updates        | 1681     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 752      |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 107944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 1985     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 304      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 749      |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 109051   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 2262     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-17.40 +/- 7.20\n",
      "Episode length: 205.40 +/- 85.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 205      |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 110000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 2499     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 736      |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 110546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0581   |\n",
      "|    n_updates        | 2636     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 733      |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 111766   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0396   |\n",
      "|    n_updates        | 2941     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 730      |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 112998   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 3249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 727      |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 114222   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0729   |\n",
      "|    n_updates        | 3555     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 725      |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 115322   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0477   |\n",
      "|    n_updates        | 3830     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 722      |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 116393   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0401   |\n",
      "|    n_updates        | 4098     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 117672   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.048    |\n",
      "|    n_updates        | 4417     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 118889   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0361   |\n",
      "|    n_updates        | 4722     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-17.00 +/- 8.00\n",
      "Episode length: 205.80 +/- 89.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 206      |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 120000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0302   |\n",
      "|    n_updates        | 4999     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 120300   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 5074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 307      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 704      |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 121576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 5393     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 702      |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 122798   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00687  |\n",
      "|    n_updates        | 5699     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 699      |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 123995   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0374   |\n",
      "|    n_updates        | 5998     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 125148   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00856  |\n",
      "|    n_updates        | 6286     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 126226   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 6556     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 304      |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 693      |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 127360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0284   |\n",
      "|    n_updates        | 6839     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 691      |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 128638   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00894  |\n",
      "|    n_updates        | 7159     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 689      |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 129973   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00922  |\n",
      "|    n_updates        | 7493     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-20.60 +/- 0.80\n",
      "Episode length: 242.80 +/- 15.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 243      |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 130000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 7499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 304      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 681      |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 131234   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 7808     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 303      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 679      |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 132422   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00574  |\n",
      "|    n_updates        | 8105     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 677      |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 133643   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 8410     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 304      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 675      |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 134836   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 8708     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 304      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 674      |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 135999   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 8999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 304      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 672      |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 137164   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 9290     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 304      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 670      |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 138378   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 9594     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 304      |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 669      |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 139447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 9861     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-20.40 +/- 0.80\n",
      "Episode length: 297.20 +/- 19.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 297      |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 140000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00812  |\n",
      "|    n_updates        | 9999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 661      |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 140580   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 10144    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 301      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 659      |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 141851   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00751  |\n",
      "|    n_updates        | 10462    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 658      |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 142941   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 10735    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 656      |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 144171   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 11042    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 655      |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 145365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 11341    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 654      |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 146559   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0085   |\n",
      "|    n_updates        | 11639    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 301      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 652      |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 147750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0045   |\n",
      "|    n_updates        | 11937    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 650      |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 149100   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 12274    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 278.00 +/- 20.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 278      |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 150000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00927  |\n",
      "|    n_updates        | 12499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 643      |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 150253   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 12563    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 642      |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 151450   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00366  |\n",
      "|    n_updates        | 12862    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 640      |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 152731   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 13182    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 299      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 639      |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 153900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 13474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 638      |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 155158   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 13789    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 301      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 637      |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 156282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 14070    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 636      |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 157531   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 14382    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 635      |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 158788   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00515  |\n",
      "|    n_updates        | 14696    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-17.80 +/- 5.91\n",
      "Episode length: 239.20 +/- 90.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 239      |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 160000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 14999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 303      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 629      |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 160297   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 15074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 303      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 628      |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 161499   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 15374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 303      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 627      |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 162723   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00568  |\n",
      "|    n_updates        | 15680    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 626      |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 163858   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00901  |\n",
      "|    n_updates        | 15964    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 625      |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 165044   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 16260    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 303      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 624      |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 166327   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00877  |\n",
      "|    n_updates        | 16581    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 623      |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 167674   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 16918    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 305      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 622      |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 168906   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 17226    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-18.80 +/- 4.40\n",
      "Episode length: 222.20 +/- 55.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 222      |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 170000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00613  |\n",
      "|    n_updates        | 17499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 617      |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 170302   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 17575    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 616      |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 171408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00904  |\n",
      "|    n_updates        | 17851    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 615      |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 172679   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 18169    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 614      |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 173869   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.026    |\n",
      "|    n_updates        | 18467    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 613      |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 175015   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00569  |\n",
      "|    n_updates        | 18753    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 612      |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 176227   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00642  |\n",
      "|    n_updates        | 19056    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 611      |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 177342   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 19335    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 610      |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 178607   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00696  |\n",
      "|    n_updates        | 19651    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 609      |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 179856   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 19963    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-18.40 +/- 3.26\n",
      "Episode length: 296.60 +/- 89.70\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 297      |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 180000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00846  |\n",
      "|    n_updates        | 19999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 604      |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 181149   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00796  |\n",
      "|    n_updates        | 20287    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 310      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 603      |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 182479   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 20619    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 310      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 603      |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 183687   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00564  |\n",
      "|    n_updates        | 20921    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 310      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 602      |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 184917   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00523  |\n",
      "|    n_updates        | 21229    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 602      |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 186070   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 21517    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 312      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 601      |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 187465   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 21866    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 311      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 600      |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 188585   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00527  |\n",
      "|    n_updates        | 22146    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 310      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 599      |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 189756   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0076   |\n",
      "|    n_updates        | 22438    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=190000, episode_reward=-17.80 +/- 6.40\n",
      "Episode length: 210.40 +/- 80.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 210      |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 190000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 22499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 595      |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 191221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 22805    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 595      |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 192439   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00981  |\n",
      "|    n_updates        | 23109    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 594      |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 193616   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 23403    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 310      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 594      |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 194854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 23713    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 310      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 593      |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 196022   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00917  |\n",
      "|    n_updates        | 24005    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 593      |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 197197   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 24299    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 592      |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 198477   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 24619    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 307      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 592      |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 199629   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00706  |\n",
      "|    n_updates        | 24907    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-19.80 +/- 2.40\n",
      "Episode length: 244.20 +/- 32.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 244      |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 24999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 200943   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 25235    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 202186   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 25546    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 307      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 203367   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 25841    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 307      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 204560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00972  |\n",
      "|    n_updates        | 26139    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 307      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 205737   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00315  |\n",
      "|    n_updates        | 26434    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 307      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 206881   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 26720    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 208273   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0243   |\n",
      "|    n_updates        | 27068    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 209543   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 27385    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-17.60 +/- 6.31\n",
      "Episode length: 252.20 +/- 101.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 252      |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 210000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 27499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 311      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 580      |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 210948   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 27736    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 312      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 580      |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total_timesteps  | 212383   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.026    |\n",
      "|    n_updates        | 28095    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 310      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 580      |\n",
      "|    time_elapsed     | 368      |\n",
      "|    total_timesteps  | 213491   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 28372    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 579      |\n",
      "|    time_elapsed     | 370      |\n",
      "|    total_timesteps  | 214632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00563  |\n",
      "|    n_updates        | 28657    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 579      |\n",
      "|    time_elapsed     | 372      |\n",
      "|    total_timesteps  | 215775   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00542  |\n",
      "|    n_updates        | 28943    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 310      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 578      |\n",
      "|    time_elapsed     | 374      |\n",
      "|    total_timesteps  | 217062   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00926  |\n",
      "|    n_updates        | 29265    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 308      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 578      |\n",
      "|    time_elapsed     | 377      |\n",
      "|    total_timesteps  | 218305   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00838  |\n",
      "|    n_updates        | 29576    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 311      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 577      |\n",
      "|    time_elapsed     | 380      |\n",
      "|    total_timesteps  | 219648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 29911    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-19.60 +/- 2.33\n",
      "Episode length: 306.20 +/- 46.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 306      |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 220000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00983  |\n",
      "|    n_updates        | 29999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 311      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.781    |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 573      |\n",
      "|    time_elapsed     | 384      |\n",
      "|    total_timesteps  | 220899   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 30224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.78     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 573      |\n",
      "|    time_elapsed     | 387      |\n",
      "|    total_timesteps  | 222144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 30535    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 310      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 573      |\n",
      "|    time_elapsed     | 389      |\n",
      "|    total_timesteps  | 223472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 30867    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 312      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.777    |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 392      |\n",
      "|    total_timesteps  | 224776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 31193    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 312      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.776    |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 395      |\n",
      "|    total_timesteps  | 226059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 31514    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 312      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.775    |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 571      |\n",
      "|    time_elapsed     | 397      |\n",
      "|    total_timesteps  | 227262   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00805  |\n",
      "|    n_updates        | 31815    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 314      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 571      |\n",
      "|    time_elapsed     | 400      |\n",
      "|    total_timesteps  | 228617   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 32154    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 314      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 570      |\n",
      "|    time_elapsed     | 402      |\n",
      "|    total_timesteps  | 229904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 32475    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-19.00 +/- 1.41\n",
      "Episode length: 429.40 +/- 106.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 429      |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 230000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 32499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 316      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.771    |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 566      |\n",
      "|    time_elapsed     | 408      |\n",
      "|    total_timesteps  | 231186   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 32796    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 315      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.77     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 410      |\n",
      "|    total_timesteps  | 232406   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 33101    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 315      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.769    |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 413      |\n",
      "|    total_timesteps  | 233694   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00668  |\n",
      "|    n_updates        | 33423    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 316      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.767    |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 415      |\n",
      "|    total_timesteps  | 234978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00553  |\n",
      "|    n_updates        | 33744    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 317      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.766    |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 564      |\n",
      "|    time_elapsed     | 418      |\n",
      "|    total_timesteps  | 236271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 34067    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 318      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.765    |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 564      |\n",
      "|    time_elapsed     | 420      |\n",
      "|    total_timesteps  | 237533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00908  |\n",
      "|    n_updates        | 34383    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 319      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.764    |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 564      |\n",
      "|    time_elapsed     | 423      |\n",
      "|    total_timesteps  | 238749   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0043   |\n",
      "|    n_updates        | 34687    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 317      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 425      |\n",
      "|    total_timesteps  | 239961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00427  |\n",
      "|    n_updates        | 34990    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-20.60 +/- 0.80\n",
      "Episode length: 263.60 +/- 25.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 264      |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 240000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 34999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 317      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.761    |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 560      |\n",
      "|    time_elapsed     | 430      |\n",
      "|    total_timesteps  | 241248   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00881  |\n",
      "|    n_updates        | 35311    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 316      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.76     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 560      |\n",
      "|    time_elapsed     | 432      |\n",
      "|    total_timesteps  | 242509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00763  |\n",
      "|    n_updates        | 35627    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 313      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.759    |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 560      |\n",
      "|    time_elapsed     | 435      |\n",
      "|    total_timesteps  | 243638   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 35909    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 315      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 559      |\n",
      "|    time_elapsed     | 437      |\n",
      "|    total_timesteps  | 244946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00868  |\n",
      "|    n_updates        | 36236    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 315      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.756    |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 559      |\n",
      "|    time_elapsed     | 440      |\n",
      "|    total_timesteps  | 246144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 36535    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 317      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.755    |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 558      |\n",
      "|    time_elapsed     | 442      |\n",
      "|    total_timesteps  | 247457   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 36864    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 317      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 558      |\n",
      "|    time_elapsed     | 445      |\n",
      "|    total_timesteps  | 248754   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 37188    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-17.40 +/- 6.22\n",
      "Episode length: 222.80 +/- 84.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 223      |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.753    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 250000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 37499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 320      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.752    |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 556      |\n",
      "|    time_elapsed     | 449      |\n",
      "|    total_timesteps  | 250277   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 37569    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 320      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.751    |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 555      |\n",
      "|    time_elapsed     | 452      |\n",
      "|    total_timesteps  | 251673   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0314   |\n",
      "|    n_updates        | 37918    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 320      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.75     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 555      |\n",
      "|    time_elapsed     | 455      |\n",
      "|    total_timesteps  | 252881   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 38220    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 320      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.748    |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 555      |\n",
      "|    time_elapsed     | 457      |\n",
      "|    total_timesteps  | 254170   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 38542    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 319      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.747    |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 555      |\n",
      "|    time_elapsed     | 460      |\n",
      "|    total_timesteps  | 255368   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00915  |\n",
      "|    n_updates        | 38841    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 320      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.746    |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 554      |\n",
      "|    time_elapsed     | 462      |\n",
      "|    total_timesteps  | 256800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 39199    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 319      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 554      |\n",
      "|    time_elapsed     | 465      |\n",
      "|    total_timesteps  | 257987   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 39496    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 321      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.743    |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 553      |\n",
      "|    time_elapsed     | 468      |\n",
      "|    total_timesteps  | 259322   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00503  |\n",
      "|    n_updates        | 39830    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-18.40 +/- 1.36\n",
      "Episode length: 315.60 +/- 56.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 316      |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.743    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 260000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00379  |\n",
      "|    n_updates        | 39999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 320      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 550      |\n",
      "|    time_elapsed     | 473      |\n",
      "|    total_timesteps  | 260613   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0069   |\n",
      "|    n_updates        | 40153    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 321      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 550      |\n",
      "|    time_elapsed     | 475      |\n",
      "|    total_timesteps  | 261969   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 40492    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 319      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.74     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 550      |\n",
      "|    time_elapsed     | 478      |\n",
      "|    total_timesteps  | 263122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0333   |\n",
      "|    n_updates        | 40780    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 319      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.738    |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 550      |\n",
      "|    time_elapsed     | 480      |\n",
      "|    total_timesteps  | 264323   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00511  |\n",
      "|    n_updates        | 41080    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 320      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.737    |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 549      |\n",
      "|    time_elapsed     | 483      |\n",
      "|    total_timesteps  | 265647   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 41411    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 320      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.736    |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 549      |\n",
      "|    time_elapsed     | 485      |\n",
      "|    total_timesteps  | 267020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 41754    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 319      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.735    |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 549      |\n",
      "|    time_elapsed     | 488      |\n",
      "|    total_timesteps  | 268177   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00964  |\n",
      "|    n_updates        | 42044    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 318      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.733    |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 549      |\n",
      "|    time_elapsed     | 490      |\n",
      "|    total_timesteps  | 269323   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 42330    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-18.40 +/- 4.27\n",
      "Episode length: 248.40 +/- 69.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 248      |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.733    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 270000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00924  |\n",
      "|    n_updates        | 42499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 319      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.732    |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 546      |\n",
      "|    time_elapsed     | 495      |\n",
      "|    total_timesteps  | 270695   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 42673    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 321      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.731    |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 546      |\n",
      "|    time_elapsed     | 497      |\n",
      "|    total_timesteps  | 272074   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 43018    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 322      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.729    |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 546      |\n",
      "|    time_elapsed     | 500      |\n",
      "|    total_timesteps  | 273451   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00848  |\n",
      "|    n_updates        | 43362    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 321      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.728    |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 545      |\n",
      "|    time_elapsed     | 502      |\n",
      "|    total_timesteps  | 274583   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00756  |\n",
      "|    n_updates        | 43645    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 322      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 545      |\n",
      "|    time_elapsed     | 505      |\n",
      "|    total_timesteps  | 275853   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 43963    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 322      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.726    |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 545      |\n",
      "|    time_elapsed     | 508      |\n",
      "|    total_timesteps  | 277184   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0284   |\n",
      "|    n_updates        | 44295    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 323      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.724    |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 545      |\n",
      "|    time_elapsed     | 510      |\n",
      "|    total_timesteps  | 278436   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 44608    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 323      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 545      |\n",
      "|    time_elapsed     | 513      |\n",
      "|    total_timesteps  | 279723   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00594  |\n",
      "|    n_updates        | 44930    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=280000, episode_reward=-17.00 +/- 7.01\n",
      "Episode length: 233.40 +/- 90.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 233      |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 280000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0237   |\n",
      "|    n_updates        | 44999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 325      |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.722    |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 543      |\n",
      "|    time_elapsed     | 517      |\n",
      "|    total_timesteps  | 281249   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 45312    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 324      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 542      |\n",
      "|    time_elapsed     | 520      |\n",
      "|    total_timesteps  | 282640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 45659    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 321      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 542      |\n",
      "|    time_elapsed     | 523      |\n",
      "|    total_timesteps  | 283809   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00845  |\n",
      "|    n_updates        | 45952    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 321      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.718    |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 542      |\n",
      "|    time_elapsed     | 525      |\n",
      "|    total_timesteps  | 284997   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00826  |\n",
      "|    n_updates        | 46249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 323      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.716    |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 541      |\n",
      "|    time_elapsed     | 528      |\n",
      "|    total_timesteps  | 286457   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 46614    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 323      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 541      |\n",
      "|    time_elapsed     | 530      |\n",
      "|    total_timesteps  | 287666   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00953  |\n",
      "|    n_updates        | 46916    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 321      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.714    |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 541      |\n",
      "|    time_elapsed     | 533      |\n",
      "|    total_timesteps  | 288904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 47225    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-19.40 +/- 1.85\n",
      "Episode length: 292.00 +/- 47.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 292      |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.713    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 290000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 47499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 323      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.713    |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 539      |\n",
      "|    time_elapsed     | 538      |\n",
      "|    total_timesteps  | 290313   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00961  |\n",
      "|    n_updates        | 47578    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 323      |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 538      |\n",
      "|    time_elapsed     | 541      |\n",
      "|    total_timesteps  | 291631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.035    |\n",
      "|    n_updates        | 47907    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 322      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.71     |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 538      |\n",
      "|    time_elapsed     | 543      |\n",
      "|    total_timesteps  | 292839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0262   |\n",
      "|    n_updates        | 48209    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 322      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.709    |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 538      |\n",
      "|    time_elapsed     | 546      |\n",
      "|    total_timesteps  | 294166   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0291   |\n",
      "|    n_updates        | 48541    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 324      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.707    |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 538      |\n",
      "|    time_elapsed     | 548      |\n",
      "|    total_timesteps  | 295531   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0444   |\n",
      "|    n_updates        | 48882    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 326      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.706    |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 538      |\n",
      "|    time_elapsed     | 551      |\n",
      "|    total_timesteps  | 296904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 49225    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 326      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.705    |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 538      |\n",
      "|    time_elapsed     | 554      |\n",
      "|    total_timesteps  | 298197   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00839  |\n",
      "|    n_updates        | 49549    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 324      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.704    |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 537      |\n",
      "|    time_elapsed     | 556      |\n",
      "|    total_timesteps  | 299451   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 49862    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-17.40 +/- 6.22\n",
      "Episode length: 373.80 +/- 156.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 374      |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.703    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 300000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 49999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 327      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.702    |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 534      |\n",
      "|    time_elapsed     | 562      |\n",
      "|    total_timesteps  | 300904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00878  |\n",
      "|    n_updates        | 50225    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 329      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 534      |\n",
      "|    time_elapsed     | 565      |\n",
      "|    total_timesteps  | 302183   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00552  |\n",
      "|    n_updates        | 50545    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 328      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.7      |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 534      |\n",
      "|    time_elapsed     | 567      |\n",
      "|    total_timesteps  | 303447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 50861    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 327      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 534      |\n",
      "|    time_elapsed     | 570      |\n",
      "|    total_timesteps  | 304754   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00584  |\n",
      "|    n_updates        | 51188    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 325      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.697    |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 534      |\n",
      "|    time_elapsed     | 572      |\n",
      "|    total_timesteps  | 305949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 51487    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 327      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 534      |\n",
      "|    time_elapsed     | 575      |\n",
      "|    total_timesteps  | 307244   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0414   |\n",
      "|    n_updates        | 51810    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 327      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.695    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 534      |\n",
      "|    time_elapsed     | 577      |\n",
      "|    total_timesteps  | 308569   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 52142    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 325      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.693    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 533      |\n",
      "|    time_elapsed     | 579      |\n",
      "|    total_timesteps  | 309690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 52422    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-20.20 +/- 0.40\n",
      "Episode length: 312.40 +/- 43.70\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 312      |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.693    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 310000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 52499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 325      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 531      |\n",
      "|    time_elapsed     | 584      |\n",
      "|    total_timesteps  | 310938   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 52734    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 325      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.691    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 531      |\n",
      "|    time_elapsed     | 587      |\n",
      "|    total_timesteps  | 312254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00771  |\n",
      "|    n_updates        | 53063    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 322      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.69     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 531      |\n",
      "|    time_elapsed     | 589      |\n",
      "|    total_timesteps  | 313452   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 53362    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 323      |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 531      |\n",
      "|    time_elapsed     | 592      |\n",
      "|    total_timesteps  | 314893   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 53723    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 326      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.687    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 531      |\n",
      "|    time_elapsed     | 595      |\n",
      "|    total_timesteps  | 316365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 54091    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 326      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 530      |\n",
      "|    time_elapsed     | 598      |\n",
      "|    total_timesteps  | 317626   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 54406    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 325      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.684    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 530      |\n",
      "|    time_elapsed     | 600      |\n",
      "|    total_timesteps  | 318911   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00517  |\n",
      "|    n_updates        | 54727    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-18.60 +/- 3.83\n",
      "Episode length: 237.40 +/- 56.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 237      |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 320000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00621  |\n",
      "|    n_updates        | 54999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 327      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 529      |\n",
      "|    time_elapsed     | 605      |\n",
      "|    total_timesteps  | 320324   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00649  |\n",
      "|    n_updates        | 55080    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 327      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.682    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 528      |\n",
      "|    time_elapsed     | 607      |\n",
      "|    total_timesteps  | 321591   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0235   |\n",
      "|    n_updates        | 55397    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 325      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.68     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 528      |\n",
      "|    time_elapsed     | 610      |\n",
      "|    total_timesteps  | 322764   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00424  |\n",
      "|    n_updates        | 55690    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 326      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.679    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 528      |\n",
      "|    time_elapsed     | 613      |\n",
      "|    total_timesteps  | 324263   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00998  |\n",
      "|    n_updates        | 56065    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 327      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 528      |\n",
      "|    time_elapsed     | 615      |\n",
      "|    total_timesteps  | 325513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0066   |\n",
      "|    n_updates        | 56378    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 326      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.677    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 528      |\n",
      "|    time_elapsed     | 618      |\n",
      "|    total_timesteps  | 326718   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 56679    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 325      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.675    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 528      |\n",
      "|    time_elapsed     | 621      |\n",
      "|    total_timesteps  | 328063   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00954  |\n",
      "|    n_updates        | 57015    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 324      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.674    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 528      |\n",
      "|    time_elapsed     | 623      |\n",
      "|    total_timesteps  | 329315   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0257   |\n",
      "|    n_updates        | 57328    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-16.60 +/- 1.02\n",
      "Episode length: 469.00 +/- 67.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 469      |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 330000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 57499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 328      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.672    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 524      |\n",
      "|    time_elapsed     | 630      |\n",
      "|    total_timesteps  | 330970   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 57742    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 329      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 524      |\n",
      "|    time_elapsed     | 633      |\n",
      "|    total_timesteps  | 332397   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 58099    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 328      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.67     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 524      |\n",
      "|    time_elapsed     | 635      |\n",
      "|    total_timesteps  | 333692   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 58422    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 328      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 524      |\n",
      "|    time_elapsed     | 638      |\n",
      "|    total_timesteps  | 335018   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00789  |\n",
      "|    n_updates        | 58754    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 329      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.667    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 524      |\n",
      "|    time_elapsed     | 641      |\n",
      "|    total_timesteps  | 336368   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 59091    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 329      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.666    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 524      |\n",
      "|    time_elapsed     | 644      |\n",
      "|    total_timesteps  | 337671   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 59417    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 331      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 524      |\n",
      "|    time_elapsed     | 646      |\n",
      "|    total_timesteps  | 339039   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 59759    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-17.40 +/- 1.85\n",
      "Episode length: 434.80 +/- 94.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 435      |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 340000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00864  |\n",
      "|    n_updates        | 59999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 331      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 521      |\n",
      "|    time_elapsed     | 652      |\n",
      "|    total_timesteps  | 340305   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 60076    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 331      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.662    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 521      |\n",
      "|    time_elapsed     | 655      |\n",
      "|    total_timesteps  | 341694   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 60423    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 333      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.66     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 521      |\n",
      "|    time_elapsed     | 658      |\n",
      "|    total_timesteps  | 343011   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 60752    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 333      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.659    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 521      |\n",
      "|    time_elapsed     | 660      |\n",
      "|    total_timesteps  | 344250   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 61062    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 333      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 520      |\n",
      "|    time_elapsed     | 663      |\n",
      "|    total_timesteps  | 345526   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 61381    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 336      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 520      |\n",
      "|    time_elapsed     | 666      |\n",
      "|    total_timesteps  | 347019   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 61754    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 334      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.655    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 520      |\n",
      "|    time_elapsed     | 668      |\n",
      "|    total_timesteps  | 348288   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00925  |\n",
      "|    n_updates        | 62071    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 333      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 520      |\n",
      "|    time_elapsed     | 671      |\n",
      "|    total_timesteps  | 349663   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00611  |\n",
      "|    n_updates        | 62415    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-14.60 +/- 6.44\n",
      "Episode length: 354.60 +/- 172.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 355      |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 350000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00738  |\n",
      "|    n_updates        | 62499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 337      |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.652    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 518      |\n",
      "|    time_elapsed     | 677      |\n",
      "|    total_timesteps  | 351346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 62836    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 338      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.651    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 518      |\n",
      "|    time_elapsed     | 680      |\n",
      "|    total_timesteps  | 352745   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00545  |\n",
      "|    n_updates        | 63186    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 337      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.65     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 518      |\n",
      "|    time_elapsed     | 683      |\n",
      "|    total_timesteps  | 353977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 63494    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 336      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.648    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 518      |\n",
      "|    time_elapsed     | 685      |\n",
      "|    total_timesteps  | 355183   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 63795    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 337      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.647    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 517      |\n",
      "|    time_elapsed     | 688      |\n",
      "|    total_timesteps  | 356500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 64124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 337      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 517      |\n",
      "|    time_elapsed     | 691      |\n",
      "|    total_timesteps  | 357951   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 64487    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 338      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.644    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 517      |\n",
      "|    time_elapsed     | 694      |\n",
      "|    total_timesteps  | 359288   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 64821    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-18.00 +/- 1.67\n",
      "Episode length: 431.00 +/- 91.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 431      |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.644    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 360000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00739  |\n",
      "|    n_updates        | 64999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 339      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.643    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 514      |\n",
      "|    time_elapsed     | 700      |\n",
      "|    total_timesteps  | 360639   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 65159    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 340      |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.642    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 514      |\n",
      "|    time_elapsed     | 703      |\n",
      "|    total_timesteps  | 362032   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00901  |\n",
      "|    n_updates        | 65507    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 341      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 514      |\n",
      "|    time_elapsed     | 706      |\n",
      "|    total_timesteps  | 363442   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00822  |\n",
      "|    n_updates        | 65860    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 340      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.639    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 514      |\n",
      "|    time_elapsed     | 709      |\n",
      "|    total_timesteps  | 364974   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.03     |\n",
      "|    n_updates        | 66243    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 340      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 514      |\n",
      "|    time_elapsed     | 712      |\n",
      "|    total_timesteps  | 366389   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0093   |\n",
      "|    n_updates        | 66597    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 340      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.636    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 514      |\n",
      "|    time_elapsed     | 714      |\n",
      "|    total_timesteps  | 367729   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0316   |\n",
      "|    n_updates        | 66932    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 342      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.634    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 514      |\n",
      "|    time_elapsed     | 717      |\n",
      "|    total_timesteps  | 369211   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 67302    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=-18.60 +/- 0.49\n",
      "Episode length: 415.40 +/- 18.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 415      |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.634    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 370000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 67499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 343      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.633    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 511      |\n",
      "|    time_elapsed     | 724      |\n",
      "|    total_timesteps  | 370705   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 67676    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 345      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.632    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 511      |\n",
      "|    time_elapsed     | 727      |\n",
      "|    total_timesteps  | 372146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00671  |\n",
      "|    n_updates        | 68036    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 345      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.63     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 511      |\n",
      "|    time_elapsed     | 729      |\n",
      "|    total_timesteps  | 373490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 68372    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 345      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.629    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 511      |\n",
      "|    time_elapsed     | 732      |\n",
      "|    total_timesteps  | 374825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00774  |\n",
      "|    n_updates        | 68706    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 345      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 511      |\n",
      "|    time_elapsed     | 735      |\n",
      "|    total_timesteps  | 376216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 69053    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 346      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.626    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 511      |\n",
      "|    time_elapsed     | 738      |\n",
      "|    total_timesteps  | 377564   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 69390    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 346      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.625    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 511      |\n",
      "|    time_elapsed     | 740      |\n",
      "|    total_timesteps  | 378879   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00633  |\n",
      "|    n_updates        | 69719    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=-16.40 +/- 2.65\n",
      "Episode length: 449.00 +/- 106.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 449      |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 380000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00895  |\n",
      "|    n_updates        | 69999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 348      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.623    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 508      |\n",
      "|    time_elapsed     | 747      |\n",
      "|    total_timesteps  | 380322   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 70080    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 348      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.622    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 508      |\n",
      "|    time_elapsed     | 750      |\n",
      "|    total_timesteps  | 381838   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 70459    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 349      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.621    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 508      |\n",
      "|    time_elapsed     | 753      |\n",
      "|    total_timesteps  | 383145   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00991  |\n",
      "|    n_updates        | 70786    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 348      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.619    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 508      |\n",
      "|    time_elapsed     | 755      |\n",
      "|    total_timesteps  | 384486   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 71121    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 347      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.618    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1228     |\n",
      "|    fps              | 508      |\n",
      "|    time_elapsed     | 758      |\n",
      "|    total_timesteps  | 386035   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 71508    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 347      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1232     |\n",
      "|    fps              | 508      |\n",
      "|    time_elapsed     | 761      |\n",
      "|    total_timesteps  | 387485   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 71871    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 350      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.615    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1236     |\n",
      "|    fps              | 508      |\n",
      "|    time_elapsed     | 764      |\n",
      "|    total_timesteps  | 388976   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 72243    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=-14.80 +/- 2.93\n",
      "Episode length: 413.80 +/- 82.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 414      |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.614    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 390000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 72499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 355      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.613    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 506      |\n",
      "|    time_elapsed     | 771      |\n",
      "|    total_timesteps  | 390689   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 72672    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 358      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.612    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1244     |\n",
      "|    fps              | 506      |\n",
      "|    time_elapsed     | 774      |\n",
      "|    total_timesteps  | 392280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 73069    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 356      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.61     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1248     |\n",
      "|    fps              | 506      |\n",
      "|    time_elapsed     | 777      |\n",
      "|    total_timesteps  | 393586   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00754  |\n",
      "|    n_updates        | 73396    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 358      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1252     |\n",
      "|    fps              | 506      |\n",
      "|    time_elapsed     | 780      |\n",
      "|    total_timesteps  | 395122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 73780    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 361      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.607    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1256     |\n",
      "|    fps              | 506      |\n",
      "|    time_elapsed     | 783      |\n",
      "|    total_timesteps  | 396768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 74191    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 361      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.606    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 506      |\n",
      "|    time_elapsed     | 786      |\n",
      "|    total_timesteps  | 398136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 74533    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 361      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.604    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1264     |\n",
      "|    fps              | 506      |\n",
      "|    time_elapsed     | 789      |\n",
      "|    total_timesteps  | 399500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00752  |\n",
      "|    n_updates        | 74874    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-18.20 +/- 2.40\n",
      "Episode length: 379.80 +/- 46.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 380      |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.604    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 400000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 74999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 361      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1268     |\n",
      "|    fps              | 504      |\n",
      "|    time_elapsed     | 795      |\n",
      "|    total_timesteps  | 401066   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 75266    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 360      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.602    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1272     |\n",
      "|    fps              | 504      |\n",
      "|    time_elapsed     | 798      |\n",
      "|    total_timesteps  | 402421   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 75605    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 361      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.6      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1276     |\n",
      "|    fps              | 504      |\n",
      "|    time_elapsed     | 801      |\n",
      "|    total_timesteps  | 403834   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00649  |\n",
      "|    n_updates        | 75958    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 360      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.599    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 504      |\n",
      "|    time_elapsed     | 803      |\n",
      "|    total_timesteps  | 405207   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00911  |\n",
      "|    n_updates        | 76301    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 358      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.598    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1284     |\n",
      "|    fps              | 504      |\n",
      "|    time_elapsed     | 806      |\n",
      "|    total_timesteps  | 406530   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 76632    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 358      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.596    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1288     |\n",
      "|    fps              | 503      |\n",
      "|    time_elapsed     | 809      |\n",
      "|    total_timesteps  | 407910   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00842  |\n",
      "|    n_updates        | 76977    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 359      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.595    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1292     |\n",
      "|    fps              | 503      |\n",
      "|    time_elapsed     | 812      |\n",
      "|    total_timesteps  | 409381   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 77345    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=-16.60 +/- 2.80\n",
      "Episode length: 457.40 +/- 89.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 457      |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.594    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 410000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 77499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 363      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.593    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1296     |\n",
      "|    fps              | 501      |\n",
      "|    time_elapsed     | 819      |\n",
      "|    total_timesteps  | 411082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 77770    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 363      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 501      |\n",
      "|    time_elapsed     | 822      |\n",
      "|    total_timesteps  | 412471   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 78117    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 364      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1304     |\n",
      "|    fps              | 501      |\n",
      "|    time_elapsed     | 825      |\n",
      "|    total_timesteps  | 413939   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0091   |\n",
      "|    n_updates        | 78484    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 364      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.589    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1308     |\n",
      "|    fps              | 501      |\n",
      "|    time_elapsed     | 828      |\n",
      "|    total_timesteps  | 415323   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 78830    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 366      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.587    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1312     |\n",
      "|    fps              | 501      |\n",
      "|    time_elapsed     | 831      |\n",
      "|    total_timesteps  | 416936   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 79233    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 366      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1316     |\n",
      "|    fps              | 501      |\n",
      "|    time_elapsed     | 834      |\n",
      "|    total_timesteps  | 418476   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0304   |\n",
      "|    n_updates        | 79618    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 368      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.584    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 501      |\n",
      "|    time_elapsed     | 837      |\n",
      "|    total_timesteps  | 419961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00908  |\n",
      "|    n_updates        | 79990    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=-17.00 +/- 0.89\n",
      "Episode length: 447.40 +/- 44.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 447      |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.584    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 420000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 79999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 370      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.583    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1324     |\n",
      "|    fps              | 499      |\n",
      "|    time_elapsed     | 844      |\n",
      "|    total_timesteps  | 421447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 80361    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 371      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.581    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1328     |\n",
      "|    fps              | 499      |\n",
      "|    time_elapsed     | 847      |\n",
      "|    total_timesteps  | 423135   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00926  |\n",
      "|    n_updates        | 80783    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 369      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.58     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1332     |\n",
      "|    fps              | 499      |\n",
      "|    time_elapsed     | 850      |\n",
      "|    total_timesteps  | 424419   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00673  |\n",
      "|    n_updates        | 81104    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 371      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.578    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1336     |\n",
      "|    fps              | 499      |\n",
      "|    time_elapsed     | 853      |\n",
      "|    total_timesteps  | 426043   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00712  |\n",
      "|    n_updates        | 81510    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 369      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.577    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 499      |\n",
      "|    time_elapsed     | 856      |\n",
      "|    total_timesteps  | 427621   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 81905    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 368      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.575    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1344     |\n",
      "|    fps              | 498      |\n",
      "|    time_elapsed     | 860      |\n",
      "|    total_timesteps  | 429077   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0068   |\n",
      "|    n_updates        | 82269    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-18.40 +/- 2.42\n",
      "Episode length: 358.80 +/- 70.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 359      |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 430000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 82499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 372      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1348     |\n",
      "|    fps              | 497      |\n",
      "|    time_elapsed     | 866      |\n",
      "|    total_timesteps  | 430790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00471  |\n",
      "|    n_updates        | 82697    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 372      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.572    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1352     |\n",
      "|    fps              | 497      |\n",
      "|    time_elapsed     | 869      |\n",
      "|    total_timesteps  | 432330   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00775  |\n",
      "|    n_updates        | 83082    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 370      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.571    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1356     |\n",
      "|    fps              | 497      |\n",
      "|    time_elapsed     | 872      |\n",
      "|    total_timesteps  | 433774   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 83443    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 371      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.569    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 497      |\n",
      "|    time_elapsed     | 875      |\n",
      "|    total_timesteps  | 435266   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 83816    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 373      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1364     |\n",
      "|    fps              | 497      |\n",
      "|    time_elapsed     | 878      |\n",
      "|    total_timesteps  | 436787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 84196    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 373      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.566    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1368     |\n",
      "|    fps              | 497      |\n",
      "|    time_elapsed     | 881      |\n",
      "|    total_timesteps  | 438335   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0078   |\n",
      "|    n_updates        | 84583    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 373      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.565    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1372     |\n",
      "|    fps              | 496      |\n",
      "|    time_elapsed     | 884      |\n",
      "|    total_timesteps  | 439743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 84935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-14.20 +/- 6.14\n",
      "Episode length: 393.40 +/- 191.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 393      |\n",
      "|    mean_reward      | -14.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 440000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 84999    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 378      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.563    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1376     |\n",
      "|    fps              | 495      |\n",
      "|    time_elapsed     | 891      |\n",
      "|    total_timesteps  | 441649   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00963  |\n",
      "|    n_updates        | 85412    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 380      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.561    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 495      |\n",
      "|    time_elapsed     | 895      |\n",
      "|    total_timesteps  | 443185   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 85796    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 382      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.56     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1384     |\n",
      "|    fps              | 495      |\n",
      "|    time_elapsed     | 898      |\n",
      "|    total_timesteps  | 444739   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 86184    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 382      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.558    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1388     |\n",
      "|    fps              | 495      |\n",
      "|    time_elapsed     | 901      |\n",
      "|    total_timesteps  | 446128   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 86531    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 382      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.557    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1392     |\n",
      "|    fps              | 494      |\n",
      "|    time_elapsed     | 904      |\n",
      "|    total_timesteps  | 447571   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 86892    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 379      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.556    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1396     |\n",
      "|    fps              | 494      |\n",
      "|    time_elapsed     | 907      |\n",
      "|    total_timesteps  | 448978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 87244    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-13.20 +/- 6.14\n",
      "Episode length: 462.20 +/- 221.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 462      |\n",
      "|    mean_reward      | -13.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 450000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00725  |\n",
      "|    n_updates        | 87499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 383      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.554    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 492      |\n",
      "|    time_elapsed     | 914      |\n",
      "|    total_timesteps  | 450754   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00784  |\n",
      "|    n_updates        | 87688    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 383      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.552    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1404     |\n",
      "|    fps              | 492      |\n",
      "|    time_elapsed     | 917      |\n",
      "|    total_timesteps  | 452238   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 88059    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 384      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1408     |\n",
      "|    fps              | 492      |\n",
      "|    time_elapsed     | 920      |\n",
      "|    total_timesteps  | 453748   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 88436    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 382      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.549    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1412     |\n",
      "|    fps              | 492      |\n",
      "|    time_elapsed     | 923      |\n",
      "|    total_timesteps  | 455184   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00838  |\n",
      "|    n_updates        | 88795    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 382      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1416     |\n",
      "|    fps              | 492      |\n",
      "|    time_elapsed     | 926      |\n",
      "|    total_timesteps  | 456667   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0243   |\n",
      "|    n_updates        | 89166    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 381      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.547    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 492      |\n",
      "|    time_elapsed     | 929      |\n",
      "|    total_timesteps  | 458042   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00942  |\n",
      "|    n_updates        | 89510    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 381      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1424     |\n",
      "|    fps              | 492      |\n",
      "|    time_elapsed     | 932      |\n",
      "|    total_timesteps  | 459515   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 89878    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=-15.60 +/- 2.06\n",
      "Episode length: 502.00 +/- 50.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 502      |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 460000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 89999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 379      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.544    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1428     |\n",
      "|    fps              | 490      |\n",
      "|    time_elapsed     | 939      |\n",
      "|    total_timesteps  | 461050   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00911  |\n",
      "|    n_updates        | 90262    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 380      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.542    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1432     |\n",
      "|    fps              | 490      |\n",
      "|    time_elapsed     | 942      |\n",
      "|    total_timesteps  | 462447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00684  |\n",
      "|    n_updates        | 90611    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 379      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.541    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1436     |\n",
      "|    fps              | 490      |\n",
      "|    time_elapsed     | 945      |\n",
      "|    total_timesteps  | 463908   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00979  |\n",
      "|    n_updates        | 90976    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 377      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.539    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 490      |\n",
      "|    time_elapsed     | 948      |\n",
      "|    total_timesteps  | 465328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0358   |\n",
      "|    n_updates        | 91331    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 377      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.538    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1444     |\n",
      "|    fps              | 490      |\n",
      "|    time_elapsed     | 951      |\n",
      "|    total_timesteps  | 466814   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00509  |\n",
      "|    n_updates        | 91703    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 375      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.536    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1448     |\n",
      "|    fps              | 490      |\n",
      "|    time_elapsed     | 955      |\n",
      "|    total_timesteps  | 468330   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 92082    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 375      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.535    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1452     |\n",
      "|    fps              | 490      |\n",
      "|    time_elapsed     | 958      |\n",
      "|    total_timesteps  | 469843   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.028    |\n",
      "|    n_updates        | 92460    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=-17.00 +/- 3.03\n",
      "Episode length: 507.80 +/- 120.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 508      |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.535    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 470000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 92499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 377      |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.533    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1456     |\n",
      "|    fps              | 488      |\n",
      "|    time_elapsed     | 965      |\n",
      "|    total_timesteps  | 471450   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 92862    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 377      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.532    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 488      |\n",
      "|    time_elapsed     | 968      |\n",
      "|    total_timesteps  | 472994   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 93248    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 378      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.53     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1464     |\n",
      "|    fps              | 488      |\n",
      "|    time_elapsed     | 972      |\n",
      "|    total_timesteps  | 474637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 93659    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 378      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.529    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1468     |\n",
      "|    fps              | 488      |\n",
      "|    time_elapsed     | 975      |\n",
      "|    total_timesteps  | 476146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00922  |\n",
      "|    n_updates        | 94036    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 381      |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1472     |\n",
      "|    fps              | 488      |\n",
      "|    time_elapsed     | 978      |\n",
      "|    total_timesteps  | 477881   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00828  |\n",
      "|    n_updates        | 94470    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 379      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1476     |\n",
      "|    fps              | 488      |\n",
      "|    time_elapsed     | 982      |\n",
      "|    total_timesteps  | 479544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 94885    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-17.60 +/- 3.32\n",
      "Episode length: 401.60 +/- 61.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 402      |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 480000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 94999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 379      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.524    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 486      |\n",
      "|    time_elapsed     | 988      |\n",
      "|    total_timesteps  | 481100   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00659  |\n",
      "|    n_updates        | 95274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 379      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.522    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1484     |\n",
      "|    fps              | 486      |\n",
      "|    time_elapsed     | 991      |\n",
      "|    total_timesteps  | 482673   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 95668    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 380      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.521    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1488     |\n",
      "|    fps              | 486      |\n",
      "|    time_elapsed     | 994      |\n",
      "|    total_timesteps  | 484178   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 96044    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 379      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.519    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1492     |\n",
      "|    fps              | 486      |\n",
      "|    time_elapsed     | 997      |\n",
      "|    total_timesteps  | 485495   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00677  |\n",
      "|    n_updates        | 96373    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 383      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1496     |\n",
      "|    fps              | 486      |\n",
      "|    time_elapsed     | 1001     |\n",
      "|    total_timesteps  | 487231   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 96807    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 379      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.516    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 486      |\n",
      "|    time_elapsed     | 1004     |\n",
      "|    total_timesteps  | 488633   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 97158    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=-16.00 +/- 4.47\n",
      "Episode length: 525.80 +/- 175.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 526      |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.515    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 490000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 97499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 381      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.515    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1504     |\n",
      "|    fps              | 484      |\n",
      "|    time_elapsed     | 1011     |\n",
      "|    total_timesteps  | 490352   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 97587    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 381      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1508     |\n",
      "|    fps              | 484      |\n",
      "|    time_elapsed     | 1014     |\n",
      "|    total_timesteps  | 491837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 97959    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 382      |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.512    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1512     |\n",
      "|    fps              | 484      |\n",
      "|    time_elapsed     | 1017     |\n",
      "|    total_timesteps  | 493390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 98347    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 383      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1516     |\n",
      "|    fps              | 484      |\n",
      "|    time_elapsed     | 1021     |\n",
      "|    total_timesteps  | 494943   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00666  |\n",
      "|    n_updates        | 98735    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 383      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.509    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 484      |\n",
      "|    time_elapsed     | 1024     |\n",
      "|    total_timesteps  | 496328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0323   |\n",
      "|    n_updates        | 99081    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 383      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.507    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1524     |\n",
      "|    fps              | 484      |\n",
      "|    time_elapsed     | 1027     |\n",
      "|    total_timesteps  | 497839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00349  |\n",
      "|    n_updates        | 99459    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 385      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.505    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1528     |\n",
      "|    fps              | 484      |\n",
      "|    time_elapsed     | 1030     |\n",
      "|    total_timesteps  | 499515   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 99878    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500000, episode_reward=-15.20 +/- 3.43\n",
      "Episode length: 561.80 +/- 79.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 562      |\n",
      "|    mean_reward      | -15.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.505    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 99999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 388      |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.504    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1532     |\n",
      "|    fps              | 482      |\n",
      "|    time_elapsed     | 1038     |\n",
      "|    total_timesteps  | 501254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 100313   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 391      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.502    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1536     |\n",
      "|    fps              | 482      |\n",
      "|    time_elapsed     | 1042     |\n",
      "|    total_timesteps  | 503022   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 100755   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 393      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.5      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 482      |\n",
      "|    time_elapsed     | 1045     |\n",
      "|    total_timesteps  | 504605   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 101151   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 394      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1544     |\n",
      "|    fps              | 482      |\n",
      "|    time_elapsed     | 1048     |\n",
      "|    total_timesteps  | 506238   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 101559   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 395      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.497    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1548     |\n",
      "|    fps              | 482      |\n",
      "|    time_elapsed     | 1052     |\n",
      "|    total_timesteps  | 507844   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 101960   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 397      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1552     |\n",
      "|    fps              | 482      |\n",
      "|    time_elapsed     | 1055     |\n",
      "|    total_timesteps  | 509512   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00766  |\n",
      "|    n_updates        | 102377   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=-15.60 +/- 2.58\n",
      "Episode length: 601.40 +/- 70.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 601      |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.495    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 510000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 102499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 397      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.494    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1556     |\n",
      "|    fps              | 480      |\n",
      "|    time_elapsed     | 1063     |\n",
      "|    total_timesteps  | 511160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00554  |\n",
      "|    n_updates        | 102789   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 396      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.493    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 480      |\n",
      "|    time_elapsed     | 1066     |\n",
      "|    total_timesteps  | 512604   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 103150   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 394      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1564     |\n",
      "|    fps              | 480      |\n",
      "|    time_elapsed     | 1070     |\n",
      "|    total_timesteps  | 514066   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 103516   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 395      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.489    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1568     |\n",
      "|    fps              | 480      |\n",
      "|    time_elapsed     | 1073     |\n",
      "|    total_timesteps  | 515677   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00686  |\n",
      "|    n_updates        | 103919   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 393      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.488    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1572     |\n",
      "|    fps              | 480      |\n",
      "|    time_elapsed     | 1076     |\n",
      "|    total_timesteps  | 517153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00705  |\n",
      "|    n_updates        | 104288   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 392      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.486    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1576     |\n",
      "|    fps              | 480      |\n",
      "|    time_elapsed     | 1079     |\n",
      "|    total_timesteps  | 518790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 104697   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-15.00 +/- 6.32\n",
      "Episode length: 451.80 +/- 195.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 452      |\n",
      "|    mean_reward      | -15      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 520000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 104999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 396      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 478      |\n",
      "|    time_elapsed     | 1087     |\n",
      "|    total_timesteps  | 520695   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 105173   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 395      |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.483    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1584     |\n",
      "|    fps              | 478      |\n",
      "|    time_elapsed     | 1091     |\n",
      "|    total_timesteps  | 522212   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0064   |\n",
      "|    n_updates        | 105552   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 396      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.481    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1588     |\n",
      "|    fps              | 478      |\n",
      "|    time_elapsed     | 1094     |\n",
      "|    total_timesteps  | 523815   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00722  |\n",
      "|    n_updates        | 105953   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 399      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.48     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1592     |\n",
      "|    fps              | 478      |\n",
      "|    time_elapsed     | 1097     |\n",
      "|    total_timesteps  | 525374   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 106343   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 397      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1596     |\n",
      "|    fps              | 478      |\n",
      "|    time_elapsed     | 1101     |\n",
      "|    total_timesteps  | 526921   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 106730   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 400      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.477    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 478      |\n",
      "|    time_elapsed     | 1104     |\n",
      "|    total_timesteps  | 528602   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 107150   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=-14.40 +/- 4.50\n",
      "Episode length: 485.80 +/- 166.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 486      |\n",
      "|    mean_reward      | -14.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 530000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00865  |\n",
      "|    n_updates        | 107499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 400      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1604     |\n",
      "|    fps              | 476      |\n",
      "|    time_elapsed     | 1111     |\n",
      "|    total_timesteps  | 530363   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 107590   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 404      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.473    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1608     |\n",
      "|    fps              | 476      |\n",
      "|    time_elapsed     | 1115     |\n",
      "|    total_timesteps  | 532247   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 108061   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 405      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.471    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1612     |\n",
      "|    fps              | 476      |\n",
      "|    time_elapsed     | 1119     |\n",
      "|    total_timesteps  | 533893   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 108473   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 406      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.47     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1616     |\n",
      "|    fps              | 476      |\n",
      "|    time_elapsed     | 1122     |\n",
      "|    total_timesteps  | 535530   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0082   |\n",
      "|    n_updates        | 108882   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 410      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 476      |\n",
      "|    time_elapsed     | 1126     |\n",
      "|    total_timesteps  | 537376   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 109343   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 416      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.466    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1624     |\n",
      "|    fps              | 476      |\n",
      "|    time_elapsed     | 1131     |\n",
      "|    total_timesteps  | 539405   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0302   |\n",
      "|    n_updates        | 109851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=-14.80 +/- 5.15\n",
      "Episode length: 509.20 +/- 161.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 509      |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.465    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 540000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00866  |\n",
      "|    n_updates        | 109999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 419      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.464    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1628     |\n",
      "|    fps              | 475      |\n",
      "|    time_elapsed     | 1139     |\n",
      "|    total_timesteps  | 541369   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 110342   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 417      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.462    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1632     |\n",
      "|    fps              | 475      |\n",
      "|    time_elapsed     | 1142     |\n",
      "|    total_timesteps  | 542978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00902  |\n",
      "|    n_updates        | 110744   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 417      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.461    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1636     |\n",
      "|    fps              | 475      |\n",
      "|    time_elapsed     | 1146     |\n",
      "|    total_timesteps  | 544676   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 111168   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 419      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 475      |\n",
      "|    time_elapsed     | 1150     |\n",
      "|    total_timesteps  | 546520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00396  |\n",
      "|    n_updates        | 111629   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 417      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.458    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1644     |\n",
      "|    fps              | 475      |\n",
      "|    time_elapsed     | 1153     |\n",
      "|    total_timesteps  | 547979   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00979  |\n",
      "|    n_updates        | 111994   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 416      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1648     |\n",
      "|    fps              | 475      |\n",
      "|    time_elapsed     | 1156     |\n",
      "|    total_timesteps  | 549481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 112370   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=-16.20 +/- 2.23\n",
      "Episode length: 535.20 +/- 92.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 535      |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 550000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 112499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 417      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.454    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1652     |\n",
      "|    fps              | 473      |\n",
      "|    time_elapsed     | 1164     |\n",
      "|    total_timesteps  | 551215   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0423   |\n",
      "|    n_updates        | 112803   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 420      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.452    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1656     |\n",
      "|    fps              | 473      |\n",
      "|    time_elapsed     | 1168     |\n",
      "|    total_timesteps  | 553142   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 113285   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 422      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.451    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 473      |\n",
      "|    time_elapsed     | 1172     |\n",
      "|    total_timesteps  | 554826   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 113706   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 424      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.449    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1664     |\n",
      "|    fps              | 473      |\n",
      "|    time_elapsed     | 1175     |\n",
      "|    total_timesteps  | 556461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 114115   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 422      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.448    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1668     |\n",
      "|    fps              | 473      |\n",
      "|    time_elapsed     | 1178     |\n",
      "|    total_timesteps  | 557847   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 114461   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 425      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1672     |\n",
      "|    fps              | 473      |\n",
      "|    time_elapsed     | 1182     |\n",
      "|    total_timesteps  | 559670   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 114917   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-12.40 +/- 6.05\n",
      "Episode length: 507.40 +/- 246.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 507      |\n",
      "|    mean_reward      | -12.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 560000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 114999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 428      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1676     |\n",
      "|    fps              | 471      |\n",
      "|    time_elapsed     | 1190     |\n",
      "|    total_timesteps  | 561581   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 115395   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 425      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1680     |\n",
      "|    fps              | 471      |\n",
      "|    time_elapsed     | 1194     |\n",
      "|    total_timesteps  | 563179   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 115794   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 426      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.441    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1684     |\n",
      "|    fps              | 471      |\n",
      "|    time_elapsed     | 1197     |\n",
      "|    total_timesteps  | 564813   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 116203   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 426      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.439    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1688     |\n",
      "|    fps              | 471      |\n",
      "|    time_elapsed     | 1201     |\n",
      "|    total_timesteps  | 566383   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00496  |\n",
      "|    n_updates        | 116595   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 426      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1692     |\n",
      "|    fps              | 471      |\n",
      "|    time_elapsed     | 1204     |\n",
      "|    total_timesteps  | 567978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 116994   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 428      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.436    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1696     |\n",
      "|    fps              | 471      |\n",
      "|    time_elapsed     | 1208     |\n",
      "|    total_timesteps  | 569690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00837  |\n",
      "|    n_updates        | 117422   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=-13.60 +/- 4.76\n",
      "Episode length: 605.20 +/- 213.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 605      |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.436    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 570000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0338   |\n",
      "|    n_updates        | 117499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 429      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 469      |\n",
      "|    time_elapsed     | 1216     |\n",
      "|    total_timesteps  | 571510   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 117877   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 431      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.432    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1704     |\n",
      "|    fps              | 469      |\n",
      "|    time_elapsed     | 1220     |\n",
      "|    total_timesteps  | 573417   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00801  |\n",
      "|    n_updates        | 118354   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 429      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.431    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1708     |\n",
      "|    fps              | 469      |\n",
      "|    time_elapsed     | 1224     |\n",
      "|    total_timesteps  | 575137   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 118784   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 428      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.429    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1712     |\n",
      "|    fps              | 469      |\n",
      "|    time_elapsed     | 1227     |\n",
      "|    total_timesteps  | 576715   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 119178   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 430      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.427    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1716     |\n",
      "|    fps              | 469      |\n",
      "|    time_elapsed     | 1231     |\n",
      "|    total_timesteps  | 578515   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00733  |\n",
      "|    n_updates        | 119628   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=-15.00 +/- 3.85\n",
      "Episode length: 524.00 +/- 169.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 524      |\n",
      "|    mean_reward      | -15      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 580000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 119999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 430      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.425    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1720     |\n",
      "|    fps              | 468      |\n",
      "|    time_elapsed     | 1239     |\n",
      "|    total_timesteps  | 580363   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00957  |\n",
      "|    n_updates        | 120090   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 427      |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1724     |\n",
      "|    fps              | 468      |\n",
      "|    time_elapsed     | 1242     |\n",
      "|    total_timesteps  | 582153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00437  |\n",
      "|    n_updates        | 120538   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 426      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1728     |\n",
      "|    fps              | 468      |\n",
      "|    time_elapsed     | 1246     |\n",
      "|    total_timesteps  | 583929   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 120982   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 428      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.42     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1732     |\n",
      "|    fps              | 468      |\n",
      "|    time_elapsed     | 1250     |\n",
      "|    total_timesteps  | 585826   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 121456   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 428      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.418    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1736     |\n",
      "|    fps              | 468      |\n",
      "|    time_elapsed     | 1254     |\n",
      "|    total_timesteps  | 587496   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0208   |\n",
      "|    n_updates        | 121873   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 426      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.417    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1740     |\n",
      "|    fps              | 468      |\n",
      "|    time_elapsed     | 1257     |\n",
      "|    total_timesteps  | 589133   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 122283   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=-16.80 +/- 2.93\n",
      "Episode length: 501.40 +/- 90.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 501      |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.416    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 590000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00601  |\n",
      "|    n_updates        | 122499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 429      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1744     |\n",
      "|    fps              | 466      |\n",
      "|    time_elapsed     | 1265     |\n",
      "|    total_timesteps  | 590908   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 122726   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 432      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.413    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1748     |\n",
      "|    fps              | 466      |\n",
      "|    time_elapsed     | 1269     |\n",
      "|    total_timesteps  | 592705   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 123176   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 433      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.411    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1752     |\n",
      "|    fps              | 466      |\n",
      "|    time_elapsed     | 1273     |\n",
      "|    total_timesteps  | 594486   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 123621   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 429      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.41     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1756     |\n",
      "|    fps              | 466      |\n",
      "|    time_elapsed     | 1276     |\n",
      "|    total_timesteps  | 596030   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00817  |\n",
      "|    n_updates        | 124007   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 432      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.408    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1760     |\n",
      "|    fps              | 466      |\n",
      "|    time_elapsed     | 1280     |\n",
      "|    total_timesteps  | 597999   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0279   |\n",
      "|    n_updates        | 124499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 433      |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1764     |\n",
      "|    fps              | 466      |\n",
      "|    time_elapsed     | 1284     |\n",
      "|    total_timesteps  | 599760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 124939   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=-13.60 +/- 3.56\n",
      "Episode length: 544.40 +/- 171.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 544      |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 600000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.033    |\n",
      "|    n_updates        | 124999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 439      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.404    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1768     |\n",
      "|    fps              | 465      |\n",
      "|    time_elapsed     | 1292     |\n",
      "|    total_timesteps  | 601769   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 125442   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 436      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.403    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1772     |\n",
      "|    fps              | 465      |\n",
      "|    time_elapsed     | 1296     |\n",
      "|    total_timesteps  | 603269   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 125817   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 433      |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.401    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1776     |\n",
      "|    fps              | 465      |\n",
      "|    time_elapsed     | 1299     |\n",
      "|    total_timesteps  | 604906   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0243   |\n",
      "|    n_updates        | 126226   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 436      |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1780     |\n",
      "|    fps              | 465      |\n",
      "|    time_elapsed     | 1303     |\n",
      "|    total_timesteps  | 606787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 126696   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 439      |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.397    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1784     |\n",
      "|    fps              | 465      |\n",
      "|    time_elapsed     | 1307     |\n",
      "|    total_timesteps  | 608741   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0268   |\n",
      "|    n_updates        | 127185   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=-13.60 +/- 6.34\n",
      "Episode length: 526.20 +/- 237.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 526      |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.396    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 610000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 127499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 447      |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.395    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1788     |\n",
      "|    fps              | 463      |\n",
      "|    time_elapsed     | 1316     |\n",
      "|    total_timesteps  | 611068   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 127766   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 447      |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.393    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1792     |\n",
      "|    fps              | 463      |\n",
      "|    time_elapsed     | 1320     |\n",
      "|    total_timesteps  | 612683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 128170   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 448      |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1796     |\n",
      "|    fps              | 463      |\n",
      "|    time_elapsed     | 1324     |\n",
      "|    total_timesteps  | 614456   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 128613   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 449      |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.39     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 463      |\n",
      "|    time_elapsed     | 1328     |\n",
      "|    total_timesteps  | 616440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 129109   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 448      |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1804     |\n",
      "|    fps              | 463      |\n",
      "|    time_elapsed     | 1332     |\n",
      "|    total_timesteps  | 618226   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 129556   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 448      |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1808     |\n",
      "|    fps              | 463      |\n",
      "|    time_elapsed     | 1336     |\n",
      "|    total_timesteps  | 619979   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 129994   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=-16.20 +/- 1.60\n",
      "Episode length: 581.40 +/- 8.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 581      |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 620000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00748  |\n",
      "|    n_updates        | 129999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 450      |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.385    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1812     |\n",
      "|    fps              | 462      |\n",
      "|    time_elapsed     | 1344     |\n",
      "|    total_timesteps  | 621715   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0273   |\n",
      "|    n_updates        | 130428   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 450      |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1816     |\n",
      "|    fps              | 462      |\n",
      "|    time_elapsed     | 1348     |\n",
      "|    total_timesteps  | 623518   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 130879   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 449      |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1820     |\n",
      "|    fps              | 462      |\n",
      "|    time_elapsed     | 1352     |\n",
      "|    total_timesteps  | 625311   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 131327   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 453      |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.379    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1824     |\n",
      "|    fps              | 462      |\n",
      "|    time_elapsed     | 1356     |\n",
      "|    total_timesteps  | 627445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 131861   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 451      |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.377    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1828     |\n",
      "|    fps              | 462      |\n",
      "|    time_elapsed     | 1360     |\n",
      "|    total_timesteps  | 629067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00955  |\n",
      "|    n_updates        | 132266   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=-14.80 +/- 3.31\n",
      "Episode length: 649.60 +/- 84.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 650      |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.376    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 630000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 132499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 451      |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.375    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1832     |\n",
      "|    fps              | 460      |\n",
      "|    time_elapsed     | 1369     |\n",
      "|    total_timesteps  | 630956   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 132738   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 452      |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.374    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1836     |\n",
      "|    fps              | 460      |\n",
      "|    time_elapsed     | 1373     |\n",
      "|    total_timesteps  | 632673   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 133168   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 453      |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1840     |\n",
      "|    fps              | 460      |\n",
      "|    time_elapsed     | 1376     |\n",
      "|    total_timesteps  | 634389   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 133597   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 456      |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.37     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1844     |\n",
      "|    fps              | 460      |\n",
      "|    time_elapsed     | 1381     |\n",
      "|    total_timesteps  | 636504   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 134125   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 454      |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.368    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1848     |\n",
      "|    fps              | 460      |\n",
      "|    time_elapsed     | 1384     |\n",
      "|    total_timesteps  | 638137   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 134534   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-13.40 +/- 5.85\n",
      "Episode length: 529.40 +/- 163.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 529      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 640000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00891  |\n",
      "|    n_updates        | 134999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 460      |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1852     |\n",
      "|    fps              | 459      |\n",
      "|    time_elapsed     | 1393     |\n",
      "|    total_timesteps  | 640471   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 135117   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 463      |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.364    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1856     |\n",
      "|    fps              | 459      |\n",
      "|    time_elapsed     | 1398     |\n",
      "|    total_timesteps  | 642379   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 135594   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 463      |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1860     |\n",
      "|    fps              | 459      |\n",
      "|    time_elapsed     | 1402     |\n",
      "|    total_timesteps  | 644266   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 136066   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 464      |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.36     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1864     |\n",
      "|    fps              | 459      |\n",
      "|    time_elapsed     | 1406     |\n",
      "|    total_timesteps  | 646147   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 136536   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 461      |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.359    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1868     |\n",
      "|    fps              | 459      |\n",
      "|    time_elapsed     | 1410     |\n",
      "|    total_timesteps  | 647891   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 136972   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 463      |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1872     |\n",
      "|    fps              | 459      |\n",
      "|    time_elapsed     | 1413     |\n",
      "|    total_timesteps  | 649537   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00877  |\n",
      "|    n_updates        | 137384   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=-15.40 +/- 1.85\n",
      "Episode length: 634.00 +/- 97.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 634      |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 650000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 137499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 465      |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.355    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1876     |\n",
      "|    fps              | 457      |\n",
      "|    time_elapsed     | 1422     |\n",
      "|    total_timesteps  | 651418   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 137854   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 464      |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.353    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1880     |\n",
      "|    fps              | 457      |\n",
      "|    time_elapsed     | 1426     |\n",
      "|    total_timesteps  | 653200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00762  |\n",
      "|    n_updates        | 138299   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 463      |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.351    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1884     |\n",
      "|    fps              | 457      |\n",
      "|    time_elapsed     | 1430     |\n",
      "|    total_timesteps  | 655060   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00905  |\n",
      "|    n_updates        | 138764   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 459      |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1888     |\n",
      "|    fps              | 457      |\n",
      "|    time_elapsed     | 1434     |\n",
      "|    total_timesteps  | 656920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 139229   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 460      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.348    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1892     |\n",
      "|    fps              | 457      |\n",
      "|    time_elapsed     | 1438     |\n",
      "|    total_timesteps  | 658663   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00553  |\n",
      "|    n_updates        | 139665   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=-14.20 +/- 1.47\n",
      "Episode length: 668.40 +/- 91.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 668      |\n",
      "|    mean_reward      | -14.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 660000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 139999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 461      |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1896     |\n",
      "|    fps              | 456      |\n",
      "|    time_elapsed     | 1447     |\n",
      "|    total_timesteps  | 660556   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00496  |\n",
      "|    n_updates        | 140138   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 459      |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.344    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 456      |\n",
      "|    time_elapsed     | 1451     |\n",
      "|    total_timesteps  | 662372   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 140592   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 459      |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.342    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1904     |\n",
      "|    fps              | 456      |\n",
      "|    time_elapsed     | 1455     |\n",
      "|    total_timesteps  | 664152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00517  |\n",
      "|    n_updates        | 141037   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 462      |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.341    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1908     |\n",
      "|    fps              | 456      |\n",
      "|    time_elapsed     | 1459     |\n",
      "|    total_timesteps  | 666161   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 141540   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 464      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.339    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1912     |\n",
      "|    fps              | 456      |\n",
      "|    time_elapsed     | 1463     |\n",
      "|    total_timesteps  | 668072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 142017   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 464      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.337    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1916     |\n",
      "|    fps              | 456      |\n",
      "|    time_elapsed     | 1467     |\n",
      "|    total_timesteps  | 669965   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 142491   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=-14.20 +/- 0.75\n",
      "Episode length: 661.20 +/- 86.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 661      |\n",
      "|    mean_reward      | -14.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.337    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 670000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00914  |\n",
      "|    n_updates        | 142499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 467      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1920     |\n",
      "|    fps              | 454      |\n",
      "|    time_elapsed     | 1477     |\n",
      "|    total_timesteps  | 671976   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 142993   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 466      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.333    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1924     |\n",
      "|    fps              | 454      |\n",
      "|    time_elapsed     | 1481     |\n",
      "|    total_timesteps  | 674015   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 143503   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 468      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1928     |\n",
      "|    fps              | 454      |\n",
      "|    time_elapsed     | 1486     |\n",
      "|    total_timesteps  | 675892   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 143972   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 467      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.329    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1932     |\n",
      "|    fps              | 454      |\n",
      "|    time_elapsed     | 1490     |\n",
      "|    total_timesteps  | 677691   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 144422   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 470      |\n",
      "|    ep_rew_mean      | -18.2    |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1936     |\n",
      "|    fps              | 454      |\n",
      "|    time_elapsed     | 1494     |\n",
      "|    total_timesteps  | 679684   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 144920   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=-12.60 +/- 5.31\n",
      "Episode length: 593.00 +/- 182.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 593      |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 680000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 144999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 475      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.325    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1940     |\n",
      "|    fps              | 453      |\n",
      "|    time_elapsed     | 1503     |\n",
      "|    total_timesteps  | 681873   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 145468   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 473      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.323    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1944     |\n",
      "|    fps              | 453      |\n",
      "|    time_elapsed     | 1507     |\n",
      "|    total_timesteps  | 683793   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 145948   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 477      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.321    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1948     |\n",
      "|    fps              | 453      |\n",
      "|    time_elapsed     | 1512     |\n",
      "|    total_timesteps  | 685824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 146455   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 472      |\n",
      "|    ep_rew_mean      | -18.2    |\n",
      "|    exploration_rate | 0.319    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1952     |\n",
      "|    fps              | 453      |\n",
      "|    time_elapsed     | 1516     |\n",
      "|    total_timesteps  | 687657   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 146914   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 473      |\n",
      "|    ep_rew_mean      | -18.2    |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1956     |\n",
      "|    fps              | 453      |\n",
      "|    time_elapsed     | 1520     |\n",
      "|    total_timesteps  | 689651   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00702  |\n",
      "|    n_updates        | 147412   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=-13.60 +/- 4.50\n",
      "Episode length: 541.00 +/- 155.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 541      |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 690000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 147499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 476      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.315    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1960     |\n",
      "|    fps              | 452      |\n",
      "|    time_elapsed     | 1529     |\n",
      "|    total_timesteps  | 691840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 147959   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 477      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.313    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1964     |\n",
      "|    fps              | 452      |\n",
      "|    time_elapsed     | 1534     |\n",
      "|    total_timesteps  | 693883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00902  |\n",
      "|    n_updates        | 148470   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 477      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1968     |\n",
      "|    fps              | 452      |\n",
      "|    time_elapsed     | 1537     |\n",
      "|    total_timesteps  | 695571   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00629  |\n",
      "|    n_updates        | 148892   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 483      |\n",
      "|    ep_rew_mean      | -18.2    |\n",
      "|    exploration_rate | 0.309    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1972     |\n",
      "|    fps              | 452      |\n",
      "|    time_elapsed     | 1542     |\n",
      "|    total_timesteps  | 697794   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00797  |\n",
      "|    n_updates        | 149448   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 481      |\n",
      "|    ep_rew_mean      | -18.1    |\n",
      "|    exploration_rate | 0.307    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1976     |\n",
      "|    fps              | 452      |\n",
      "|    time_elapsed     | 1546     |\n",
      "|    total_timesteps  | 699507   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0295   |\n",
      "|    n_updates        | 149876   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=-12.20 +/- 6.24\n",
      "Episode length: 495.20 +/- 240.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 495      |\n",
      "|    mean_reward      | -12.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.307    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 700000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 149999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 487      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.305    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1980     |\n",
      "|    fps              | 451      |\n",
      "|    time_elapsed     | 1555     |\n",
      "|    total_timesteps  | 701942   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 150485   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 487      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.303    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1984     |\n",
      "|    fps              | 451      |\n",
      "|    time_elapsed     | 1559     |\n",
      "|    total_timesteps  | 703763   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 150940   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 488      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1988     |\n",
      "|    fps              | 451      |\n",
      "|    time_elapsed     | 1563     |\n",
      "|    total_timesteps  | 705692   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00921  |\n",
      "|    n_updates        | 151422   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 489      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1992     |\n",
      "|    fps              | 451      |\n",
      "|    time_elapsed     | 1567     |\n",
      "|    total_timesteps  | 707578   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 151894   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 488      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.298    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1996     |\n",
      "|    fps              | 451      |\n",
      "|    time_elapsed     | 1571     |\n",
      "|    total_timesteps  | 709331   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00653  |\n",
      "|    n_updates        | 152332   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=-14.60 +/- 2.15\n",
      "Episode length: 556.00 +/- 65.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 556      |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.297    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 710000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 152499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 491      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.296    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 450      |\n",
      "|    time_elapsed     | 1580     |\n",
      "|    total_timesteps  | 711426   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00761  |\n",
      "|    n_updates        | 152856   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 491      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.294    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2004     |\n",
      "|    fps              | 450      |\n",
      "|    time_elapsed     | 1584     |\n",
      "|    total_timesteps  | 713255   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 153313   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 489      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2008     |\n",
      "|    fps              | 450      |\n",
      "|    time_elapsed     | 1588     |\n",
      "|    total_timesteps  | 715089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00992  |\n",
      "|    n_updates        | 153772   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 490      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.29     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2012     |\n",
      "|    fps              | 450      |\n",
      "|    time_elapsed     | 1593     |\n",
      "|    total_timesteps  | 717107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 154276   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 490      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2016     |\n",
      "|    fps              | 450      |\n",
      "|    time_elapsed     | 1597     |\n",
      "|    total_timesteps  | 719010   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 154752   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=720000, episode_reward=-15.20 +/- 4.49\n",
      "Episode length: 590.00 +/- 60.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 590      |\n",
      "|    mean_reward      | -15.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.287    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 720000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 154999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 494      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2020     |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 1606     |\n",
      "|    total_timesteps  | 721343   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 155335   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 492      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.284    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2024     |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 1611     |\n",
      "|    total_timesteps  | 723204   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 155800   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 492      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.282    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2028     |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 1615     |\n",
      "|    total_timesteps  | 725070   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 156267   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 496      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.28     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2032     |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 1620     |\n",
      "|    total_timesteps  | 727329   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 156832   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 494      |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2036     |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 1624     |\n",
      "|    total_timesteps  | 729090   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00855  |\n",
      "|    n_updates        | 157272   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=-13.20 +/- 5.78\n",
      "Episode length: 513.60 +/- 212.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 514      |\n",
      "|    mean_reward      | -13.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.277    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 730000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00686  |\n",
      "|    n_updates        | 157499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 496      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2040     |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 1633     |\n",
      "|    total_timesteps  | 731458   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00813  |\n",
      "|    n_updates        | 157864   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 498      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2044     |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 1638     |\n",
      "|    total_timesteps  | 733637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 158409   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 499      |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.272    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2048     |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 1642     |\n",
      "|    total_timesteps  | 735737   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00946  |\n",
      "|    n_updates        | 158934   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 501      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.27     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2052     |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 1647     |\n",
      "|    total_timesteps  | 737760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 159439   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 501      |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.268    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2056     |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 1651     |\n",
      "|    total_timesteps  | 739753   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 159938   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=-11.60 +/- 3.93\n",
      "Episode length: 668.60 +/- 162.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 669      |\n",
      "|    mean_reward      | -11.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.267    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 740000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00971  |\n",
      "|    n_updates        | 159999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 502      |\n",
      "|    ep_rew_mean      | -18.1    |\n",
      "|    exploration_rate | 0.265    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2060     |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 1662     |\n",
      "|    total_timesteps  | 742076   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 160518   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 503      |\n",
      "|    ep_rew_mean      | -18.1    |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2064     |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 1666     |\n",
      "|    total_timesteps  | 744187   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 161046   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 506      |\n",
      "|    ep_rew_mean      | -18      |\n",
      "|    exploration_rate | 0.261    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2068     |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 1671     |\n",
      "|    total_timesteps  | 746175   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0317   |\n",
      "|    n_updates        | 161543   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 504      |\n",
      "|    ep_rew_mean      | -18.1    |\n",
      "|    exploration_rate | 0.259    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2072     |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 1675     |\n",
      "|    total_timesteps  | 748170   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 162042   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=-11.60 +/- 5.12\n",
      "Episode length: 610.00 +/- 133.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 610      |\n",
      "|    mean_reward      | -11.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.258    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 750000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00656  |\n",
      "|    n_updates        | 162499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 510      |\n",
      "|    ep_rew_mean      | -18.2    |\n",
      "|    exploration_rate | 0.257    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2076     |\n",
      "|    fps              | 445      |\n",
      "|    time_elapsed     | 1685     |\n",
      "|    total_timesteps  | 750523   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 162630   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 506      |\n",
      "|    ep_rew_mean      | -18.1    |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2080     |\n",
      "|    fps              | 445      |\n",
      "|    time_elapsed     | 1690     |\n",
      "|    total_timesteps  | 752542   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 163135   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 507      |\n",
      "|    ep_rew_mean      | -18      |\n",
      "|    exploration_rate | 0.253    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2084     |\n",
      "|    fps              | 445      |\n",
      "|    time_elapsed     | 1694     |\n",
      "|    total_timesteps  | 754484   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 163620   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 508      |\n",
      "|    ep_rew_mean      | -18.1    |\n",
      "|    exploration_rate | 0.251    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2088     |\n",
      "|    fps              | 445      |\n",
      "|    time_elapsed     | 1698     |\n",
      "|    total_timesteps  | 756487   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 164121   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 509      |\n",
      "|    ep_rew_mean      | -18.1    |\n",
      "|    exploration_rate | 0.249    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2092     |\n",
      "|    fps              | 445      |\n",
      "|    time_elapsed     | 1703     |\n",
      "|    total_timesteps  | 758446   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00797  |\n",
      "|    n_updates        | 164611   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=-11.80 +/- 4.71\n",
      "Episode length: 534.60 +/- 249.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 535      |\n",
      "|    mean_reward      | -11.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.248    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 760000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 164999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 517      |\n",
      "|    ep_rew_mean      | -18.1    |\n",
      "|    exploration_rate | 0.247    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2096     |\n",
      "|    fps              | 444      |\n",
      "|    time_elapsed     | 1713     |\n",
      "|    total_timesteps  | 760999   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 165249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 515      |\n",
      "|    ep_rew_mean      | -18.1    |\n",
      "|    exploration_rate | 0.245    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 444      |\n",
      "|    time_elapsed     | 1717     |\n",
      "|    total_timesteps  | 762960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 165739   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 520      |\n",
      "|    ep_rew_mean      | -18      |\n",
      "|    exploration_rate | 0.242    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2104     |\n",
      "|    fps              | 444      |\n",
      "|    time_elapsed     | 1722     |\n",
      "|    total_timesteps  | 765233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 166308   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 524      |\n",
      "|    ep_rew_mean      | -17.9    |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2108     |\n",
      "|    fps              | 444      |\n",
      "|    time_elapsed     | 1727     |\n",
      "|    total_timesteps  | 767461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 166865   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 524      |\n",
      "|    ep_rew_mean      | -17.9    |\n",
      "|    exploration_rate | 0.238    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2112     |\n",
      "|    fps              | 444      |\n",
      "|    time_elapsed     | 1732     |\n",
      "|    total_timesteps  | 769534   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00479  |\n",
      "|    n_updates        | 167383   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=-13.00 +/- 5.18\n",
      "Episode length: 504.40 +/- 192.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 504      |\n",
      "|    mean_reward      | -13      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.238    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 770000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 167499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 530      |\n",
      "|    ep_rew_mean      | -18      |\n",
      "|    exploration_rate | 0.236    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2116     |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 1741     |\n",
      "|    total_timesteps  | 772025   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00655  |\n",
      "|    n_updates        | 168006   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 527      |\n",
      "|    ep_rew_mean      | -17.9    |\n",
      "|    exploration_rate | 0.234    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2120     |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 1745     |\n",
      "|    total_timesteps  | 774083   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 168520   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 531      |\n",
      "|    ep_rew_mean      | -17.8    |\n",
      "|    exploration_rate | 0.231    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2124     |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 1750     |\n",
      "|    total_timesteps  | 776338   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0291   |\n",
      "|    n_updates        | 169084   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 533      |\n",
      "|    ep_rew_mean      | -17.8    |\n",
      "|    exploration_rate | 0.229    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2128     |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 1755     |\n",
      "|    total_timesteps  | 778393   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 169598   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=-16.00 +/- 0.89\n",
      "Episode length: 644.60 +/- 66.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 645      |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.228    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 780000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0295   |\n",
      "|    n_updates        | 169999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 531      |\n",
      "|    ep_rew_mean      | -17.9    |\n",
      "|    exploration_rate | 0.227    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2132     |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 1764     |\n",
      "|    total_timesteps  | 780434   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 170108   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 535      |\n",
      "|    ep_rew_mean      | -17.8    |\n",
      "|    exploration_rate | 0.225    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2136     |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 1769     |\n",
      "|    total_timesteps  | 782635   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 170658   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 534      |\n",
      "|    ep_rew_mean      | -17.6    |\n",
      "|    exploration_rate | 0.223    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2140     |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 1774     |\n",
      "|    total_timesteps  | 784834   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00954  |\n",
      "|    n_updates        | 171208   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 531      |\n",
      "|    ep_rew_mean      | -17.7    |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2144     |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 1778     |\n",
      "|    total_timesteps  | 786741   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00834  |\n",
      "|    n_updates        | 171685   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 533      |\n",
      "|    ep_rew_mean      | -17.7    |\n",
      "|    exploration_rate | 0.219    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2148     |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 1784     |\n",
      "|    total_timesteps  | 789041   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 172260   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=-12.40 +/- 5.35\n",
      "Episode length: 544.60 +/- 253.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 545      |\n",
      "|    mean_reward      | -12.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.218    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 790000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 172499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 539      |\n",
      "|    ep_rew_mean      | -17.8    |\n",
      "|    exploration_rate | 0.216    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2152     |\n",
      "|    fps              | 441      |\n",
      "|    time_elapsed     | 1794     |\n",
      "|    total_timesteps  | 791656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00853  |\n",
      "|    n_updates        | 172913   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 541      |\n",
      "|    ep_rew_mean      | -17.8    |\n",
      "|    exploration_rate | 0.214    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2156     |\n",
      "|    fps              | 441      |\n",
      "|    time_elapsed     | 1799     |\n",
      "|    total_timesteps  | 793900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 173474   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 539      |\n",
      "|    ep_rew_mean      | -17.8    |\n",
      "|    exploration_rate | 0.212    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2160     |\n",
      "|    fps              | 441      |\n",
      "|    time_elapsed     | 1804     |\n",
      "|    total_timesteps  | 795966   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00586  |\n",
      "|    n_updates        | 173991   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 540      |\n",
      "|    ep_rew_mean      | -17.7    |\n",
      "|    exploration_rate | 0.21     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2164     |\n",
      "|    fps              | 441      |\n",
      "|    time_elapsed     | 1809     |\n",
      "|    total_timesteps  | 798211   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 174552   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=-13.40 +/- 3.77\n",
      "Episode length: 569.80 +/- 204.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 570      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.208    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 800000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00827  |\n",
      "|    n_updates        | 174999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 543      |\n",
      "|    ep_rew_mean      | -17.9    |\n",
      "|    exploration_rate | 0.208    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2168     |\n",
      "|    fps              | 440      |\n",
      "|    time_elapsed     | 1818     |\n",
      "|    total_timesteps  | 800497   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 175124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 543      |\n",
      "|    ep_rew_mean      | -17.9    |\n",
      "|    exploration_rate | 0.206    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2172     |\n",
      "|    fps              | 440      |\n",
      "|    time_elapsed     | 1823     |\n",
      "|    total_timesteps  | 802510   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 175627   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 541      |\n",
      "|    ep_rew_mean      | -17.7    |\n",
      "|    exploration_rate | 0.203    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2176     |\n",
      "|    fps              | 440      |\n",
      "|    time_elapsed     | 1828     |\n",
      "|    total_timesteps  | 804672   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00653  |\n",
      "|    n_updates        | 176167   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 545      |\n",
      "|    ep_rew_mean      | -17.6    |\n",
      "|    exploration_rate | 0.201    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2180     |\n",
      "|    fps              | 440      |\n",
      "|    time_elapsed     | 1833     |\n",
      "|    total_timesteps  | 807034   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 176758   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 549      |\n",
      "|    ep_rew_mean      | -17.5    |\n",
      "|    exploration_rate | 0.199    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2184     |\n",
      "|    fps              | 440      |\n",
      "|    time_elapsed     | 1838     |\n",
      "|    total_timesteps  | 809337   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 177334   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=-12.00 +/- 2.61\n",
      "Episode length: 601.00 +/- 183.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 601      |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.198    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 810000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 177499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 553      |\n",
      "|    ep_rew_mean      | -17.5    |\n",
      "|    exploration_rate | 0.196    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2188     |\n",
      "|    fps              | 439      |\n",
      "|    time_elapsed     | 1848     |\n",
      "|    total_timesteps  | 811755   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 177938   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 556      |\n",
      "|    ep_rew_mean      | -17.4    |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2192     |\n",
      "|    fps              | 439      |\n",
      "|    time_elapsed     | 1853     |\n",
      "|    total_timesteps  | 814033   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00567  |\n",
      "|    n_updates        | 178508   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 551      |\n",
      "|    ep_rew_mean      | -17.3    |\n",
      "|    exploration_rate | 0.192    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2196     |\n",
      "|    fps              | 439      |\n",
      "|    time_elapsed     | 1858     |\n",
      "|    total_timesteps  | 816089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0242   |\n",
      "|    n_updates        | 179022   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 551      |\n",
      "|    ep_rew_mean      | -17.4    |\n",
      "|    exploration_rate | 0.19     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 439      |\n",
      "|    time_elapsed     | 1862     |\n",
      "|    total_timesteps  | 818051   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 179512   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=-11.00 +/- 5.10\n",
      "Episode length: 616.00 +/- 293.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 616      |\n",
      "|    mean_reward      | -11      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.188    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 820000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 179999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 552      |\n",
      "|    ep_rew_mean      | -17.6    |\n",
      "|    exploration_rate | 0.188    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2204     |\n",
      "|    fps              | 438      |\n",
      "|    time_elapsed     | 1873     |\n",
      "|    total_timesteps  | 820436   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00815  |\n",
      "|    n_updates        | 180108   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 553      |\n",
      "|    ep_rew_mean      | -17.6    |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2208     |\n",
      "|    fps              | 438      |\n",
      "|    time_elapsed     | 1878     |\n",
      "|    total_timesteps  | 822763   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.032    |\n",
      "|    n_updates        | 180690   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 553      |\n",
      "|    ep_rew_mean      | -17.6    |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2212     |\n",
      "|    fps              | 438      |\n",
      "|    time_elapsed     | 1883     |\n",
      "|    total_timesteps  | 824850   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 181212   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 552      |\n",
      "|    ep_rew_mean      | -17.4    |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2216     |\n",
      "|    fps              | 438      |\n",
      "|    time_elapsed     | 1888     |\n",
      "|    total_timesteps  | 827212   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00762  |\n",
      "|    n_updates        | 181802   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 554      |\n",
      "|    ep_rew_mean      | -17.3    |\n",
      "|    exploration_rate | 0.179    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2220     |\n",
      "|    fps              | 438      |\n",
      "|    time_elapsed     | 1893     |\n",
      "|    total_timesteps  | 829445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 182361   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=-12.00 +/- 2.83\n",
      "Episode length: 649.00 +/- 105.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 649      |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.178    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 830000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 182499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 554      |\n",
      "|    ep_rew_mean      | -17.4    |\n",
      "|    exploration_rate | 0.177    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2224     |\n",
      "|    fps              | 436      |\n",
      "|    time_elapsed     | 1903     |\n",
      "|    total_timesteps  | 831738   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 182934   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 554      |\n",
      "|    ep_rew_mean      | -17.4    |\n",
      "|    exploration_rate | 0.175    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2228     |\n",
      "|    fps              | 436      |\n",
      "|    time_elapsed     | 1908     |\n",
      "|    total_timesteps  | 833782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 183445   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 555      |\n",
      "|    ep_rew_mean      | -17.3    |\n",
      "|    exploration_rate | 0.172    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2232     |\n",
      "|    fps              | 436      |\n",
      "|    time_elapsed     | 1913     |\n",
      "|    total_timesteps  | 835907   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 183976   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 556      |\n",
      "|    ep_rew_mean      | -17.2    |\n",
      "|    exploration_rate | 0.17     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2236     |\n",
      "|    fps              | 436      |\n",
      "|    time_elapsed     | 1918     |\n",
      "|    total_timesteps  | 838211   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 184552   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=-16.00 +/- 2.28\n",
      "Episode length: 579.20 +/- 52.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 579      |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 840000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 184999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 558      |\n",
      "|    ep_rew_mean      | -17.1    |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2240     |\n",
      "|    fps              | 435      |\n",
      "|    time_elapsed     | 1928     |\n",
      "|    total_timesteps  | 840613   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00671  |\n",
      "|    n_updates        | 185153   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 557      |\n",
      "|    ep_rew_mean      | -17.2    |\n",
      "|    exploration_rate | 0.166    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2244     |\n",
      "|    fps              | 435      |\n",
      "|    time_elapsed     | 1933     |\n",
      "|    total_timesteps  | 842437   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 185609   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 556      |\n",
      "|    ep_rew_mean      | -17.1    |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2248     |\n",
      "|    fps              | 435      |\n",
      "|    time_elapsed     | 1938     |\n",
      "|    total_timesteps  | 844679   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.028    |\n",
      "|    n_updates        | 186169   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 552      |\n",
      "|    ep_rew_mean      | -16.9    |\n",
      "|    exploration_rate | 0.162    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2252     |\n",
      "|    fps              | 435      |\n",
      "|    time_elapsed     | 1943     |\n",
      "|    total_timesteps  | 846886   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 186721   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 553      |\n",
      "|    ep_rew_mean      | -16.9    |\n",
      "|    exploration_rate | 0.159    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2256     |\n",
      "|    fps              | 435      |\n",
      "|    time_elapsed     | 1948     |\n",
      "|    total_timesteps  | 849223   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 187305   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=-13.00 +/- 4.34\n",
      "Episode length: 642.80 +/- 70.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 643      |\n",
      "|    mean_reward      | -13      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.159    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 850000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 187499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 557      |\n",
      "|    ep_rew_mean      | -16.9    |\n",
      "|    exploration_rate | 0.157    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2260     |\n",
      "|    fps              | 434      |\n",
      "|    time_elapsed     | 1958     |\n",
      "|    total_timesteps  | 851671   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 187917   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 558      |\n",
      "|    ep_rew_mean      | -16.9    |\n",
      "|    exploration_rate | 0.155    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2264     |\n",
      "|    fps              | 434      |\n",
      "|    time_elapsed     | 1964     |\n",
      "|    total_timesteps  | 853983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 188495   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 560      |\n",
      "|    ep_rew_mean      | -16.7    |\n",
      "|    exploration_rate | 0.152    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2268     |\n",
      "|    fps              | 434      |\n",
      "|    time_elapsed     | 1970     |\n",
      "|    total_timesteps  | 856512   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 189127   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 561      |\n",
      "|    ep_rew_mean      | -16.6    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2272     |\n",
      "|    fps              | 434      |\n",
      "|    time_elapsed     | 1974     |\n",
      "|    total_timesteps  | 858573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 189643   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=-14.80 +/- 3.97\n",
      "Episode length: 583.60 +/- 78.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 584      |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.149    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 860000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 189999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 557      |\n",
      "|    ep_rew_mean      | -16.7    |\n",
      "|    exploration_rate | 0.148    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2276     |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 1983     |\n",
      "|    total_timesteps  | 860404   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 190100   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 555      |\n",
      "|    ep_rew_mean      | -16.8    |\n",
      "|    exploration_rate | 0.146    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2280     |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 1988     |\n",
      "|    total_timesteps  | 862507   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 190626   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 555      |\n",
      "|    ep_rew_mean      | -16.8    |\n",
      "|    exploration_rate | 0.144    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2284     |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 1993     |\n",
      "|    total_timesteps  | 864788   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 191196   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 551      |\n",
      "|    ep_rew_mean      | -16.7    |\n",
      "|    exploration_rate | 0.142    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2288     |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 1997     |\n",
      "|    total_timesteps  | 866887   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00697  |\n",
      "|    n_updates        | 191721   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 551      |\n",
      "|    ep_rew_mean      | -16.7    |\n",
      "|    exploration_rate | 0.14     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2292     |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 2002     |\n",
      "|    total_timesteps  | 869094   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 192273   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=-11.00 +/- 5.22\n",
      "Episode length: 508.00 +/- 244.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 508      |\n",
      "|    mean_reward      | -11      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.139    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 870000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 192499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 556      |\n",
      "|    ep_rew_mean      | -16.9    |\n",
      "|    exploration_rate | 0.137    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2296     |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 2012     |\n",
      "|    total_timesteps  | 871654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 192913   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 558      |\n",
      "|    ep_rew_mean      | -16.8    |\n",
      "|    exploration_rate | 0.135    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 2017     |\n",
      "|    total_timesteps  | 873856   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 193463   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 557      |\n",
      "|    ep_rew_mean      | -16.5    |\n",
      "|    exploration_rate | 0.133    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2304     |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 2022     |\n",
      "|    total_timesteps  | 876111   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 194027   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 558      |\n",
      "|    ep_rew_mean      | -16.5    |\n",
      "|    exploration_rate | 0.13     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2308     |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 2028     |\n",
      "|    total_timesteps  | 878607   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0031   |\n",
      "|    n_updates        | 194651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=-13.60 +/- 3.14\n",
      "Episode length: 553.80 +/- 166.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 554      |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.129    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 880000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 194999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 563      |\n",
      "|    ep_rew_mean      | -16.4    |\n",
      "|    exploration_rate | 0.128    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2312     |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 2038     |\n",
      "|    total_timesteps  | 881143   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 195285   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 562      |\n",
      "|    ep_rew_mean      | -16.5    |\n",
      "|    exploration_rate | 0.125    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2316     |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 2043     |\n",
      "|    total_timesteps  | 883425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 195856   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 567      |\n",
      "|    ep_rew_mean      | -16.4    |\n",
      "|    exploration_rate | 0.123    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2320     |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 2050     |\n",
      "|    total_timesteps  | 886101   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 196525   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 568      |\n",
      "|    ep_rew_mean      | -16.3    |\n",
      "|    exploration_rate | 0.12     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2324     |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 2055     |\n",
      "|    total_timesteps  | 888498   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0318   |\n",
      "|    n_updates        | 197124   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=-12.60 +/- 4.63\n",
      "Episode length: 500.20 +/- 170.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.119    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 890000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 197499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 574      |\n",
      "|    ep_rew_mean      | -16.4    |\n",
      "|    exploration_rate | 0.118    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2328     |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 2065     |\n",
      "|    total_timesteps  | 891145   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0383   |\n",
      "|    n_updates        | 197786   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 574      |\n",
      "|    ep_rew_mean      | -16.4    |\n",
      "|    exploration_rate | 0.116    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2332     |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 2070     |\n",
      "|    total_timesteps  | 893303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00849  |\n",
      "|    n_updates        | 198325   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 577      |\n",
      "|    ep_rew_mean      | -16.4    |\n",
      "|    exploration_rate | 0.113    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2336     |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 2076     |\n",
      "|    total_timesteps  | 895886   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 198971   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 579      |\n",
      "|    ep_rew_mean      | -16.3    |\n",
      "|    exploration_rate | 0.11     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2340     |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 2082     |\n",
      "|    total_timesteps  | 898502   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0328   |\n",
      "|    n_updates        | 199625   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=-13.40 +/- 2.80\n",
      "Episode length: 590.20 +/- 73.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 590      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.109    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 900000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0429   |\n",
      "|    n_updates        | 199999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 587      |\n",
      "|    ep_rew_mean      | -16.1    |\n",
      "|    exploration_rate | 0.108    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2344     |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 2092     |\n",
      "|    total_timesteps  | 901144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 200285   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 586      |\n",
      "|    ep_rew_mean      | -16.2    |\n",
      "|    exploration_rate | 0.106    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2348     |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 2097     |\n",
      "|    total_timesteps  | 903282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 200820   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 588      |\n",
      "|    ep_rew_mean      | -16.2    |\n",
      "|    exploration_rate | 0.103    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2352     |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 2103     |\n",
      "|    total_timesteps  | 905647   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00804  |\n",
      "|    n_updates        | 201411   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 587      |\n",
      "|    ep_rew_mean      | -16.2    |\n",
      "|    exploration_rate | 0.101    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2356     |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 2108     |\n",
      "|    total_timesteps  | 907961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00988  |\n",
      "|    n_updates        | 201990   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=-9.20 +/- 3.92\n",
      "Episode length: 700.60 +/- 119.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 701      |\n",
      "|    mean_reward      | -9.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0991   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 910000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 202499   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 588      |\n",
      "|    ep_rew_mean      | -16.2    |\n",
      "|    exploration_rate | 0.0986   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2360     |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 2119     |\n",
      "|    total_timesteps  | 910459   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00721  |\n",
      "|    n_updates        | 202614   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 587      |\n",
      "|    ep_rew_mean      | -16.1    |\n",
      "|    exploration_rate | 0.0964   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2364     |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 2125     |\n",
      "|    total_timesteps  | 912723   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 203180   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 585      |\n",
      "|    ep_rew_mean      | -16.2    |\n",
      "|    exploration_rate | 0.0941   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2368     |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 2130     |\n",
      "|    total_timesteps  | 915044   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 203760   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 590      |\n",
      "|    ep_rew_mean      | -16.1    |\n",
      "|    exploration_rate | 0.0916   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2372     |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 2136     |\n",
      "|    total_timesteps  | 917530   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00909  |\n",
      "|    n_updates        | 204382   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=-12.40 +/- 5.16\n",
      "Episode length: 616.00 +/- 248.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 616      |\n",
      "|    mean_reward      | -12.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0892   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 920000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 204999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 602      |\n",
      "|    ep_rew_mean      | -16      |\n",
      "|    exploration_rate | 0.0886   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2376     |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 2147     |\n",
      "|    total_timesteps  | 920604   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 205150   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 608      |\n",
      "|    ep_rew_mean      | -15.8    |\n",
      "|    exploration_rate | 0.0859   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2380     |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 2154     |\n",
      "|    total_timesteps  | 923355   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00915  |\n",
      "|    n_updates        | 205838   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 611      |\n",
      "|    ep_rew_mean      | -15.7    |\n",
      "|    exploration_rate | 0.0834   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2384     |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 2160     |\n",
      "|    total_timesteps  | 925847   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 206461   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 615      |\n",
      "|    ep_rew_mean      | -15.7    |\n",
      "|    exploration_rate | 0.0809   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2388     |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 2166     |\n",
      "|    total_timesteps  | 928417   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 207104   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=-12.60 +/- 6.41\n",
      "Episode length: 487.00 +/- 257.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 487      |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0793   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 930000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 207499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 623      |\n",
      "|    ep_rew_mean      | -15.7    |\n",
      "|    exploration_rate | 0.0779   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2392     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 2176     |\n",
      "|    total_timesteps  | 931414   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 207853   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 626      |\n",
      "|    ep_rew_mean      | -15.4    |\n",
      "|    exploration_rate | 0.0751   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2396     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 2183     |\n",
      "|    total_timesteps  | 934208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0378   |\n",
      "|    n_updates        | 208551   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 630      |\n",
      "|    ep_rew_mean      | -15.3    |\n",
      "|    exploration_rate | 0.0725   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 2189     |\n",
      "|    total_timesteps  | 936866   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 209216   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 638      |\n",
      "|    ep_rew_mean      | -15.1    |\n",
      "|    exploration_rate | 0.0695   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2404     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 2196     |\n",
      "|    total_timesteps  | 939869   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 209967   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=-13.60 +/- 2.15\n",
      "Episode length: 673.80 +/- 74.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 674      |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0694   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 940000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 209999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 636      |\n",
      "|    ep_rew_mean      | -15.2    |\n",
      "|    exploration_rate | 0.0672   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2408     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 2206     |\n",
      "|    total_timesteps  | 942244   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 210560   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 641      |\n",
      "|    ep_rew_mean      | -15      |\n",
      "|    exploration_rate | 0.0642   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2412     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 2213     |\n",
      "|    total_timesteps  | 945230   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 211307   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 647      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.0613   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2416     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 2220     |\n",
      "|    total_timesteps  | 948136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0335   |\n",
      "|    n_updates        | 212033   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=-13.20 +/- 5.19\n",
      "Episode length: 520.80 +/- 237.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 521      |\n",
      "|    mean_reward      | -13.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0595   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 950000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 212499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 653      |\n",
      "|    ep_rew_mean      | -15      |\n",
      "|    exploration_rate | 0.0581   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2420     |\n",
      "|    fps              | 426      |\n",
      "|    time_elapsed     | 2231     |\n",
      "|    total_timesteps  | 951448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00456  |\n",
      "|    n_updates        | 212861   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 657      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.0554   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2424     |\n",
      "|    fps              | 426      |\n",
      "|    time_elapsed     | 2238     |\n",
      "|    total_timesteps  | 954190   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 213547   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 655      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.0529   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2428     |\n",
      "|    fps              | 426      |\n",
      "|    time_elapsed     | 2244     |\n",
      "|    total_timesteps  | 956670   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 214167   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 660      |\n",
      "|    ep_rew_mean      | -14.7    |\n",
      "|    exploration_rate | 0.0503   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2432     |\n",
      "|    fps              | 426      |\n",
      "|    time_elapsed     | 2250     |\n",
      "|    total_timesteps  | 959337   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 214834   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=960000, episode_reward=-12.00 +/- 5.40\n",
      "Episode length: 580.80 +/- 248.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 581      |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0496   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 960000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 214999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 668      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.047    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2436     |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 2262     |\n",
      "|    total_timesteps  | 962656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00759  |\n",
      "|    n_updates        | 215663   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 668      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.0444   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2440     |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 2268     |\n",
      "|    total_timesteps  | 965265   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 216316   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 666      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.042    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2444     |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 2274     |\n",
      "|    total_timesteps  | 967716   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 216928   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=-11.20 +/- 4.12\n",
      "Episode length: 599.20 +/- 258.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 599      |\n",
      "|    mean_reward      | -11.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0397   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 970000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00864  |\n",
      "|    n_updates        | 217499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 675      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.0389   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2448     |\n",
      "|    fps              | 424      |\n",
      "|    time_elapsed     | 2286     |\n",
      "|    total_timesteps  | 970790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 217697   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 680      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.0361   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2452     |\n",
      "|    fps              | 424      |\n",
      "|    time_elapsed     | 2292     |\n",
      "|    total_timesteps  | 973626   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 218406   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 682      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.0336   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2456     |\n",
      "|    fps              | 424      |\n",
      "|    time_elapsed     | 2298     |\n",
      "|    total_timesteps  | 976174   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 219043   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 682      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.0311   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2460     |\n",
      "|    fps              | 424      |\n",
      "|    time_elapsed     | 2304     |\n",
      "|    total_timesteps  | 978683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0237   |\n",
      "|    n_updates        | 219670   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=-13.40 +/- 2.58\n",
      "Episode length: 644.80 +/- 81.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 645      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0298   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 980000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 219999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 687      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.0284   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2464     |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 2315     |\n",
      "|    total_timesteps  | 981438   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0408   |\n",
      "|    n_updates        | 220359   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 691      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.0257   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2468     |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 2322     |\n",
      "|    total_timesteps  | 984182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 221045   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 694      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.0229   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2472     |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 2328     |\n",
      "|    total_timesteps  | 986959   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 221739   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 690      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.0203   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2476     |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 2334     |\n",
      "|    total_timesteps  | 989571   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 222392   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=-12.00 +/- 3.79\n",
      "Episode length: 577.40 +/- 225.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 577      |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0199   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 990000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0361   |\n",
      "|    n_updates        | 222499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 690      |\n",
      "|    ep_rew_mean      | -15.1    |\n",
      "|    exploration_rate | 0.0176   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2480     |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 2345     |\n",
      "|    total_timesteps  | 992368   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 223091   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 693      |\n",
      "|    ep_rew_mean      | -15.1    |\n",
      "|    exploration_rate | 0.0149   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2484     |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 2352     |\n",
      "|    total_timesteps  | 995100   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0472   |\n",
      "|    n_updates        | 223774   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 692      |\n",
      "|    ep_rew_mean      | -15.1    |\n",
      "|    exploration_rate | 0.0123   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2488     |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 2358     |\n",
      "|    total_timesteps  | 997648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00508  |\n",
      "|    n_updates        | 224411   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=-12.60 +/- 3.56\n",
      "Episode length: 676.80 +/- 90.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 677      |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00631  |\n",
      "|    n_updates        | 224999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 694      |\n",
      "|    ep_rew_mean      | -15      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2492     |\n",
      "|    fps              | 422      |\n",
      "|    time_elapsed     | 2370     |\n",
      "|    total_timesteps  | 1000847  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00814  |\n",
      "|    n_updates        | 225211   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 692      |\n",
      "|    ep_rew_mean      | -15.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2496     |\n",
      "|    fps              | 422      |\n",
      "|    time_elapsed     | 2376     |\n",
      "|    total_timesteps  | 1003381  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 225845   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 694      |\n",
      "|    ep_rew_mean      | -15.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 422      |\n",
      "|    time_elapsed     | 2383     |\n",
      "|    total_timesteps  | 1006245  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0083   |\n",
      "|    n_updates        | 226561   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 692      |\n",
      "|    ep_rew_mean      | -15.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2504     |\n",
      "|    fps              | 422      |\n",
      "|    time_elapsed     | 2390     |\n",
      "|    total_timesteps  | 1009019  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 227254   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=-13.80 +/- 2.64\n",
      "Episode length: 619.80 +/- 62.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 620      |\n",
      "|    mean_reward      | -13.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0371   |\n",
      "|    n_updates        | 227499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 698      |\n",
      "|    ep_rew_mean      | -15      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2508     |\n",
      "|    fps              | 421      |\n",
      "|    time_elapsed     | 2402     |\n",
      "|    total_timesteps  | 1012035  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 228008   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 696      |\n",
      "|    ep_rew_mean      | -15.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2512     |\n",
      "|    fps              | 421      |\n",
      "|    time_elapsed     | 2408     |\n",
      "|    total_timesteps  | 1014796  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 228698   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 696      |\n",
      "|    ep_rew_mean      | -15.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2516     |\n",
      "|    fps              | 421      |\n",
      "|    time_elapsed     | 2415     |\n",
      "|    total_timesteps  | 1017743  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00841  |\n",
      "|    n_updates        | 229435   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=-15.40 +/- 2.06\n",
      "Episode length: 548.00 +/- 50.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 548      |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0082   |\n",
      "|    n_updates        | 229999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 693      |\n",
      "|    ep_rew_mean      | -15      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2520     |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 2426     |\n",
      "|    total_timesteps  | 1020723  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00968  |\n",
      "|    n_updates        | 230180   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 695      |\n",
      "|    ep_rew_mean      | -15      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2524     |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 2433     |\n",
      "|    total_timesteps  | 1023706  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 230926   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 700      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2528     |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 2440     |\n",
      "|    total_timesteps  | 1026621  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 231655   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 702      |\n",
      "|    ep_rew_mean      | -14.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2532     |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 2446     |\n",
      "|    total_timesteps  | 1029488  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 232371   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1030000, episode_reward=-10.80 +/- 3.31\n",
      "Episode length: 623.60 +/- 273.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 624      |\n",
      "|    mean_reward      | -10.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 232499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 701      |\n",
      "|    ep_rew_mean      | -14.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2536     |\n",
      "|    fps              | 419      |\n",
      "|    time_elapsed     | 2459     |\n",
      "|    total_timesteps  | 1032779  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 233194   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 703      |\n",
      "|    ep_rew_mean      | -14.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2540     |\n",
      "|    fps              | 419      |\n",
      "|    time_elapsed     | 2465     |\n",
      "|    total_timesteps  | 1035576  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 233893   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 710      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2544     |\n",
      "|    fps              | 419      |\n",
      "|    time_elapsed     | 2473     |\n",
      "|    total_timesteps  | 1038738  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 234684   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=-16.40 +/- 3.01\n",
      "Episode length: 509.00 +/- 49.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 509      |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 234999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 718      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2548     |\n",
      "|    fps              | 419      |\n",
      "|    time_elapsed     | 2486     |\n",
      "|    total_timesteps  | 1042621  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 235655   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 715      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2552     |\n",
      "|    fps              | 419      |\n",
      "|    time_elapsed     | 2492     |\n",
      "|    total_timesteps  | 1045150  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 236287   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 713      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2556     |\n",
      "|    fps              | 419      |\n",
      "|    time_elapsed     | 2497     |\n",
      "|    total_timesteps  | 1047512  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 236877   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=-13.40 +/- 4.76\n",
      "Episode length: 636.00 +/- 146.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 636      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 237499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 722      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2560     |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 2510     |\n",
      "|    total_timesteps  | 1050840  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 237709   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 724      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2564     |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 2517     |\n",
      "|    total_timesteps  | 1053861  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 238465   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 720      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2568     |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 2523     |\n",
      "|    total_timesteps  | 1056152  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 239037   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 719      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2572     |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 2529     |\n",
      "|    total_timesteps  | 1058836  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 239708   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=-12.80 +/- 4.26\n",
      "Episode length: 583.20 +/- 238.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 583      |\n",
      "|    mean_reward      | -12.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00801  |\n",
      "|    n_updates        | 239999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 729      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2576     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 2542     |\n",
      "|    total_timesteps  | 1062441  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 240610   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 727      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2580     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 2548     |\n",
      "|    total_timesteps  | 1065092  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 241272   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 724      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2584     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 2553     |\n",
      "|    total_timesteps  | 1067486  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00821  |\n",
      "|    n_updates        | 241871   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1070000, episode_reward=-9.00 +/- 5.33\n",
      "Episode length: 591.20 +/- 290.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 591      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 242499   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 729      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2588     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 2565     |\n",
      "|    total_timesteps  | 1070595  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0095   |\n",
      "|    n_updates        | 242648   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 723      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2592     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 2571     |\n",
      "|    total_timesteps  | 1073116  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 243278   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 725      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2596     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 2577     |\n",
      "|    total_timesteps  | 1075881  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0254   |\n",
      "|    n_updates        | 243970   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 725      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 2584     |\n",
      "|    total_timesteps  | 1078737  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 244684   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=-10.40 +/- 6.09\n",
      "Episode length: 595.80 +/- 308.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 596      |\n",
      "|    mean_reward      | -10.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 244999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 730      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2604     |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 2596     |\n",
      "|    total_timesteps  | 1082010  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 245502   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 730      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2608     |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 2603     |\n",
      "|    total_timesteps  | 1085047  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 246261   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2612     |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 2611     |\n",
      "|    total_timesteps  | 1088097  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 247024   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1090000, episode_reward=-9.60 +/- 5.00\n",
      "Episode length: 666.20 +/- 305.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 666      |\n",
      "|    mean_reward      | -9.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 247499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 735      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2616     |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 2623     |\n",
      "|    total_timesteps  | 1091261  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 247815   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 732      |\n",
      "|    ep_rew_mean      | -14.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2620     |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 2629     |\n",
      "|    total_timesteps  | 1093970  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00762  |\n",
      "|    n_updates        | 248492   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 730      |\n",
      "|    ep_rew_mean      | -14.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2624     |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 2636     |\n",
      "|    total_timesteps  | 1096699  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00604  |\n",
      "|    n_updates        | 249174   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 729      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2628     |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 2643     |\n",
      "|    total_timesteps  | 1099565  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 249891   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=-11.20 +/- 4.26\n",
      "Episode length: 673.40 +/- 274.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 673      |\n",
      "|    mean_reward      | -11.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 249999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2632     |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 2655     |\n",
      "|    total_timesteps  | 1102763  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 250690   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 730      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2636     |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 2662     |\n",
      "|    total_timesteps  | 1105752  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0098   |\n",
      "|    n_updates        | 251437   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2640     |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 2670     |\n",
      "|    total_timesteps  | 1108868  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.028    |\n",
      "|    n_updates        | 252216   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=-13.00 +/- 3.58\n",
      "Episode length: 640.80 +/- 165.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 641      |\n",
      "|    mean_reward      | -13      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 252499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | -14.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2644     |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 2682     |\n",
      "|    total_timesteps  | 1112059  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00847  |\n",
      "|    n_updates        | 253014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 720      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2648     |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 2688     |\n",
      "|    total_timesteps  | 1114586  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 253646   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 723      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2652     |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 2695     |\n",
      "|    total_timesteps  | 1117471  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 254367   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=-10.20 +/- 3.06\n",
      "Episode length: 798.80 +/- 98.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 799      |\n",
      "|    mean_reward      | -10.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00709  |\n",
      "|    n_updates        | 254999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2656     |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 2709     |\n",
      "|    total_timesteps  | 1120790  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 255197   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 729      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2660     |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 2716     |\n",
      "|    total_timesteps  | 1123767  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00824  |\n",
      "|    n_updates        | 255941   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 730      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2664     |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 2723     |\n",
      "|    total_timesteps  | 1126841  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00545  |\n",
      "|    n_updates        | 256710   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 737      |\n",
      "|    ep_rew_mean      | -14.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2668     |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 2730     |\n",
      "|    total_timesteps  | 1129835  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00715  |\n",
      "|    n_updates        | 257458   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1130000, episode_reward=-12.20 +/- 4.02\n",
      "Episode length: 676.20 +/- 120.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 676      |\n",
      "|    mean_reward      | -12.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 257499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 739      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2672     |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 2742     |\n",
      "|    total_timesteps  | 1132725  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 258181   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 729      |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2676     |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 2748     |\n",
      "|    total_timesteps  | 1135341  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 258835   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2680     |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 2755     |\n",
      "|    total_timesteps  | 1138362  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 259590   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1140000, episode_reward=-12.40 +/- 6.09\n",
      "Episode length: 545.60 +/- 245.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 546      |\n",
      "|    mean_reward      | -12.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 259999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 747      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2684     |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 2768     |\n",
      "|    total_timesteps  | 1142219  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 260554   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 744      |\n",
      "|    ep_rew_mean      | -14.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2688     |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 2775     |\n",
      "|    total_timesteps  | 1145031  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 261257   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 745      |\n",
      "|    ep_rew_mean      | -14.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2692     |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 2781     |\n",
      "|    total_timesteps  | 1147623  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 261905   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=-13.60 +/- 1.62\n",
      "Episode length: 654.40 +/- 124.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 654      |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 262499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 748      |\n",
      "|    ep_rew_mean      | -14.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2696     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 2793     |\n",
      "|    total_timesteps  | 1150683  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.031    |\n",
      "|    n_updates        | 262670   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 750      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2700     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 2800     |\n",
      "|    total_timesteps  | 1153763  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00872  |\n",
      "|    n_updates        | 263440   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 745      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2704     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 2807     |\n",
      "|    total_timesteps  | 1156471  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0315   |\n",
      "|    n_updates        | 264117   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 741      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2708     |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 2813     |\n",
      "|    total_timesteps  | 1159158  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 264789   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=-13.80 +/- 3.31\n",
      "Episode length: 590.80 +/- 183.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 591      |\n",
      "|    mean_reward      | -13.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 264999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 740      |\n",
      "|    ep_rew_mean      | -14.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2712     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 2824     |\n",
      "|    total_timesteps  | 1162141  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00772  |\n",
      "|    n_updates        | 265535   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 737      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2716     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 2831     |\n",
      "|    total_timesteps  | 1164938  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 266234   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 739      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2720     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 2838     |\n",
      "|    total_timesteps  | 1167916  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00541  |\n",
      "|    n_updates        | 266978   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1170000, episode_reward=-13.40 +/- 4.22\n",
      "Episode length: 610.80 +/- 118.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 611      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 267499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 747      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2724     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 2850     |\n",
      "|    total_timesteps  | 1171377  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 267844   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 751      |\n",
      "|    ep_rew_mean      | -14.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2728     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 2858     |\n",
      "|    total_timesteps  | 1174621  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0266   |\n",
      "|    n_updates        | 268655   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 750      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2732     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 2866     |\n",
      "|    total_timesteps  | 1177785  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 269446   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=-12.40 +/- 3.44\n",
      "Episode length: 725.80 +/- 114.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 726      |\n",
      "|    mean_reward      | -12.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00807  |\n",
      "|    n_updates        | 269999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 748      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2736     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 2877     |\n",
      "|    total_timesteps  | 1180538  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 270134   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 740      |\n",
      "|    ep_rew_mean      | -14.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2740     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 2883     |\n",
      "|    total_timesteps  | 1182821  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 270705   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 735      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2744     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 2889     |\n",
      "|    total_timesteps  | 1185530  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.007    |\n",
      "|    n_updates        | 271382   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 739      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2748     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 2896     |\n",
      "|    total_timesteps  | 1188439  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00988  |\n",
      "|    n_updates        | 272109   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1190000, episode_reward=-11.20 +/- 6.14\n",
      "Episode length: 712.40 +/- 114.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 712      |\n",
      "|    mean_reward      | -11.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 272499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 739      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2752     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 2909     |\n",
      "|    total_timesteps  | 1191406  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 272851   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 739      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2756     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 2916     |\n",
      "|    total_timesteps  | 1194698  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 273674   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 738      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2760     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 2923     |\n",
      "|    total_timesteps  | 1197539  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0238   |\n",
      "|    n_updates        | 274384   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=-13.40 +/- 3.72\n",
      "Episode length: 679.60 +/- 108.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 680      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0295   |\n",
      "|    n_updates        | 274999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 738      |\n",
      "|    ep_rew_mean      | -14.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2764     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 2935     |\n",
      "|    total_timesteps  | 1200611  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 275152   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 737      |\n",
      "|    ep_rew_mean      | -14.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2768     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 2942     |\n",
      "|    total_timesteps  | 1203520  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0307   |\n",
      "|    n_updates        | 275879   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 736      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2772     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 2948     |\n",
      "|    total_timesteps  | 1206331  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 276582   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 741      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2776     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 2956     |\n",
      "|    total_timesteps  | 1209472  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 277367   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1210000, episode_reward=-13.40 +/- 4.03\n",
      "Episode length: 569.20 +/- 202.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 569      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 277499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 745      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2780     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 2968     |\n",
      "|    total_timesteps  | 1212841  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 278210   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 732      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2784     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 2974     |\n",
      "|    total_timesteps  | 1215451  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 278862   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 740      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2788     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 2982     |\n",
      "|    total_timesteps  | 1219011  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 279752   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=-12.60 +/- 3.50\n",
      "Episode length: 738.20 +/- 37.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 738      |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 279999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 749      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2792     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 2996     |\n",
      "|    total_timesteps  | 1222531  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0341   |\n",
      "|    n_updates        | 280632   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 748      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2796     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 3003     |\n",
      "|    total_timesteps  | 1225458  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00647  |\n",
      "|    n_updates        | 281364   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 748      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2800     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 3010     |\n",
      "|    total_timesteps  | 1228600  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0271   |\n",
      "|    n_updates        | 282149   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=-13.20 +/- 6.49\n",
      "Episode length: 564.40 +/- 188.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 564      |\n",
      "|    mean_reward      | -13.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 282499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 759      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2804     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 3023     |\n",
      "|    total_timesteps  | 1232345  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 283086   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 762      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2808     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 3030     |\n",
      "|    total_timesteps  | 1235333  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0304   |\n",
      "|    n_updates        | 283833   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 763      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2812     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 3038     |\n",
      "|    total_timesteps  | 1238486  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 284621   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=-10.00 +/- 5.18\n",
      "Episode length: 642.40 +/- 314.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 642      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 284999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 774      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2816     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 3052     |\n",
      "|    total_timesteps  | 1242313  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 285578   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 776      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2820     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 3059     |\n",
      "|    total_timesteps  | 1245489  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 286372   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 771      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2824     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 3066     |\n",
      "|    total_timesteps  | 1248431  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00993  |\n",
      "|    n_updates        | 287107   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=-14.60 +/- 3.26\n",
      "Episode length: 605.80 +/- 189.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 606      |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 287499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 767      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2828     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 3077     |\n",
      "|    total_timesteps  | 1251281  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 287820   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 765      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2832     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 3084     |\n",
      "|    total_timesteps  | 1254239  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00652  |\n",
      "|    n_updates        | 288559   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 768      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2836     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 3091     |\n",
      "|    total_timesteps  | 1257338  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00651  |\n",
      "|    n_updates        | 289334   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=-10.80 +/- 4.79\n",
      "Episode length: 682.80 +/- 208.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 683      |\n",
      "|    mean_reward      | -10.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 289999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2840     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 3105     |\n",
      "|    total_timesteps  | 1260763  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 290190   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 783      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2844     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 3112     |\n",
      "|    total_timesteps  | 1263828  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 290956   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 781      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2848     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 3118     |\n",
      "|    total_timesteps  | 1266500  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 291624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 781      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2852     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 3125     |\n",
      "|    total_timesteps  | 1269553  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00759  |\n",
      "|    n_updates        | 292388   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1270000, episode_reward=-14.80 +/- 3.66\n",
      "Episode length: 585.60 +/- 196.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 586      |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 292499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2856     |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 3137     |\n",
      "|    total_timesteps  | 1272588  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 293146   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2860     |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 3144     |\n",
      "|    total_timesteps  | 1275458  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0358   |\n",
      "|    n_updates        | 293864   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2864     |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 3150     |\n",
      "|    total_timesteps  | 1278416  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 294603   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=-13.20 +/- 3.54\n",
      "Episode length: 696.80 +/- 163.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 697      |\n",
      "|    mean_reward      | -13.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 294999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 780      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2868     |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 3163     |\n",
      "|    total_timesteps  | 1281529  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 295382   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 781      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2872     |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 3170     |\n",
      "|    total_timesteps  | 1284389  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 296097   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 780      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2876     |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 3177     |\n",
      "|    total_timesteps  | 1287500  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 296874   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1290000, episode_reward=-13.40 +/- 3.72\n",
      "Episode length: 666.60 +/- 65.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 667      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00889  |\n",
      "|    n_updates        | 297499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 775      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2880     |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 3189     |\n",
      "|    total_timesteps  | 1290390  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00986  |\n",
      "|    n_updates        | 297597   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2884     |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 3196     |\n",
      "|    total_timesteps  | 1293275  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 298318   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 776      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2888     |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 3204     |\n",
      "|    total_timesteps  | 1296618  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 299154   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 773      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2892     |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 3211     |\n",
      "|    total_timesteps  | 1299846  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 299961   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=-12.00 +/- 3.63\n",
      "Episode length: 728.80 +/- 55.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 729      |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00538  |\n",
      "|    n_updates        | 299999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 777      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2896     |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 3225     |\n",
      "|    total_timesteps  | 1303180  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 300794   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 776      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2900     |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 3232     |\n",
      "|    total_timesteps  | 1306157  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 301539   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 769      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2904     |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 3239     |\n",
      "|    total_timesteps  | 1309223  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 302305   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1310000, episode_reward=-11.20 +/- 4.49\n",
      "Episode length: 845.60 +/- 189.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 846      |\n",
      "|    mean_reward      | -11.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0298   |\n",
      "|    n_updates        | 302499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 772      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2908     |\n",
      "|    fps              | 403      |\n",
      "|    time_elapsed     | 3253     |\n",
      "|    total_timesteps  | 1312538  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00662  |\n",
      "|    n_updates        | 303134   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 771      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2912     |\n",
      "|    fps              | 403      |\n",
      "|    time_elapsed     | 3260     |\n",
      "|    total_timesteps  | 1315566  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0327   |\n",
      "|    n_updates        | 303891   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 764      |\n",
      "|    ep_rew_mean      | -13.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2916     |\n",
      "|    fps              | 403      |\n",
      "|    time_elapsed     | 3268     |\n",
      "|    total_timesteps  | 1318672  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00958  |\n",
      "|    n_updates        | 304667   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1320000, episode_reward=-6.80 +/- 2.64\n",
      "Episode length: 773.60 +/- 356.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 774      |\n",
      "|    mean_reward      | -6.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 304999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 765      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2920     |\n",
      "|    fps              | 402      |\n",
      "|    time_elapsed     | 3282     |\n",
      "|    total_timesteps  | 1322013  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 305503   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 767      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2924     |\n",
      "|    fps              | 402      |\n",
      "|    time_elapsed     | 3289     |\n",
      "|    total_timesteps  | 1325160  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 306289   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 768      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2928     |\n",
      "|    fps              | 402      |\n",
      "|    time_elapsed     | 3296     |\n",
      "|    total_timesteps  | 1328078  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 307019   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=-9.20 +/- 3.87\n",
      "Episode length: 651.20 +/- 297.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 651      |\n",
      "|    mean_reward      | -9.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0243   |\n",
      "|    n_updates        | 307499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 774      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2932     |\n",
      "|    fps              | 402      |\n",
      "|    time_elapsed     | 3310     |\n",
      "|    total_timesteps  | 1331626  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 307906   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 774      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2936     |\n",
      "|    fps              | 402      |\n",
      "|    time_elapsed     | 3317     |\n",
      "|    total_timesteps  | 1334760  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00397  |\n",
      "|    n_updates        | 308689   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 770      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2940     |\n",
      "|    fps              | 402      |\n",
      "|    time_elapsed     | 3324     |\n",
      "|    total_timesteps  | 1337737  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 309434   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=-14.60 +/- 1.74\n",
      "Episode length: 677.20 +/- 145.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 677      |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 309999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 769      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2944     |\n",
      "|    fps              | 401      |\n",
      "|    time_elapsed     | 3336     |\n",
      "|    total_timesteps  | 1340774  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0281   |\n",
      "|    n_updates        | 310193   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 768      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2948     |\n",
      "|    fps              | 401      |\n",
      "|    time_elapsed     | 3342     |\n",
      "|    total_timesteps  | 1343299  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 310824   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 769      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2952     |\n",
      "|    fps              | 401      |\n",
      "|    time_elapsed     | 3349     |\n",
      "|    total_timesteps  | 1346498  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 311624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 770      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2956     |\n",
      "|    fps              | 401      |\n",
      "|    time_elapsed     | 3357     |\n",
      "|    total_timesteps  | 1349547  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00846  |\n",
      "|    n_updates        | 312386   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=-10.00 +/- 4.77\n",
      "Episode length: 657.00 +/- 328.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 657      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 312499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 773      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2960     |\n",
      "|    fps              | 401      |\n",
      "|    time_elapsed     | 3369     |\n",
      "|    total_timesteps  | 1352792  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 313197   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 767      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2964     |\n",
      "|    fps              | 401      |\n",
      "|    time_elapsed     | 3375     |\n",
      "|    total_timesteps  | 1355148  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0078   |\n",
      "|    n_updates        | 313786   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 768      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2968     |\n",
      "|    fps              | 401      |\n",
      "|    time_elapsed     | 3382     |\n",
      "|    total_timesteps  | 1358311  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 314577   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=-10.20 +/- 3.97\n",
      "Episode length: 798.20 +/- 151.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 798      |\n",
      "|    mean_reward      | -10.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 314999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 770      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2972     |\n",
      "|    fps              | 400      |\n",
      "|    time_elapsed     | 3396     |\n",
      "|    total_timesteps  | 1361427  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 315356   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 771      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2976     |\n",
      "|    fps              | 400      |\n",
      "|    time_elapsed     | 3403     |\n",
      "|    total_timesteps  | 1364555  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0242   |\n",
      "|    n_updates        | 316138   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2980     |\n",
      "|    fps              | 401      |\n",
      "|    time_elapsed     | 3411     |\n",
      "|    total_timesteps  | 1368216  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.026    |\n",
      "|    n_updates        | 317053   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1370000, episode_reward=-11.20 +/- 2.40\n",
      "Episode length: 791.00 +/- 72.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 791      |\n",
      "|    mean_reward      | -11.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 317499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 783      |\n",
      "|    ep_rew_mean      | -13.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2984     |\n",
      "|    fps              | 400      |\n",
      "|    time_elapsed     | 3425     |\n",
      "|    total_timesteps  | 1371612  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00794  |\n",
      "|    n_updates        | 317902   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2988     |\n",
      "|    fps              | 400      |\n",
      "|    time_elapsed     | 3432     |\n",
      "|    total_timesteps  | 1374449  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0288   |\n",
      "|    n_updates        | 318612   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 780      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2992     |\n",
      "|    fps              | 400      |\n",
      "|    time_elapsed     | 3440     |\n",
      "|    total_timesteps  | 1377814  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 319453   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=-10.20 +/- 5.00\n",
      "Episode length: 723.00 +/- 276.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 723      |\n",
      "|    mean_reward      | -10.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00964  |\n",
      "|    n_updates        | 319999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 781      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2996     |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 3454     |\n",
      "|    total_timesteps  | 1381298  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 320324   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 780      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3000     |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 3460     |\n",
      "|    total_timesteps  | 1384163  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0056   |\n",
      "|    n_updates        | 321040   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 780      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3004     |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 3468     |\n",
      "|    total_timesteps  | 1387183  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 321795   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 774      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3008     |\n",
      "|    fps              | 400      |\n",
      "|    time_elapsed     | 3474     |\n",
      "|    total_timesteps  | 1389921  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 322480   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=-12.40 +/- 5.08\n",
      "Episode length: 901.40 +/- 111.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 901      |\n",
      "|    mean_reward      | -12.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 322499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 776      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3012     |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 3488     |\n",
      "|    total_timesteps  | 1393185  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 323296   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 774      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3016     |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 3495     |\n",
      "|    total_timesteps  | 1396029  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0099   |\n",
      "|    n_updates        | 324007   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 772      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3020     |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 3503     |\n",
      "|    total_timesteps  | 1399228  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 324806   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=-9.00 +/- 5.59\n",
      "Episode length: 704.00 +/- 275.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 704      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 324999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 777      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3024     |\n",
      "|    fps              | 398      |\n",
      "|    time_elapsed     | 3516     |\n",
      "|    total_timesteps  | 1402907  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00789  |\n",
      "|    n_updates        | 325726   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3028     |\n",
      "|    fps              | 398      |\n",
      "|    time_elapsed     | 3523     |\n",
      "|    total_timesteps  | 1405874  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0322   |\n",
      "|    n_updates        | 326468   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 771      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3032     |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 3530     |\n",
      "|    total_timesteps  | 1408749  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 327187   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1410000, episode_reward=-11.40 +/- 4.08\n",
      "Episode length: 715.80 +/- 215.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 716      |\n",
      "|    mean_reward      | -11.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 327499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3036     |\n",
      "|    fps              | 398      |\n",
      "|    time_elapsed     | 3545     |\n",
      "|    total_timesteps  | 1412682  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 328170   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3040     |\n",
      "|    fps              | 398      |\n",
      "|    time_elapsed     | 3552     |\n",
      "|    total_timesteps  | 1415665  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00613  |\n",
      "|    n_updates        | 328916   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3044     |\n",
      "|    fps              | 398      |\n",
      "|    time_elapsed     | 3558     |\n",
      "|    total_timesteps  | 1418564  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 329640   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=-10.60 +/- 4.84\n",
      "Episode length: 693.20 +/- 324.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 693      |\n",
      "|    mean_reward      | -10.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0404   |\n",
      "|    n_updates        | 329999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 788      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3048     |\n",
      "|    fps              | 398      |\n",
      "|    time_elapsed     | 3572     |\n",
      "|    total_timesteps  | 1422127  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 330531   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 782      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3052     |\n",
      "|    fps              | 398      |\n",
      "|    time_elapsed     | 3578     |\n",
      "|    total_timesteps  | 1424747  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 331186   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 781      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3056     |\n",
      "|    fps              | 398      |\n",
      "|    time_elapsed     | 3585     |\n",
      "|    total_timesteps  | 1427690  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 331922   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1430000, episode_reward=-9.00 +/- 6.32\n",
      "Episode length: 734.20 +/- 394.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 734      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 332499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 785      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3060     |\n",
      "|    fps              | 397      |\n",
      "|    time_elapsed     | 3599     |\n",
      "|    total_timesteps  | 1431257  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 332814   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 790      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3064     |\n",
      "|    fps              | 397      |\n",
      "|    time_elapsed     | 3606     |\n",
      "|    total_timesteps  | 1434197  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 333549   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 790      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3068     |\n",
      "|    fps              | 397      |\n",
      "|    time_elapsed     | 3613     |\n",
      "|    total_timesteps  | 1437324  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 334330   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=-13.80 +/- 3.66\n",
      "Episode length: 719.40 +/- 100.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 719      |\n",
      "|    mean_reward      | -13.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00804  |\n",
      "|    n_updates        | 334999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 794      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3072     |\n",
      "|    fps              | 397      |\n",
      "|    time_elapsed     | 3627     |\n",
      "|    total_timesteps  | 1440799  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 335199   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 796      |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3076     |\n",
      "|    fps              | 397      |\n",
      "|    time_elapsed     | 3634     |\n",
      "|    total_timesteps  | 1444138  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 336034   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 790      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3080     |\n",
      "|    fps              | 397      |\n",
      "|    time_elapsed     | 3642     |\n",
      "|    total_timesteps  | 1447266  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 336816   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1450000, episode_reward=-11.80 +/- 3.97\n",
      "Episode length: 665.20 +/- 174.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 665      |\n",
      "|    mean_reward      | -11.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 337499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 793      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3084     |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 3656     |\n",
      "|    total_timesteps  | 1450896  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 337723   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 801      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3088     |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 3664     |\n",
      "|    total_timesteps  | 1454529  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00923  |\n",
      "|    n_updates        | 338632   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 796      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3092     |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 3671     |\n",
      "|    total_timesteps  | 1457456  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 339363   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=-11.40 +/- 2.87\n",
      "Episode length: 822.00 +/- 182.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 822      |\n",
      "|    mean_reward      | -11.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 339999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 793      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3096     |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 3685     |\n",
      "|    total_timesteps  | 1460614  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 340153   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 792      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3100     |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 3691     |\n",
      "|    total_timesteps  | 1463357  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 340839   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 787      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3104     |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 3697     |\n",
      "|    total_timesteps  | 1465861  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 341465   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 792      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3108     |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 3705     |\n",
      "|    total_timesteps  | 1469098  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 342274   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=-10.80 +/- 1.60\n",
      "Episode length: 865.80 +/- 101.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 866      |\n",
      "|    mean_reward      | -10.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00988  |\n",
      "|    n_updates        | 342499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 790      |\n",
      "|    ep_rew_mean      | -14.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3112     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 3718     |\n",
      "|    total_timesteps  | 1472149  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 343037   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 794      |\n",
      "|    ep_rew_mean      | -14.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3116     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 3726     |\n",
      "|    total_timesteps  | 1475399  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0276   |\n",
      "|    n_updates        | 343849   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 796      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3120     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 3734     |\n",
      "|    total_timesteps  | 1478827  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 344706   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1480000, episode_reward=-11.60 +/- 3.01\n",
      "Episode length: 639.80 +/- 174.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 640      |\n",
      "|    mean_reward      | -11.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 344999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 794      |\n",
      "|    ep_rew_mean      | -14.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3124     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 3747     |\n",
      "|    total_timesteps  | 1482295  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 345573   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 791      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3128     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 3754     |\n",
      "|    total_timesteps  | 1485015  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 346253   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 790      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3132     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 3760     |\n",
      "|    total_timesteps  | 1487778  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 346944   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=-13.60 +/- 3.01\n",
      "Episode length: 796.40 +/- 249.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 796      |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0362   |\n",
      "|    n_updates        | 347499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 790      |\n",
      "|    ep_rew_mean      | -14.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3136     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 3775     |\n",
      "|    total_timesteps  | 1491669  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 347917   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 790      |\n",
      "|    ep_rew_mean      | -14.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3140     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 3782     |\n",
      "|    total_timesteps  | 1494681  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 348670   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 792      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3144     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 3789     |\n",
      "|    total_timesteps  | 1497731  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 349432   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1500000, episode_reward=-10.80 +/- 2.79\n",
      "Episode length: 700.20 +/- 227.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 700      |\n",
      "|    mean_reward      | -10.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00495  |\n",
      "|    n_updates        | 349999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 792      |\n",
      "|    ep_rew_mean      | -14.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3148     |\n",
      "|    fps              | 394      |\n",
      "|    time_elapsed     | 3803     |\n",
      "|    total_timesteps  | 1501347  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00904  |\n",
      "|    n_updates        | 350336   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 800      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3152     |\n",
      "|    fps              | 394      |\n",
      "|    time_elapsed     | 3811     |\n",
      "|    total_timesteps  | 1504797  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00614  |\n",
      "|    n_updates        | 351199   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 801      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3156     |\n",
      "|    fps              | 394      |\n",
      "|    time_elapsed     | 3818     |\n",
      "|    total_timesteps  | 1507773  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 351943   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=-10.80 +/- 4.45\n",
      "Episode length: 811.40 +/- 121.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 811      |\n",
      "|    mean_reward      | -10.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 352499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 798      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3160     |\n",
      "|    fps              | 394      |\n",
      "|    time_elapsed     | 3832     |\n",
      "|    total_timesteps  | 1511013  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 352753   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 798      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3164     |\n",
      "|    fps              | 394      |\n",
      "|    time_elapsed     | 3839     |\n",
      "|    total_timesteps  | 1514024  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00894  |\n",
      "|    n_updates        | 353505   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 797      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3168     |\n",
      "|    fps              | 394      |\n",
      "|    time_elapsed     | 3846     |\n",
      "|    total_timesteps  | 1517038  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 354259   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1520000, episode_reward=-13.80 +/- 6.85\n",
      "Episode length: 629.20 +/- 210.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 629      |\n",
      "|    mean_reward      | -13.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00998  |\n",
      "|    n_updates        | 354999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 799      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3172     |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 3859     |\n",
      "|    total_timesteps  | 1520730  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 355182   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 798      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3176     |\n",
      "|    fps              | 394      |\n",
      "|    time_elapsed     | 3867     |\n",
      "|    total_timesteps  | 1523974  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00996  |\n",
      "|    n_updates        | 355993   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 801      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3180     |\n",
      "|    fps              | 394      |\n",
      "|    time_elapsed     | 3875     |\n",
      "|    total_timesteps  | 1527334  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 356833   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=-9.40 +/- 5.54\n",
      "Episode length: 851.80 +/- 312.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 852      |\n",
      "|    mean_reward      | -9.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 357499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 800      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3184     |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 3890     |\n",
      "|    total_timesteps  | 1530875  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00951  |\n",
      "|    n_updates        | 357718   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 795      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3188     |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 3897     |\n",
      "|    total_timesteps  | 1534034  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 358508   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 796      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3192     |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 3904     |\n",
      "|    total_timesteps  | 1537073  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 359268   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=-12.20 +/- 3.37\n",
      "Episode length: 751.00 +/- 178.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 751      |\n",
      "|    mean_reward      | -12.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 359999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 802      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3196     |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 3919     |\n",
      "|    total_timesteps  | 1540771  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00919  |\n",
      "|    n_updates        | 360192   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 805      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3200     |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 3926     |\n",
      "|    total_timesteps  | 1543875  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.027    |\n",
      "|    n_updates        | 360968   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 809      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3204     |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 3933     |\n",
      "|    total_timesteps  | 1546783  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 361695   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1550000, episode_reward=-10.00 +/- 6.39\n",
      "Episode length: 702.00 +/- 323.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 702      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 362499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 816      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3208     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 3947     |\n",
      "|    total_timesteps  | 1550664  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0487   |\n",
      "|    n_updates        | 362665   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 812      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3212     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 3954     |\n",
      "|    total_timesteps  | 1553339  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 363334   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 811      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3216     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 3961     |\n",
      "|    total_timesteps  | 1556463  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 364115   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 803      |\n",
      "|    ep_rew_mean      | -14.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3220     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 3967     |\n",
      "|    total_timesteps  | 1559118  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00879  |\n",
      "|    n_updates        | 364779   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=-11.00 +/- 5.59\n",
      "Episode length: 654.00 +/- 298.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 654      |\n",
      "|    mean_reward      | -11      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00843  |\n",
      "|    n_updates        | 364999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 810      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3224     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 3982     |\n",
      "|    total_timesteps  | 1563279  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00699  |\n",
      "|    n_updates        | 365819   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 811      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3228     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 3989     |\n",
      "|    total_timesteps  | 1566164  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 366540   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 816      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3232     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 3996     |\n",
      "|    total_timesteps  | 1569348  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 367336   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=-12.80 +/- 2.99\n",
      "Episode length: 911.40 +/- 111.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 911      |\n",
      "|    mean_reward      | -12.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0257   |\n",
      "|    n_updates        | 367499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 806      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3236     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 4010     |\n",
      "|    total_timesteps  | 1572313  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 368078   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 812      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3240     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 4018     |\n",
      "|    total_timesteps  | 1575842  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00567  |\n",
      "|    n_updates        | 368960   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 810      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3244     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 4025     |\n",
      "|    total_timesteps  | 1578772  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 369692   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=-13.60 +/- 4.08\n",
      "Episode length: 674.60 +/- 271.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 675      |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00772  |\n",
      "|    n_updates        | 369999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 808      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3248     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4038     |\n",
      "|    total_timesteps  | 1582126  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 370531   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 801      |\n",
      "|    ep_rew_mean      | -14.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3252     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4044     |\n",
      "|    total_timesteps  | 1584946  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 371236   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 802      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3256     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4051     |\n",
      "|    total_timesteps  | 1587986  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 371996   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1590000, episode_reward=-9.00 +/- 5.18\n",
      "Episode length: 707.00 +/- 289.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 707      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 372499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 808      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3260     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4066     |\n",
      "|    total_timesteps  | 1591842  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00427  |\n",
      "|    n_updates        | 372960   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 810      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3264     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4073     |\n",
      "|    total_timesteps  | 1595067  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 373766   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 812      |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3268     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4081     |\n",
      "|    total_timesteps  | 1598273  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 374568   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=-12.60 +/- 5.46\n",
      "Episode length: 581.20 +/- 278.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 581      |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.005    |\n",
      "|    n_updates        | 374999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 817      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3272     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4095     |\n",
      "|    total_timesteps  | 1602474  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00812  |\n",
      "|    n_updates        | 375618   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 819      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3276     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4103     |\n",
      "|    total_timesteps  | 1605829  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00742  |\n",
      "|    n_updates        | 376457   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 815      |\n",
      "|    ep_rew_mean      | -14.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3280     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4110     |\n",
      "|    total_timesteps  | 1608838  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 377209   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=-10.60 +/- 3.50\n",
      "Episode length: 707.60 +/- 230.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 708      |\n",
      "|    mean_reward      | -10.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00948  |\n",
      "|    n_updates        | 377499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 816      |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3284     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 4124     |\n",
      "|    total_timesteps  | 1612427  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 378106   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 817      |\n",
      "|    ep_rew_mean      | -14.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3288     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4132     |\n",
      "|    total_timesteps  | 1615782  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00622  |\n",
      "|    n_updates        | 378945   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 820      |\n",
      "|    ep_rew_mean      | -14.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3292     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 4139     |\n",
      "|    total_timesteps  | 1619090  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 379772   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=-14.00 +/- 3.03\n",
      "Episode length: 684.60 +/- 139.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 685      |\n",
      "|    mean_reward      | -14      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00505  |\n",
      "|    n_updates        | 379999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 813      |\n",
      "|    ep_rew_mean      | -14.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3296     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 4152     |\n",
      "|    total_timesteps  | 1622100  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0265   |\n",
      "|    n_updates        | 380524   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 823      |\n",
      "|    ep_rew_mean      | -14      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3300     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 4161     |\n",
      "|    total_timesteps  | 1626142  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00528  |\n",
      "|    n_updates        | 381535   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 826      |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3304     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 4169     |\n",
      "|    total_timesteps  | 1629350  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00789  |\n",
      "|    n_updates        | 382337   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=-12.80 +/- 4.62\n",
      "Episode length: 639.60 +/- 212.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 640      |\n",
      "|    mean_reward      | -12.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 382499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 823      |\n",
      "|    ep_rew_mean      | -13.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3308     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 4182     |\n",
      "|    total_timesteps  | 1632994  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 383248   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 827      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3312     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 4189     |\n",
      "|    total_timesteps  | 1636075  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 384018   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 830      |\n",
      "|    ep_rew_mean      | -13.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3316     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 4197     |\n",
      "|    total_timesteps  | 1639470  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 384867   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=-9.40 +/- 6.89\n",
      "Episode length: 722.20 +/- 267.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 722      |\n",
      "|    mean_reward      | -9.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00988  |\n",
      "|    n_updates        | 384999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 841      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3320     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 4211     |\n",
      "|    total_timesteps  | 1643183  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 385795   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 833      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3324     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 4219     |\n",
      "|    total_timesteps  | 1646592  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00647  |\n",
      "|    n_updates        | 386647   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 834      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3328     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 4226     |\n",
      "|    total_timesteps  | 1649565  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 387391   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=-10.40 +/- 4.80\n",
      "Episode length: 727.60 +/- 149.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 728      |\n",
      "|    mean_reward      | -10.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 387499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 836      |\n",
      "|    ep_rew_mean      | -13.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3332     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4240     |\n",
      "|    total_timesteps  | 1652994  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 388248   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 836      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3336     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4247     |\n",
      "|    total_timesteps  | 1655883  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 388970   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 832      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3340     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4254     |\n",
      "|    total_timesteps  | 1659071  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0367   |\n",
      "|    n_updates        | 389767   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1660000, episode_reward=-14.80 +/- 1.60\n",
      "Episode length: 767.20 +/- 106.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 767      |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00939  |\n",
      "|    n_updates        | 389999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 837      |\n",
      "|    ep_rew_mean      | -13.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3344     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4268     |\n",
      "|    total_timesteps  | 1662462  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 390615   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 832      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3348     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4274     |\n",
      "|    total_timesteps  | 1665310  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 391327   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 834      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3352     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4282     |\n",
      "|    total_timesteps  | 1668353  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 392088   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1670000, episode_reward=-11.80 +/- 5.46\n",
      "Episode length: 610.60 +/- 305.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 611      |\n",
      "|    mean_reward      | -11.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 392499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 849      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3356     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4297     |\n",
      "|    total_timesteps  | 1672924  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 393230   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 846      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3360     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4305     |\n",
      "|    total_timesteps  | 1676443  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 394110   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 845      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3364     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4313     |\n",
      "|    total_timesteps  | 1679610  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 394902   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1680000, episode_reward=-11.80 +/- 5.19\n",
      "Episode length: 755.00 +/- 192.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 755      |\n",
      "|    mean_reward      | -11.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00447  |\n",
      "|    n_updates        | 394999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 848      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3368     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 4326     |\n",
      "|    total_timesteps  | 1683100  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 395774   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 834      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3372     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4333     |\n",
      "|    total_timesteps  | 1685826  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00936  |\n",
      "|    n_updates        | 396456   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 835      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3376     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 4341     |\n",
      "|    total_timesteps  | 1689367  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 397341   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1690000, episode_reward=-12.00 +/- 4.15\n",
      "Episode length: 581.40 +/- 226.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 581      |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00693  |\n",
      "|    n_updates        | 397499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 843      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3380     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 4354     |\n",
      "|    total_timesteps  | 1693158  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 398289   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 844      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3384     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 4363     |\n",
      "|    total_timesteps  | 1696780  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00847  |\n",
      "|    n_updates        | 399194   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 840      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3388     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 4370     |\n",
      "|    total_timesteps  | 1699815  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 399953   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=-11.40 +/- 4.08\n",
      "Episode length: 769.60 +/- 173.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 770      |\n",
      "|    mean_reward      | -11.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0092   |\n",
      "|    n_updates        | 399999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 847      |\n",
      "|    ep_rew_mean      | -13.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3392     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 4385     |\n",
      "|    total_timesteps  | 1703754  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 400938   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 848      |\n",
      "|    ep_rew_mean      | -13      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3396     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 4392     |\n",
      "|    total_timesteps  | 1706899  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 401724   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 838      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3400     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 4399     |\n",
      "|    total_timesteps  | 1709977  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00814  |\n",
      "|    n_updates        | 402494   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1710000, episode_reward=-12.60 +/- 3.93\n",
      "Episode length: 794.40 +/- 147.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 794      |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0485   |\n",
      "|    n_updates        | 402499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 837      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3404     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 4413     |\n",
      "|    total_timesteps  | 1713044  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 403260   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 833      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3408     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 4420     |\n",
      "|    total_timesteps  | 1716304  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 404075   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 836      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3412     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 4428     |\n",
      "|    total_timesteps  | 1719710  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 404927   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1720000, episode_reward=-13.40 +/- 3.56\n",
      "Episode length: 685.40 +/- 78.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 685      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 404999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 839      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3416     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4442     |\n",
      "|    total_timesteps  | 1723347  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 405836   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 837      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3420     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4450     |\n",
      "|    total_timesteps  | 1726843  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 406710   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1730000, episode_reward=-12.20 +/- 5.95\n",
      "Episode length: 619.00 +/- 312.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 619      |\n",
      "|    mean_reward      | -12.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 407499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 840      |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3424     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4464     |\n",
      "|    total_timesteps  | 1730591  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00691  |\n",
      "|    n_updates        | 407647   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 844      |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3428     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4472     |\n",
      "|    total_timesteps  | 1733962  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 408490   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 843      |\n",
      "|    ep_rew_mean      | -13.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3432     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4480     |\n",
      "|    total_timesteps  | 1737295  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00948  |\n",
      "|    n_updates        | 409323   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1740000, episode_reward=-9.40 +/- 5.24\n",
      "Episode length: 837.40 +/- 194.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 837      |\n",
      "|    mean_reward      | -9.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 409999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 849      |\n",
      "|    ep_rew_mean      | -13.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3436     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4494     |\n",
      "|    total_timesteps  | 1740823  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0331   |\n",
      "|    n_updates        | 410205   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 856      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3440     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4503     |\n",
      "|    total_timesteps  | 1744627  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00759  |\n",
      "|    n_updates        | 411156   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 857      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3444     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4511     |\n",
      "|    total_timesteps  | 1748146  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00633  |\n",
      "|    n_updates        | 412036   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1750000, episode_reward=-13.80 +/- 2.48\n",
      "Episode length: 747.00 +/- 58.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 747      |\n",
      "|    mean_reward      | -13.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0287   |\n",
      "|    n_updates        | 412499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 863      |\n",
      "|    ep_rew_mean      | -13.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3448     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4525     |\n",
      "|    total_timesteps  | 1751616  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.033    |\n",
      "|    n_updates        | 412903   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 870      |\n",
      "|    ep_rew_mean      | -13      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3452     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4533     |\n",
      "|    total_timesteps  | 1755373  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 413843   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 862      |\n",
      "|    ep_rew_mean      | -12.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3456     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 4542     |\n",
      "|    total_timesteps  | 1759172  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 414792   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1760000, episode_reward=-8.80 +/- 3.71\n",
      "Episode length: 734.00 +/- 330.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 734      |\n",
      "|    mean_reward      | -8.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00388  |\n",
      "|    n_updates        | 414999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 862      |\n",
      "|    ep_rew_mean      | -13.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3460     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 4556     |\n",
      "|    total_timesteps  | 1762689  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00838  |\n",
      "|    n_updates        | 415672   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 864      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3464     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 4564     |\n",
      "|    total_timesteps  | 1765969  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 416492   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 862      |\n",
      "|    ep_rew_mean      | -13      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3468     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 4571     |\n",
      "|    total_timesteps  | 1769269  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00846  |\n",
      "|    n_updates        | 417317   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1770000, episode_reward=-9.80 +/- 4.53\n",
      "Episode length: 753.80 +/- 307.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 754      |\n",
      "|    mean_reward      | -9.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0304   |\n",
      "|    n_updates        | 417499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 873      |\n",
      "|    ep_rew_mean      | -13      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3472     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 4586     |\n",
      "|    total_timesteps  | 1773092  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 418272   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 872      |\n",
      "|    ep_rew_mean      | -13.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3476     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 4594     |\n",
      "|    total_timesteps  | 1776536  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0312   |\n",
      "|    n_updates        | 419133   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 866      |\n",
      "|    ep_rew_mean      | -12.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3480     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 4602     |\n",
      "|    total_timesteps  | 1779715  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 419928   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1780000, episode_reward=-11.80 +/- 1.72\n",
      "Episode length: 742.00 +/- 141.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 742      |\n",
      "|    mean_reward      | -11.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 419999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 867      |\n",
      "|    ep_rew_mean      | -13.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3484     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 4616     |\n",
      "|    total_timesteps  | 1783469  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 420867   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 872      |\n",
      "|    ep_rew_mean      | -13      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3488     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 4624     |\n",
      "|    total_timesteps  | 1787012  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 421752   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1790000, episode_reward=-9.80 +/- 3.87\n",
      "Episode length: 843.80 +/- 294.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 844      |\n",
      "|    mean_reward      | -9.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 422499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 871      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3492     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4639     |\n",
      "|    total_timesteps  | 1790850  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 422712   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 873      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3496     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 4647     |\n",
      "|    total_timesteps  | 1794217  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00881  |\n",
      "|    n_updates        | 423554   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 873      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3500     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 4655     |\n",
      "|    total_timesteps  | 1797323  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00794  |\n",
      "|    n_updates        | 424330   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=-13.80 +/- 5.84\n",
      "Episode length: 571.60 +/- 218.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 572      |\n",
      "|    mean_reward      | -13.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 424999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 884      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3504     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4668     |\n",
      "|    total_timesteps  | 1801447  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00733  |\n",
      "|    n_updates        | 425361   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 886      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3508     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4677     |\n",
      "|    total_timesteps  | 1804938  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00822  |\n",
      "|    n_updates        | 426234   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 889      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3512     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4685     |\n",
      "|    total_timesteps  | 1808607  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 427151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1810000, episode_reward=-12.60 +/- 5.39\n",
      "Episode length: 584.60 +/- 297.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 585      |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0223   |\n",
      "|    n_updates        | 427499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 889      |\n",
      "|    ep_rew_mean      | -13.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3516     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4698     |\n",
      "|    total_timesteps  | 1812237  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 428059   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 889      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3520     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4706     |\n",
      "|    total_timesteps  | 1815787  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 428946   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 890      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3524     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4715     |\n",
      "|    total_timesteps  | 1819613  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 429903   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1820000, episode_reward=-6.60 +/- 3.83\n",
      "Episode length: 979.80 +/- 236.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 980      |\n",
      "|    mean_reward      | -6.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 429999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 898      |\n",
      "|    ep_rew_mean      | -13.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3528     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4732     |\n",
      "|    total_timesteps  | 1823723  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 430930   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 897      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3532     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4740     |\n",
      "|    total_timesteps  | 1826993  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00992  |\n",
      "|    n_updates        | 431748   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1830000, episode_reward=-11.60 +/- 5.24\n",
      "Episode length: 729.00 +/- 292.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 729      |\n",
      "|    mean_reward      | -11.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 432499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 906      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3536     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4756     |\n",
      "|    total_timesteps  | 1831389  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 432847   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 904      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3540     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4764     |\n",
      "|    total_timesteps  | 1835013  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00542  |\n",
      "|    n_updates        | 433753   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 906      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3544     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 4773     |\n",
      "|    total_timesteps  | 1838748  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 434686   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=-10.00 +/- 3.85\n",
      "Episode length: 912.80 +/- 172.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 913      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 434999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 912      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3548     |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 4789     |\n",
      "|    total_timesteps  | 1842840  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 435709   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 908      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3552     |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 4797     |\n",
      "|    total_timesteps  | 1846222  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00782  |\n",
      "|    n_updates        | 436555   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 907      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3556     |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 4806     |\n",
      "|    total_timesteps  | 1849837  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00787  |\n",
      "|    n_updates        | 437459   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1850000, episode_reward=-12.80 +/- 4.83\n",
      "Episode length: 768.80 +/- 111.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 769      |\n",
      "|    mean_reward      | -12.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00519  |\n",
      "|    n_updates        | 437499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 911      |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3560     |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 4820     |\n",
      "|    total_timesteps  | 1853757  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0063   |\n",
      "|    n_updates        | 438439   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 916      |\n",
      "|    ep_rew_mean      | -12.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3564     |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 4829     |\n",
      "|    total_timesteps  | 1857562  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 439390   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1860000, episode_reward=-10.00 +/- 3.85\n",
      "Episode length: 854.40 +/- 196.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 854      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 439999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 925      |\n",
      "|    ep_rew_mean      | -12.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3568     |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 4846     |\n",
      "|    total_timesteps  | 1861815  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 440453   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 922      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3572     |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 4854     |\n",
      "|    total_timesteps  | 1865316  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 441328   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 924      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3576     |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 4862     |\n",
      "|    total_timesteps  | 1868963  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 442240   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1870000, episode_reward=-13.00 +/- 3.29\n",
      "Episode length: 912.80 +/- 91.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 913      |\n",
      "|    mean_reward      | -13      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 442499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 924      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3580     |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 4876     |\n",
      "|    total_timesteps  | 1872117  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 443029   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 921      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3584     |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 4885     |\n",
      "|    total_timesteps  | 1875612  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 443902   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 921      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3588     |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 4893     |\n",
      "|    total_timesteps  | 1879095  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 444773   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1880000, episode_reward=-12.20 +/- 5.15\n",
      "Episode length: 910.20 +/- 197.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 910      |\n",
      "|    mean_reward      | -12.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 444999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 918      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3592     |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 4908     |\n",
      "|    total_timesteps  | 1882699  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0235   |\n",
      "|    n_updates        | 445674   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 921      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3596     |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 4917     |\n",
      "|    total_timesteps  | 1886356  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00802  |\n",
      "|    n_updates        | 446588   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 926      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3600     |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 4925     |\n",
      "|    total_timesteps  | 1889968  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00636  |\n",
      "|    n_updates        | 447491   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1890000, episode_reward=-13.40 +/- 3.44\n",
      "Episode length: 845.00 +/- 117.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 845      |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00912  |\n",
      "|    n_updates        | 447499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 919      |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3604     |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 4939     |\n",
      "|    total_timesteps  | 1893306  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00511  |\n",
      "|    n_updates        | 448326   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 913      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3608     |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 4946     |\n",
      "|    total_timesteps  | 1896271  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 449067   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 913      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3612     |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 4955     |\n",
      "|    total_timesteps  | 1899931  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00512  |\n",
      "|    n_updates        | 449982   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1900000, episode_reward=-9.20 +/- 5.27\n",
      "Episode length: 907.00 +/- 162.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 907      |\n",
      "|    mean_reward      | -9.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 449999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 912      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3616     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 4970     |\n",
      "|    total_timesteps  | 1903469  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 450867   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 918      |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3620     |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 4979     |\n",
      "|    total_timesteps  | 1907611  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00684  |\n",
      "|    n_updates        | 451902   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1910000, episode_reward=-12.00 +/- 5.62\n",
      "Episode length: 652.00 +/- 269.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 652      |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0085   |\n",
      "|    n_updates        | 452499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 921      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3624     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 4994     |\n",
      "|    total_timesteps  | 1911701  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.043    |\n",
      "|    n_updates        | 452925   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 916      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3628     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 5002     |\n",
      "|    total_timesteps  | 1915328  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 453831   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 918      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3632     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 5010     |\n",
      "|    total_timesteps  | 1918761  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 454690   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=-10.60 +/- 4.08\n",
      "Episode length: 686.00 +/- 273.70\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 686      |\n",
      "|    mean_reward      | -10.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00541  |\n",
      "|    n_updates        | 454999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 910      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3636     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 5024     |\n",
      "|    total_timesteps  | 1922411  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 455602   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 915      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3640     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 5034     |\n",
      "|    total_timesteps  | 1926464  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00541  |\n",
      "|    n_updates        | 456615   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 910      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3644     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 5041     |\n",
      "|    total_timesteps  | 1929745  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00825  |\n",
      "|    n_updates        | 457436   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1930000, episode_reward=-11.00 +/- 4.60\n",
      "Episode length: 863.40 +/- 193.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 863      |\n",
      "|    mean_reward      | -11      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 457499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 907      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3648     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 5057     |\n",
      "|    total_timesteps  | 1933557  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00861  |\n",
      "|    n_updates        | 458389   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 907      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3652     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 5064     |\n",
      "|    total_timesteps  | 1936874  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00534  |\n",
      "|    n_updates        | 459218   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1940000, episode_reward=-13.00 +/- 2.76\n",
      "Episode length: 798.20 +/- 193.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 798      |\n",
      "|    mean_reward      | -13      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 459999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 914      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3656     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 5081     |\n",
      "|    total_timesteps  | 1941266  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0278   |\n",
      "|    n_updates        | 460316   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 910      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3660     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 5089     |\n",
      "|    total_timesteps  | 1944721  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 461180   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 909      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3664     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 5098     |\n",
      "|    total_timesteps  | 1948458  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 462114   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1950000, episode_reward=-9.80 +/- 1.94\n",
      "Episode length: 806.20 +/- 315.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 806      |\n",
      "|    mean_reward      | -9.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 462499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 909      |\n",
      "|    ep_rew_mean      | -12.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3668     |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 5114     |\n",
      "|    total_timesteps  | 1952714  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 463178   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 913      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3672     |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 5123     |\n",
      "|    total_timesteps  | 1956574  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 464143   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 909      |\n",
      "|    ep_rew_mean      | -12.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3676     |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 5131     |\n",
      "|    total_timesteps  | 1959856  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 464963   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1960000, episode_reward=-7.40 +/- 3.50\n",
      "Episode length: 953.00 +/- 57.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 953      |\n",
      "|    mean_reward      | -7.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 464999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 913      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3680     |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 5146     |\n",
      "|    total_timesteps  | 1963376  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 465843   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 914      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3684     |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 5155     |\n",
      "|    total_timesteps  | 1967015  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 466753   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1970000, episode_reward=-12.00 +/- 4.94\n",
      "Episode length: 815.80 +/- 203.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 816      |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00545  |\n",
      "|    n_updates        | 467499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 918      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3688     |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 5170     |\n",
      "|    total_timesteps  | 1970911  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0296   |\n",
      "|    n_updates        | 467727   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 921      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3692     |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 5179     |\n",
      "|    total_timesteps  | 1974812  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 468702   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 919      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3696     |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 5187     |\n",
      "|    total_timesteps  | 1978219  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 469554   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1980000, episode_reward=-11.80 +/- 3.31\n",
      "Episode length: 997.60 +/- 142.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 998      |\n",
      "|    mean_reward      | -11.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 469999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 916      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3700     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 5202     |\n",
      "|    total_timesteps  | 1981617  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00686  |\n",
      "|    n_updates        | 470404   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 916      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3704     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 5210     |\n",
      "|    total_timesteps  | 1984862  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 471215   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 920      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3708     |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 5218     |\n",
      "|    total_timesteps  | 1988287  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00775  |\n",
      "|    n_updates        | 472071   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1990000, episode_reward=-9.20 +/- 4.12\n",
      "Episode length: 674.60 +/- 336.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 675      |\n",
      "|    mean_reward      | -9.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 472499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 931      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3712     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 5234     |\n",
      "|    total_timesteps  | 1993032  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0324   |\n",
      "|    n_updates        | 473257   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 937      |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3716     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 5244     |\n",
      "|    total_timesteps  | 1997216  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00867  |\n",
      "|    n_updates        | 474303   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2000000, episode_reward=-10.20 +/- 5.27\n",
      "Episode length: 732.60 +/- 364.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 733      |\n",
      "|    mean_reward      | -10.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00721  |\n",
      "|    n_updates        | 474999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 940      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3720     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 5259     |\n",
      "|    total_timesteps  | 2001587  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 475396   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 937      |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3724     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 5268     |\n",
      "|    total_timesteps  | 2005399  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0345   |\n",
      "|    n_updates        | 476349   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 938      |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3728     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 5277     |\n",
      "|    total_timesteps  | 2009086  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0292   |\n",
      "|    n_updates        | 477271   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2010000, episode_reward=-9.40 +/- 4.72\n",
      "Episode length: 1040.20 +/- 228.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | -9.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00984  |\n",
      "|    n_updates        | 477499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 944      |\n",
      "|    ep_rew_mean      | -12.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3732     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 5294     |\n",
      "|    total_timesteps  | 2013198  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00522  |\n",
      "|    n_updates        | 478299   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 945      |\n",
      "|    ep_rew_mean      | -11.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3736     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 5303     |\n",
      "|    total_timesteps  | 2016946  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00276  |\n",
      "|    n_updates        | 479236   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2020000, episode_reward=-8.60 +/- 3.20\n",
      "Episode length: 934.00 +/- 317.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 934      |\n",
      "|    mean_reward      | -8.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00551  |\n",
      "|    n_updates        | 479999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 952      |\n",
      "|    ep_rew_mean      | -11.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3740     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5321     |\n",
      "|    total_timesteps  | 2021706  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00965  |\n",
      "|    n_updates        | 480426   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 956      |\n",
      "|    ep_rew_mean      | -11.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3744     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5330     |\n",
      "|    total_timesteps  | 2025295  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00445  |\n",
      "|    n_updates        | 481323   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 953      |\n",
      "|    ep_rew_mean      | -12      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3748     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 5338     |\n",
      "|    total_timesteps  | 2028832  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00658  |\n",
      "|    n_updates        | 482207   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2030000, episode_reward=-11.40 +/- 6.15\n",
      "Episode length: 752.80 +/- 208.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 753      |\n",
      "|    mean_reward      | -11.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0318   |\n",
      "|    n_updates        | 482499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 960      |\n",
      "|    ep_rew_mean      | -12.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3752     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5353     |\n",
      "|    total_timesteps  | 2032911  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 483227   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 951      |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3756     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5361     |\n",
      "|    total_timesteps  | 2036381  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 484095   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 951      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3760     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5369     |\n",
      "|    total_timesteps  | 2039826  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 484956   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2040000, episode_reward=-12.00 +/- 4.34\n",
      "Episode length: 870.20 +/- 187.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 870      |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 484999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 951      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3764     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5385     |\n",
      "|    total_timesteps  | 2043574  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0296   |\n",
      "|    n_updates        | 485893   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 952      |\n",
      "|    ep_rew_mean      | -12.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3768     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5395     |\n",
      "|    total_timesteps  | 2047953  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 486988   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2050000, episode_reward=-12.60 +/- 6.34\n",
      "Episode length: 717.00 +/- 373.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 717      |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00936  |\n",
      "|    n_updates        | 487499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 962      |\n",
      "|    ep_rew_mean      | -12.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3772     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5412     |\n",
      "|    total_timesteps  | 2052765  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 488191   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 968      |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3776     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5421     |\n",
      "|    total_timesteps  | 2056645  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0267   |\n",
      "|    n_updates        | 489161   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2060000, episode_reward=-13.20 +/- 5.60\n",
      "Episode length: 734.40 +/- 225.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 734      |\n",
      "|    mean_reward      | -13.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00495  |\n",
      "|    n_updates        | 489999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 976      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3780     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5436     |\n",
      "|    total_timesteps  | 2060961  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00876  |\n",
      "|    n_updates        | 490240   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 976      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3784     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5445     |\n",
      "|    total_timesteps  | 2064566  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 491141   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 978      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3788     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 5455     |\n",
      "|    total_timesteps  | 2068759  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 492189   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2070000, episode_reward=-9.60 +/- 6.31\n",
      "Episode length: 886.40 +/- 117.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 886      |\n",
      "|    mean_reward      | -9.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 492499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 980      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3792     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 5471     |\n",
      "|    total_timesteps  | 2072821  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00941  |\n",
      "|    n_updates        | 493205   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 977      |\n",
      "|    ep_rew_mean      | -12.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3796     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 5478     |\n",
      "|    total_timesteps  | 2075909  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00946  |\n",
      "|    n_updates        | 493977   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 980      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3800     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 5487     |\n",
      "|    total_timesteps  | 2079654  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 494913   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2080000, episode_reward=-7.80 +/- 5.64\n",
      "Episode length: 912.00 +/- 194.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 912      |\n",
      "|    mean_reward      | -7.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 494999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 997      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3804     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 5505     |\n",
      "|    total_timesteps  | 2084570  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0238   |\n",
      "|    n_updates        | 496142   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3808     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 5514     |\n",
      "|    total_timesteps  | 2088371  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 497092   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2090000, episode_reward=-8.60 +/- 3.20\n",
      "Episode length: 953.60 +/- 341.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 954      |\n",
      "|    mean_reward      | -8.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 497499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 999      |\n",
      "|    ep_rew_mean      | -12.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3812     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 5532     |\n",
      "|    total_timesteps  | 2092957  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00836  |\n",
      "|    n_updates        | 498239   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 997      |\n",
      "|    ep_rew_mean      | -12.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3816     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 5541     |\n",
      "|    total_timesteps  | 2096897  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.008    |\n",
      "|    n_updates        | 499224   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2100000, episode_reward=-5.80 +/- 5.04\n",
      "Episode length: 997.20 +/- 176.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 997      |\n",
      "|    mean_reward      | -5.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 499999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 993      |\n",
      "|    ep_rew_mean      | -12.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3820     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5558     |\n",
      "|    total_timesteps  | 2100931  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 500232   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 997      |\n",
      "|    ep_rew_mean      | -12      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3824     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 5567     |\n",
      "|    total_timesteps  | 2105073  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 501268   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 998      |\n",
      "|    ep_rew_mean      | -12.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3828     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 5576     |\n",
      "|    total_timesteps  | 2108884  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00389  |\n",
      "|    n_updates        | 502220   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2110000, episode_reward=-6.60 +/- 4.50\n",
      "Episode length: 939.60 +/- 442.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 940      |\n",
      "|    mean_reward      | -6.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00625  |\n",
      "|    n_updates        | 502499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | -12.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3832     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5596     |\n",
      "|    total_timesteps  | 2114307  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00684  |\n",
      "|    n_updates        | 503576   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.02e+03 |\n",
      "|    ep_rew_mean      | -11.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3836     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5606     |\n",
      "|    total_timesteps  | 2118641  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 504660   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2120000, episode_reward=-11.00 +/- 5.80\n",
      "Episode length: 858.60 +/- 162.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 859      |\n",
      "|    mean_reward      | -11      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00559  |\n",
      "|    n_updates        | 504999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | -12      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3840     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5622     |\n",
      "|    total_timesteps  | 2122697  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 505674   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | -12      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3844     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5630     |\n",
      "|    total_timesteps  | 2126273  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 506568   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | -11.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3848     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5638     |\n",
      "|    total_timesteps  | 2129818  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 507454   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2130000, episode_reward=-9.80 +/- 2.04\n",
      "Episode length: 988.60 +/- 76.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 989      |\n",
      "|    mean_reward      | -9.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 507499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | -11.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3852     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5655     |\n",
      "|    total_timesteps  | 2133614  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0072   |\n",
      "|    n_updates        | 508403   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | -11.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3856     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5662     |\n",
      "|    total_timesteps  | 2136927  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00655  |\n",
      "|    n_updates        | 509231   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2140000, episode_reward=-12.00 +/- 3.22\n",
      "Episode length: 822.40 +/- 211.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 822      |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 509999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | -11.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3860     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5678     |\n",
      "|    total_timesteps  | 2141006  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 510251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | -11.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3864     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5686     |\n",
      "|    total_timesteps  | 2144548  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0262   |\n",
      "|    n_updates        | 511136   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -12.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3868     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 5696     |\n",
      "|    total_timesteps  | 2148377  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00608  |\n",
      "|    n_updates        | 512094   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2150000, episode_reward=-11.00 +/- 1.67\n",
      "Episode length: 858.60 +/- 245.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 859      |\n",
      "|    mean_reward      | -11      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00682  |\n",
      "|    n_updates        | 512499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 998      |\n",
      "|    ep_rew_mean      | -11.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3872     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 5712     |\n",
      "|    total_timesteps  | 2152581  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 513145   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 996      |\n",
      "|    ep_rew_mean      | -11.8    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3876     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 5720     |\n",
      "|    total_timesteps  | 2156269  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 514067   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 990      |\n",
      "|    ep_rew_mean      | -11.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3880     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 5729     |\n",
      "|    total_timesteps  | 2159936  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 514983   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2160000, episode_reward=-7.80 +/- 3.66\n",
      "Episode length: 987.40 +/- 265.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 987      |\n",
      "|    mean_reward      | -7.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0293   |\n",
      "|    n_updates        | 514999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 992      |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3884     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 5745     |\n",
      "|    total_timesteps  | 2163778  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 515944   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 984      |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3888     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 5753     |\n",
      "|    total_timesteps  | 2167130  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00901  |\n",
      "|    n_updates        | 516782   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2170000, episode_reward=-8.60 +/- 5.75\n",
      "Episode length: 996.60 +/- 208.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 997      |\n",
      "|    mean_reward      | -8.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00662  |\n",
      "|    n_updates        | 517499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 980      |\n",
      "|    ep_rew_mean      | -11.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3892     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 5769     |\n",
      "|    total_timesteps  | 2170822  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 517705   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 994      |\n",
      "|    ep_rew_mean      | -11.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3896     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 5780     |\n",
      "|    total_timesteps  | 2175339  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00808  |\n",
      "|    n_updates        | 518834   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 996      |\n",
      "|    ep_rew_mean      | -11.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3900     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 5789     |\n",
      "|    total_timesteps  | 2179237  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 519809   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2180000, episode_reward=-10.20 +/- 3.71\n",
      "Episode length: 713.20 +/- 306.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 713      |\n",
      "|    mean_reward      | -10.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 519999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 988      |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3904     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 5804     |\n",
      "|    total_timesteps  | 2183349  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 520837   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 986      |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3908     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 5812     |\n",
      "|    total_timesteps  | 2186952  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 521737   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2190000, episode_reward=-7.80 +/- 3.87\n",
      "Episode length: 1013.20 +/- 254.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | -7.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00802  |\n",
      "|    n_updates        | 522499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 977      |\n",
      "|    ep_rew_mean      | -11.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3912     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5828     |\n",
      "|    total_timesteps  | 2190684  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00543  |\n",
      "|    n_updates        | 522670   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 976      |\n",
      "|    ep_rew_mean      | -11.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3916     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5838     |\n",
      "|    total_timesteps  | 2194536  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 523633   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 975      |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3920     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5847     |\n",
      "|    total_timesteps  | 2198418  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00708  |\n",
      "|    n_updates        | 524604   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2200000, episode_reward=-8.40 +/- 2.15\n",
      "Episode length: 899.60 +/- 298.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 900      |\n",
      "|    mean_reward      | -8.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00998  |\n",
      "|    n_updates        | 524999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 975      |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3924     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5863     |\n",
      "|    total_timesteps  | 2202548  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00844  |\n",
      "|    n_updates        | 525636   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 976      |\n",
      "|    ep_rew_mean      | -11.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3928     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5872     |\n",
      "|    total_timesteps  | 2206511  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 526627   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2210000, episode_reward=-11.20 +/- 4.31\n",
      "Episode length: 914.20 +/- 273.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 914      |\n",
      "|    mean_reward      | -11.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00623  |\n",
      "|    n_updates        | 527499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 967      |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3932     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5890     |\n",
      "|    total_timesteps  | 2211034  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00989  |\n",
      "|    n_updates        | 527758   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 957      |\n",
      "|    ep_rew_mean      | -11.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3936     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5897     |\n",
      "|    total_timesteps  | 2214353  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 528588   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 956      |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3940     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5907     |\n",
      "|    total_timesteps  | 2218317  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 529579   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2220000, episode_reward=-8.40 +/- 3.93\n",
      "Episode length: 1003.60 +/- 111.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -8.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 529999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 968      |\n",
      "|    ep_rew_mean      | -11.4    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3944     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5925     |\n",
      "|    total_timesteps  | 2223069  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00785  |\n",
      "|    n_updates        | 530767   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 972      |\n",
      "|    ep_rew_mean      | -11.2    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3948     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5935     |\n",
      "|    total_timesteps  | 2227025  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00665  |\n",
      "|    n_updates        | 531756   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2230000, episode_reward=-7.20 +/- 4.12\n",
      "Episode length: 786.80 +/- 377.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 787      |\n",
      "|    mean_reward      | -7.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 532499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 981      |\n",
      "|    ep_rew_mean      | -11.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3952     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 5951     |\n",
      "|    total_timesteps  | 2231731  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 532932   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 987      |\n",
      "|    ep_rew_mean      | -10.9    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3956     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5960     |\n",
      "|    total_timesteps  | 2235600  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0044   |\n",
      "|    n_updates        | 533899   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 986      |\n",
      "|    ep_rew_mean      | -10.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3960     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 5970     |\n",
      "|    total_timesteps  | 2239582  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 534895   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2240000, episode_reward=-10.40 +/- 5.16\n",
      "Episode length: 886.40 +/- 104.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 886      |\n",
      "|    mean_reward      | -10.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00704  |\n",
      "|    n_updates        | 534999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 990      |\n",
      "|    ep_rew_mean      | -10.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3964     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 5986     |\n",
      "|    total_timesteps  | 2243581  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 535895   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 989      |\n",
      "|    ep_rew_mean      | -10.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3968     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 5995     |\n",
      "|    total_timesteps  | 2247280  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 536819   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2250000, episode_reward=-5.80 +/- 3.60\n",
      "Episode length: 1070.80 +/- 139.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -5.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 537499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 981      |\n",
      "|    ep_rew_mean      | -10.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3972     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 6011     |\n",
      "|    total_timesteps  | 2250701  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 537675   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 981      |\n",
      "|    ep_rew_mean      | -10.7    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3976     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 6019     |\n",
      "|    total_timesteps  | 2254388  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 538596   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 985      |\n",
      "|    ep_rew_mean      | -10.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3980     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 6029     |\n",
      "|    total_timesteps  | 2258473  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00699  |\n",
      "|    n_updates        | 539618   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2260000, episode_reward=-11.40 +/- 5.20\n",
      "Episode length: 717.20 +/- 232.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 717      |\n",
      "|    mean_reward      | -11.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00674  |\n",
      "|    n_updates        | 539999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 992      |\n",
      "|    ep_rew_mean      | -10.6    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3984     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 6045     |\n",
      "|    total_timesteps  | 2262944  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0087   |\n",
      "|    n_updates        | 540735   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 997      |\n",
      "|    ep_rew_mean      | -10.5    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3988     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 6054     |\n",
      "|    total_timesteps  | 2266800  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 541699   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2270000, episode_reward=-7.60 +/- 3.38\n",
      "Episode length: 962.80 +/- 173.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 963      |\n",
      "|    mean_reward      | -7.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 542499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -10.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3992     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 6071     |\n",
      "|    total_timesteps  | 2271055  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 542763   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 998      |\n",
      "|    ep_rew_mean      | -10.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3996     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 6081     |\n",
      "|    total_timesteps  | 2275121  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00864  |\n",
      "|    n_updates        | 543780   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -10.3    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4000     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 6091     |\n",
      "|    total_timesteps  | 2279463  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 544865   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2280000, episode_reward=-9.00 +/- 3.03\n",
      "Episode length: 824.80 +/- 305.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 825      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 544999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | -10.1    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4004     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6107     |\n",
      "|    total_timesteps  | 2283930  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 545982   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | -9.92    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4008     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 6117     |\n",
      "|    total_timesteps  | 2288032  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0312   |\n",
      "|    n_updates        | 547007   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2290000, episode_reward=-3.00 +/- 3.74\n",
      "Episode length: 936.40 +/- 411.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 936      |\n",
      "|    mean_reward      | -3       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 547499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.02e+03 |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4012     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6135     |\n",
      "|    total_timesteps  | 2292984  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 548245   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.03e+03 |\n",
      "|    ep_rew_mean      | -9.69    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4016     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6146     |\n",
      "|    total_timesteps  | 2297671  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 549417   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2300000, episode_reward=-7.60 +/- 3.93\n",
      "Episode length: 922.00 +/- 167.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 922      |\n",
      "|    mean_reward      | -7.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00844  |\n",
      "|    n_updates        | 549999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.03e+03 |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4020     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6163     |\n",
      "|    total_timesteps  | 2301866  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 550466   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.03e+03 |\n",
      "|    ep_rew_mean      | -9.91    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4024     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6171     |\n",
      "|    total_timesteps  | 2305251  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00843  |\n",
      "|    n_updates        | 551312   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.03e+03 |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4028     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6181     |\n",
      "|    total_timesteps  | 2309548  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 552386   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2310000, episode_reward=-10.40 +/- 3.44\n",
      "Episode length: 916.80 +/- 188.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 917      |\n",
      "|    mean_reward      | -10.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 552499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.04e+03 |\n",
      "|    ep_rew_mean      | -9.5     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4032     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6200     |\n",
      "|    total_timesteps  | 2314876  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 553718   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.04e+03 |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4036     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6209     |\n",
      "|    total_timesteps  | 2318718  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 554679   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2320000, episode_reward=-4.60 +/- 6.62\n",
      "Episode length: 887.00 +/- 358.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 887      |\n",
      "|    mean_reward      | -4.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00761  |\n",
      "|    n_updates        | 554999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.05e+03 |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4040     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6227     |\n",
      "|    total_timesteps  | 2323417  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 555854   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.05e+03 |\n",
      "|    ep_rew_mean      | -9.22    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4044     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6237     |\n",
      "|    total_timesteps  | 2327832  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00831  |\n",
      "|    n_updates        | 556957   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2330000, episode_reward=-9.40 +/- 4.32\n",
      "Episode length: 724.00 +/- 368.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 724      |\n",
      "|    mean_reward      | -9.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 557499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.06e+03 |\n",
      "|    ep_rew_mean      | -9.22    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4048     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6255     |\n",
      "|    total_timesteps  | 2333168  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 558291   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.06e+03 |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4052     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 6265     |\n",
      "|    total_timesteps  | 2337489  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 559372   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2340000, episode_reward=-11.40 +/- 3.38\n",
      "Episode length: 910.80 +/- 78.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 911      |\n",
      "|    mean_reward      | -11.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 559999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.05e+03 |\n",
      "|    ep_rew_mean      | -9.26    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4056     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6279     |\n",
      "|    total_timesteps  | 2340816  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 560203   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.05e+03 |\n",
      "|    ep_rew_mean      | -9.43    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4060     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6289     |\n",
      "|    total_timesteps  | 2344984  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 561245   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.06e+03 |\n",
      "|    ep_rew_mean      | -9.38    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4064     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6299     |\n",
      "|    total_timesteps  | 2349142  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 562285   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2350000, episode_reward=-4.20 +/- 5.49\n",
      "Episode length: 963.00 +/- 401.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 963      |\n",
      "|    mean_reward      | -4.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 562499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.07e+03 |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4068     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6319     |\n",
      "|    total_timesteps  | 2354470  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 563617   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -9.17    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4072     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6328     |\n",
      "|    total_timesteps  | 2358285  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 564571   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2360000, episode_reward=-4.20 +/- 3.43\n",
      "Episode length: 1049.40 +/- 315.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | -4.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00871  |\n",
      "|    n_updates        | 564999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -9.15    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4076     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6345     |\n",
      "|    total_timesteps  | 2362559  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 565639   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4080     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6355     |\n",
      "|    total_timesteps  | 2366709  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00897  |\n",
      "|    n_updates        | 566677   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2370000, episode_reward=-5.80 +/- 2.23\n",
      "Episode length: 1110.80 +/- 60.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -5.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00702  |\n",
      "|    n_updates        | 567499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4084     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6373     |\n",
      "|    total_timesteps  | 2371113  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 567778   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4088     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6384     |\n",
      "|    total_timesteps  | 2375465  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 568866   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.82    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4092     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 6392     |\n",
      "|    total_timesteps  | 2379125  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 569781   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2380000, episode_reward=-2.60 +/- 8.11\n",
      "Episode length: 816.20 +/- 405.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 816      |\n",
      "|    mean_reward      | -2.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 569999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4096     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 6411     |\n",
      "|    total_timesteps  | 2384456  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 571113   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4100     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 6420     |\n",
      "|    total_timesteps  | 2388214  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 572053   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2390000, episode_reward=-5.80 +/- 7.22\n",
      "Episode length: 878.20 +/- 257.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 878      |\n",
      "|    mean_reward      | -5.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 572499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.8     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4104     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 6437     |\n",
      "|    total_timesteps  | 2392922  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00844  |\n",
      "|    n_updates        | 573230   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.1e+03  |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4108     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 6448     |\n",
      "|    total_timesteps  | 2397545  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0095   |\n",
      "|    n_updates        | 574386   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=-3.80 +/- 4.96\n",
      "Episode length: 1117.80 +/- 167.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -3.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 574999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.45    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4112     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 6468     |\n",
      "|    total_timesteps  | 2402378  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0238   |\n",
      "|    n_updates        | 575594   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.5     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4116     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 6477     |\n",
      "|    total_timesteps  | 2406403  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 576600   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2410000, episode_reward=-7.00 +/- 4.15\n",
      "Episode length: 864.80 +/- 423.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 865      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 577499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.1e+03  |\n",
      "|    ep_rew_mean      | -8.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4120     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 6497     |\n",
      "|    total_timesteps  | 2412224  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 578055   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.11e+03 |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4124     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 6508     |\n",
      "|    total_timesteps  | 2416588  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00925  |\n",
      "|    n_updates        | 579146   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2420000, episode_reward=-8.80 +/- 4.40\n",
      "Episode length: 937.20 +/- 166.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 937      |\n",
      "|    mean_reward      | -8.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 579999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.11e+03 |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4128     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6525     |\n",
      "|    total_timesteps  | 2420872  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0488   |\n",
      "|    n_updates        | 580217   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.1e+03  |\n",
      "|    ep_rew_mean      | -8.59    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4132     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 6534     |\n",
      "|    total_timesteps  | 2424622  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00703  |\n",
      "|    n_updates        | 581155   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.1e+03  |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4136     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 6543     |\n",
      "|    total_timesteps  | 2428655  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00742  |\n",
      "|    n_updates        | 582163   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2430000, episode_reward=-4.40 +/- 5.16\n",
      "Episode length: 1061.60 +/- 125.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -4.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 582499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.59    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4140     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6559     |\n",
      "|    total_timesteps  | 2432255  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00807  |\n",
      "|    n_updates        | 583063   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4144     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6569     |\n",
      "|    total_timesteps  | 2436287  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00738  |\n",
      "|    n_updates        | 584071   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2440000, episode_reward=-4.00 +/- 2.83\n",
      "Episode length: 1092.80 +/- 281.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | -4       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 584999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4148     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6588     |\n",
      "|    total_timesteps  | 2441111  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 585277   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4152     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6598     |\n",
      "|    total_timesteps  | 2445144  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00801  |\n",
      "|    n_updates        | 586285   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.4     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4156     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6608     |\n",
      "|    total_timesteps  | 2449608  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00649  |\n",
      "|    n_updates        | 587401   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2450000, episode_reward=-5.20 +/- 6.01\n",
      "Episode length: 1040.20 +/- 232.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | -5.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00396  |\n",
      "|    n_updates        | 587499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.43    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4160     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6626     |\n",
      "|    total_timesteps  | 2454021  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00653  |\n",
      "|    n_updates        | 588505   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4164     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6635     |\n",
      "|    total_timesteps  | 2458048  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 589511   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2460000, episode_reward=-6.20 +/- 2.32\n",
      "Episode length: 1009.40 +/- 259.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | -6.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 589999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4168     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6655     |\n",
      "|    total_timesteps  | 2463117  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0096   |\n",
      "|    n_updates        | 590779   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.3     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4172     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6665     |\n",
      "|    total_timesteps  | 2467455  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00915  |\n",
      "|    n_updates        | 591863   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2470000, episode_reward=-8.40 +/- 4.72\n",
      "Episode length: 1004.00 +/- 264.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -8.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 592499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4176     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6682     |\n",
      "|    total_timesteps  | 2471726  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 592931   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.51    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4180     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6691     |\n",
      "|    total_timesteps  | 2475594  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00551  |\n",
      "|    n_updates        | 593898   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.41    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4184     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 6701     |\n",
      "|    total_timesteps  | 2479841  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00767  |\n",
      "|    n_updates        | 594960   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2480000, episode_reward=-5.60 +/- 4.08\n",
      "Episode length: 974.80 +/- 110.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 975      |\n",
      "|    mean_reward      | -5.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 594999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.55    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4188     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6719     |\n",
      "|    total_timesteps  | 2484345  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00679  |\n",
      "|    n_updates        | 596086   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.1e+03  |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4192     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6729     |\n",
      "|    total_timesteps  | 2488647  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 597161   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2490000, episode_reward=-0.40 +/- 4.96\n",
      "Episode length: 1143.00 +/- 105.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 597499   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4196     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6748     |\n",
      "|    total_timesteps  | 2493297  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 598324   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.1e+03  |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4200     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6759     |\n",
      "|    total_timesteps  | 2497906  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 599476   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2500000, episode_reward=-8.80 +/- 5.34\n",
      "Episode length: 863.00 +/- 309.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 863      |\n",
      "|    mean_reward      | -8.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 599999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4204     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6775     |\n",
      "|    total_timesteps  | 2502068  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00379  |\n",
      "|    n_updates        | 600516   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4208     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6786     |\n",
      "|    total_timesteps  | 2506522  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00533  |\n",
      "|    n_updates        | 601630   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2510000, episode_reward=-3.20 +/- 4.17\n",
      "Episode length: 930.40 +/- 335.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 930      |\n",
      "|    mean_reward      | -3.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00669  |\n",
      "|    n_updates        | 602499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.51    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4212     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6803     |\n",
      "|    total_timesteps  | 2510893  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 602723   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4216     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6812     |\n",
      "|    total_timesteps  | 2514644  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00754  |\n",
      "|    n_updates        | 603660   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.07e+03 |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4220     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 6822     |\n",
      "|    total_timesteps  | 2519081  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 604770   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2520000, episode_reward=-4.20 +/- 2.56\n",
      "Episode length: 1060.20 +/- 401.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -4.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 604999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.07e+03 |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4224     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 6841     |\n",
      "|    total_timesteps  | 2523551  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00441  |\n",
      "|    n_updates        | 605887   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.07e+03 |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4228     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 6850     |\n",
      "|    total_timesteps  | 2527613  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 606903   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2530000, episode_reward=-2.00 +/- 6.60\n",
      "Episode length: 1053.60 +/- 131.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00976  |\n",
      "|    n_updates        | 607499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.07e+03 |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4232     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 6868     |\n",
      "|    total_timesteps  | 2532005  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00973  |\n",
      "|    n_updates        | 608001   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4236     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 6879     |\n",
      "|    total_timesteps  | 2536798  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 609199   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2540000, episode_reward=-4.40 +/- 7.76\n",
      "Episode length: 1013.20 +/- 216.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | -4.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 609999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4240     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 6897     |\n",
      "|    total_timesteps  | 2541175  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0275   |\n",
      "|    n_updates        | 610293   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.57    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4244     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 6905     |\n",
      "|    total_timesteps  | 2544630  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00896  |\n",
      "|    n_updates        | 611157   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.07e+03 |\n",
      "|    ep_rew_mean      | -8.59    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4248     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 6915     |\n",
      "|    total_timesteps  | 2548542  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 612135   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2550000, episode_reward=-1.40 +/- 5.95\n",
      "Episode length: 1144.80 +/- 108.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | -1.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 612499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.52    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4252     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 6934     |\n",
      "|    total_timesteps  | 2552888  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00606  |\n",
      "|    n_updates        | 613221   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4256     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 6945     |\n",
      "|    total_timesteps  | 2557564  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 614390   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2560000, episode_reward=-8.20 +/- 4.92\n",
      "Episode length: 1035.00 +/- 215.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | -8.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 614999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4260     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 6963     |\n",
      "|    total_timesteps  | 2562027  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00537  |\n",
      "|    n_updates        | 615506   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -7.9     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4264     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 6974     |\n",
      "|    total_timesteps  | 2566959  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00739  |\n",
      "|    n_updates        | 616739   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2570000, episode_reward=-6.40 +/- 4.76\n",
      "Episode length: 1123.80 +/- 143.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -6.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 617499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -7.94    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4268     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 6993     |\n",
      "|    total_timesteps  | 2571161  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 617790   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -7.87    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4272     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 7002     |\n",
      "|    total_timesteps  | 2575261  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 618815   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.07e+03 |\n",
      "|    ep_rew_mean      | -7.89    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4276     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 7011     |\n",
      "|    total_timesteps  | 2579189  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 619797   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2580000, episode_reward=-1.80 +/- 5.64\n",
      "Episode length: 956.40 +/- 341.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 956      |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 619999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | -8.02    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4280     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 7030     |\n",
      "|    total_timesteps  | 2584043  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 621010   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -7.92    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4284     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 7041     |\n",
      "|    total_timesteps  | 2588643  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 622160   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2590000, episode_reward=-9.80 +/- 5.42\n",
      "Episode length: 952.00 +/- 128.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 952      |\n",
      "|    mean_reward      | -9.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 622499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -7.9     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4288     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 7059     |\n",
      "|    total_timesteps  | 2593486  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00471  |\n",
      "|    n_updates        | 623371   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -8.04    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4292     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 7069     |\n",
      "|    total_timesteps  | 2597697  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 624424   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2600000, episode_reward=-4.60 +/- 5.00\n",
      "Episode length: 1067.20 +/- 140.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -4.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 624999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -7.91    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4296     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 7087     |\n",
      "|    total_timesteps  | 2602173  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00775  |\n",
      "|    n_updates        | 625543   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.09e+03 |\n",
      "|    ep_rew_mean      | -7.69    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4300     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 7098     |\n",
      "|    total_timesteps  | 2606743  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00648  |\n",
      "|    n_updates        | 626685   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2610000, episode_reward=-6.20 +/- 6.79\n",
      "Episode length: 833.60 +/- 439.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 834      |\n",
      "|    mean_reward      | -6.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 627499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.1e+03  |\n",
      "|    ep_rew_mean      | -7.66    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4304     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 7118     |\n",
      "|    total_timesteps  | 2612482  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00742  |\n",
      "|    n_updates        | 628120   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.11e+03 |\n",
      "|    ep_rew_mean      | -7.7     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4308     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 7129     |\n",
      "|    total_timesteps  | 2617206  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 629301   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2620000, episode_reward=-3.60 +/- 2.24\n",
      "Episode length: 1027.00 +/- 451.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -3.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00404  |\n",
      "|    n_updates        | 629999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.11e+03 |\n",
      "|    ep_rew_mean      | -7.58    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4312     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7148     |\n",
      "|    total_timesteps  | 2622258  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 630564   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.12e+03 |\n",
      "|    ep_rew_mean      | -7.54    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4316     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7158     |\n",
      "|    total_timesteps  | 2626279  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00581  |\n",
      "|    n_updates        | 631569   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2630000, episode_reward=3.00 +/- 4.29\n",
      "Episode length: 1041.00 +/- 287.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 632499   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.12e+03 |\n",
      "|    ep_rew_mean      | -7.6     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4320     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7177     |\n",
      "|    total_timesteps  | 2631107  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 632776   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.13e+03 |\n",
      "|    ep_rew_mean      | -6.96    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4324     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7189     |\n",
      "|    total_timesteps  | 2636189  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 634047   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2640000, episode_reward=-6.40 +/- 3.50\n",
      "Episode length: 1012.00 +/- 268.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | -6.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 634999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.13e+03 |\n",
      "|    ep_rew_mean      | -6.91    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4328     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7207     |\n",
      "|    total_timesteps  | 2641025  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 635256   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.13e+03 |\n",
      "|    ep_rew_mean      | -6.74    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4332     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7217     |\n",
      "|    total_timesteps  | 2645164  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0032   |\n",
      "|    n_updates        | 636290   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.13e+03 |\n",
      "|    ep_rew_mean      | -6.83    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4336     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7228     |\n",
      "|    total_timesteps  | 2649888  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00919  |\n",
      "|    n_updates        | 637471   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2650000, episode_reward=-1.40 +/- 1.85\n",
      "Episode length: 1172.80 +/- 110.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -1.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 637499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.13e+03 |\n",
      "|    ep_rew_mean      | -6.55    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4340     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7248     |\n",
      "|    total_timesteps  | 2654641  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00713  |\n",
      "|    n_updates        | 638660   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -6.21    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4344     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7258     |\n",
      "|    total_timesteps  | 2659131  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 639782   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2660000, episode_reward=-9.00 +/- 5.02\n",
      "Episode length: 816.80 +/- 356.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 817      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 639999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -6.24    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4348     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7276     |\n",
      "|    total_timesteps  | 2664120  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00861  |\n",
      "|    n_updates        | 641029   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -6.2     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4352     |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 7287     |\n",
      "|    total_timesteps  | 2668854  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 642213   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2670000, episode_reward=-6.80 +/- 4.07\n",
      "Episode length: 1098.80 +/- 64.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -6.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0257   |\n",
      "|    n_updates        | 642499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -6.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4356     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7307     |\n",
      "|    total_timesteps  | 2673701  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 643425   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -6.64    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4360     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7316     |\n",
      "|    total_timesteps  | 2677519  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 644379   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2680000, episode_reward=-2.00 +/- 4.73\n",
      "Episode length: 1036.80 +/- 283.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.033    |\n",
      "|    n_updates        | 644999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -6.73    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4364     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7336     |\n",
      "|    total_timesteps  | 2682705  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 645676   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.17e+03 |\n",
      "|    ep_rew_mean      | -6.16    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4368     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7348     |\n",
      "|    total_timesteps  | 2688024  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.029    |\n",
      "|    n_updates        | 647005   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2690000, episode_reward=-4.60 +/- 2.42\n",
      "Episode length: 1024.20 +/- 450.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -4.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 647499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.18e+03 |\n",
      "|    ep_rew_mean      | -6.18    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4372     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7369     |\n",
      "|    total_timesteps  | 2693724  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 648430   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.19e+03 |\n",
      "|    ep_rew_mean      | -6.19    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4376     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7379     |\n",
      "|    total_timesteps  | 2697962  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 649490   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2700000, episode_reward=-7.80 +/- 1.60\n",
      "Episode length: 831.20 +/- 349.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 831      |\n",
      "|    mean_reward      | -7.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 649999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.19e+03 |\n",
      "|    ep_rew_mean      | -5.77    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4380     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7398     |\n",
      "|    total_timesteps  | 2703358  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 650839   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.19e+03 |\n",
      "|    ep_rew_mean      | -5.75    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4384     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7409     |\n",
      "|    total_timesteps  | 2708061  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 652015   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2710000, episode_reward=-6.20 +/- 3.31\n",
      "Episode length: 954.80 +/- 174.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 955      |\n",
      "|    mean_reward      | -6.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00938  |\n",
      "|    n_updates        | 652499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.2e+03  |\n",
      "|    ep_rew_mean      | -5.5     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4388     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7427     |\n",
      "|    total_timesteps  | 2713014  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 653253   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.2e+03  |\n",
      "|    ep_rew_mean      | -5.37    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4392     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7439     |\n",
      "|    total_timesteps  | 2717875  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00994  |\n",
      "|    n_updates        | 654468   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2720000, episode_reward=-4.60 +/- 5.61\n",
      "Episode length: 997.20 +/- 502.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 997      |\n",
      "|    mean_reward      | -4.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0099   |\n",
      "|    n_updates        | 654999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.19    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4396     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7459     |\n",
      "|    total_timesteps  | 2723301  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 655825   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4400     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7469     |\n",
      "|    total_timesteps  | 2727768  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 656941   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2730000, episode_reward=-1.00 +/- 6.48\n",
      "Episode length: 975.00 +/- 332.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 975      |\n",
      "|    mean_reward      | -1       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0038   |\n",
      "|    n_updates        | 657499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.34    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4404     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7490     |\n",
      "|    total_timesteps  | 2733458  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 658364   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.18    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4408     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 7501     |\n",
      "|    total_timesteps  | 2738199  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 659549   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2740000, episode_reward=-1.40 +/- 7.34\n",
      "Episode length: 1103.20 +/- 286.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -1.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0078   |\n",
      "|    n_updates        | 659999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.25    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4412     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7520     |\n",
      "|    total_timesteps  | 2743002  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00743  |\n",
      "|    n_updates        | 660750   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.14    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4416     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7530     |\n",
      "|    total_timesteps  | 2747118  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 661779   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2750000, episode_reward=-3.20 +/- 5.74\n",
      "Episode length: 934.60 +/- 445.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 935      |\n",
      "|    mean_reward      | -3.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00552  |\n",
      "|    n_updates        | 662499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.17    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4420     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7548     |\n",
      "|    total_timesteps  | 2752192  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00469  |\n",
      "|    n_updates        | 663047   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.2e+03  |\n",
      "|    ep_rew_mean      | -5.54    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4424     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7559     |\n",
      "|    total_timesteps  | 2756683  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00839  |\n",
      "|    n_updates        | 664170   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2760000, episode_reward=-4.40 +/- 7.94\n",
      "Episode length: 854.60 +/- 426.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 855      |\n",
      "|    mean_reward      | -4.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 664999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.15    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4428     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7578     |\n",
      "|    total_timesteps  | 2762109  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00293  |\n",
      "|    n_updates        | 665527   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.21    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4432     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7588     |\n",
      "|    total_timesteps  | 2766626  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 666656   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2770000, episode_reward=-3.60 +/- 6.34\n",
      "Episode length: 1177.60 +/- 151.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -3.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 667499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4436     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7607     |\n",
      "|    total_timesteps  | 2771061  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0312   |\n",
      "|    n_updates        | 667765   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.12    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4440     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7618     |\n",
      "|    total_timesteps  | 2775661  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 668915   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2780000, episode_reward=-1.40 +/- 6.65\n",
      "Episode length: 1060.80 +/- 302.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -1.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 669999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.97    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4444     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7639     |\n",
      "|    total_timesteps  | 2781299  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00776  |\n",
      "|    n_updates        | 670324   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.78    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4448     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7650     |\n",
      "|    total_timesteps  | 2785960  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 671489   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2790000, episode_reward=-3.00 +/- 4.24\n",
      "Episode length: 1000.40 +/- 336.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 672499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.93    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4452     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7669     |\n",
      "|    total_timesteps  | 2791053  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00999  |\n",
      "|    n_updates        | 672763   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -5.03    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4456     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7679     |\n",
      "|    total_timesteps  | 2795457  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00608  |\n",
      "|    n_updates        | 673864   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -5.01    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4460     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 7689     |\n",
      "|    total_timesteps  | 2799700  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 674924   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2800000, episode_reward=-3.80 +/- 4.71\n",
      "Episode length: 1132.40 +/- 214.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | -3.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 674999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.95    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4464     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7710     |\n",
      "|    total_timesteps  | 2805107  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0064   |\n",
      "|    n_updates        | 676276   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.31    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4468     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7720     |\n",
      "|    total_timesteps  | 2809262  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00482  |\n",
      "|    n_updates        | 677315   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2810000, episode_reward=0.40 +/- 8.40\n",
      "Episode length: 923.60 +/- 247.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 924      |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 677499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -5.28    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4472     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7740     |\n",
      "|    total_timesteps  | 2814881  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 678720   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -4.91    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4476     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7750     |\n",
      "|    total_timesteps  | 2819331  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 679832   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2820000, episode_reward=-4.20 +/- 7.98\n",
      "Episode length: 846.60 +/- 292.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 847      |\n",
      "|    mean_reward      | -4.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00581  |\n",
      "|    n_updates        | 679999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -4.76    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4480     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7770     |\n",
      "|    total_timesteps  | 2824813  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 681203   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -4.89    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4484     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7780     |\n",
      "|    total_timesteps  | 2829213  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00993  |\n",
      "|    n_updates        | 682303   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2830000, episode_reward=-2.80 +/- 7.03\n",
      "Episode length: 991.00 +/- 384.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 991      |\n",
      "|    mean_reward      | -2.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00368  |\n",
      "|    n_updates        | 682499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -4.73    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4488     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7799     |\n",
      "|    total_timesteps  | 2834289  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 683572   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -4.63    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4492     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7810     |\n",
      "|    total_timesteps  | 2839141  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 684785   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2840000, episode_reward=-1.40 +/- 6.89\n",
      "Episode length: 1119.40 +/- 377.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -1.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00763  |\n",
      "|    n_updates        | 684999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.87    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4496     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7832     |\n",
      "|    total_timesteps  | 2844832  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00862  |\n",
      "|    n_updates        | 686207   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -4.93    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4500     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7842     |\n",
      "|    total_timesteps  | 2849096  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 687273   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2850000, episode_reward=-4.40 +/- 8.24\n",
      "Episode length: 921.40 +/- 378.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 921      |\n",
      "|    mean_reward      | -4.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00697  |\n",
      "|    n_updates        | 687499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -4.8     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4504     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7862     |\n",
      "|    total_timesteps  | 2854535  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 688633   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -4.91    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4508     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 7873     |\n",
      "|    total_timesteps  | 2859176  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00473  |\n",
      "|    n_updates        | 689793   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2860000, episode_reward=-0.80 +/- 2.79\n",
      "Episode length: 1039.80 +/- 392.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00635  |\n",
      "|    n_updates        | 689999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.8     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4512     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 7894     |\n",
      "|    total_timesteps  | 2864720  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 691179   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.76    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4516     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 7905     |\n",
      "|    total_timesteps  | 2869830  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00403  |\n",
      "|    n_updates        | 692457   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2870000, episode_reward=-1.80 +/- 4.79\n",
      "Episode length: 1221.60 +/- 161.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 692499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.54    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4520     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 7927     |\n",
      "|    total_timesteps  | 2874999  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00487  |\n",
      "|    n_updates        | 693749   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2880000, episode_reward=-2.80 +/- 4.96\n",
      "Episode length: 898.20 +/- 435.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 898      |\n",
      "|    mean_reward      | -2.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 694999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -4.32    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4524     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 7947     |\n",
      "|    total_timesteps  | 2881128  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 695281   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.44    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4528     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 7957     |\n",
      "|    total_timesteps  | 2885327  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0409   |\n",
      "|    n_updates        | 696331   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.42    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4532     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 7967     |\n",
      "|    total_timesteps  | 2889635  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00918  |\n",
      "|    n_updates        | 697408   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2890000, episode_reward=-3.00 +/- 4.69\n",
      "Episode length: 1119.60 +/- 279.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -3       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 697499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.53    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4536     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 7987     |\n",
      "|    total_timesteps  | 2894415  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 698603   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -5       |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4540     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 7998     |\n",
      "|    total_timesteps  | 2899266  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00867  |\n",
      "|    n_updates        | 699816   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2900000, episode_reward=-4.80 +/- 3.66\n",
      "Episode length: 1062.00 +/- 302.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -4.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00776  |\n",
      "|    n_updates        | 699999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -5.35    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4544     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 8018     |\n",
      "|    total_timesteps  | 2904342  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 701085   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -5.17    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4548     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 8028     |\n",
      "|    total_timesteps  | 2908701  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 702175   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2910000, episode_reward=-3.40 +/- 3.88\n",
      "Episode length: 1173.40 +/- 147.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -3.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 702499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.98    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4552     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 8048     |\n",
      "|    total_timesteps  | 2913732  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 703432   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.88    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4556     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 8059     |\n",
      "|    total_timesteps  | 2918167  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 704541   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2920000, episode_reward=-5.80 +/- 2.71\n",
      "Episode length: 1121.40 +/- 208.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -5.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00909  |\n",
      "|    n_updates        | 704999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -4.58    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4560     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8080     |\n",
      "|    total_timesteps  | 2923514  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0081   |\n",
      "|    n_updates        | 705878   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.49    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4564     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8089     |\n",
      "|    total_timesteps  | 2927397  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 706849   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2930000, episode_reward=-0.20 +/- 4.87\n",
      "Episode length: 1137.80 +/- 128.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | -0.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00959  |\n",
      "|    n_updates        | 707499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.45    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4568     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8109     |\n",
      "|    total_timesteps  | 2932629  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00648  |\n",
      "|    n_updates        | 708157   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.35    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4572     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8121     |\n",
      "|    total_timesteps  | 2937618  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00959  |\n",
      "|    n_updates        | 709404   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2940000, episode_reward=1.60 +/- 10.27\n",
      "Episode length: 1156.20 +/- 232.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00795  |\n",
      "|    n_updates        | 709999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.51    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4576     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8141     |\n",
      "|    total_timesteps  | 2942452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 710612   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.55    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4580     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8151     |\n",
      "|    total_timesteps  | 2946839  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0053   |\n",
      "|    n_updates        | 711709   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2950000, episode_reward=-5.00 +/- 2.28\n",
      "Episode length: 964.80 +/- 420.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 965      |\n",
      "|    mean_reward      | -5       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 712499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.48    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4584     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8172     |\n",
      "|    total_timesteps  | 2952455  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 713113   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.87    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4588     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8182     |\n",
      "|    total_timesteps  | 2957047  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 714261   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2960000, episode_reward=-5.60 +/- 4.76\n",
      "Episode length: 1044.00 +/- 139.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | -5.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 714999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.93    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4592     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8202     |\n",
      "|    total_timesteps  | 2962171  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0292   |\n",
      "|    n_updates        | 715542   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.6     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4596     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8213     |\n",
      "|    total_timesteps  | 2966923  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 716730   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2970000, episode_reward=-6.60 +/- 7.66\n",
      "Episode length: 982.20 +/- 202.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 982      |\n",
      "|    mean_reward      | -6.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 717499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.43    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4600     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8233     |\n",
      "|    total_timesteps  | 2972282  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0315   |\n",
      "|    n_updates        | 718070   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.43    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4604     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 8244     |\n",
      "|    total_timesteps  | 2977099  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00758  |\n",
      "|    n_updates        | 719274   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2980000, episode_reward=-4.80 +/- 5.84\n",
      "Episode length: 1017.40 +/- 366.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -4.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00905  |\n",
      "|    n_updates        | 719999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.49    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4608     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8265     |\n",
      "|    total_timesteps  | 2982504  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 720625   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.13    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4612     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8276     |\n",
      "|    total_timesteps  | 2987440  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00871  |\n",
      "|    n_updates        | 721859   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2990000, episode_reward=-0.40 +/- 11.62\n",
      "Episode length: 932.20 +/- 138.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 932      |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00943  |\n",
      "|    n_updates        | 722499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.05    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4616     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8296     |\n",
      "|    total_timesteps  | 2992853  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00674  |\n",
      "|    n_updates        | 723213   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.85    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4620     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8308     |\n",
      "|    total_timesteps  | 2997900  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00814  |\n",
      "|    n_updates        | 724474   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3000000, episode_reward=-2.20 +/- 6.05\n",
      "Episode length: 1052.00 +/- 169.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 724999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.04    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4624     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8328     |\n",
      "|    total_timesteps  | 3003261  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 725815   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.18    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4628     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8338     |\n",
      "|    total_timesteps  | 3007741  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00869  |\n",
      "|    n_updates        | 726935   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3010000, episode_reward=-4.80 +/- 5.15\n",
      "Episode length: 1170.40 +/- 108.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -4.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00942  |\n",
      "|    n_updates        | 727499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.88    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4632     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8358     |\n",
      "|    total_timesteps  | 3012221  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 728055   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -3.48    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4636     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8368     |\n",
      "|    total_timesteps  | 3016662  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 729165   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3020000, episode_reward=-2.00 +/- 4.69\n",
      "Episode length: 1088.20 +/- 370.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 729999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.34    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4640     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8389     |\n",
      "|    total_timesteps  | 3022049  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00892  |\n",
      "|    n_updates        | 730512   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -3.08    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4644     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8399     |\n",
      "|    total_timesteps  | 3026613  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00934  |\n",
      "|    n_updates        | 731653   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3030000, episode_reward=0.40 +/- 4.76\n",
      "Episode length: 1080.80 +/- 454.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 732499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.37    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4648     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8418     |\n",
      "|    total_timesteps  | 3031390  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 732847   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -3.43    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4652     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8429     |\n",
      "|    total_timesteps  | 3035879  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 733969   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3040000, episode_reward=-2.20 +/- 5.56\n",
      "Episode length: 1039.40 +/- 241.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 734999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.51    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4656     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8448     |\n",
      "|    total_timesteps  | 3041057  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 735264   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.63    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4660     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 8460     |\n",
      "|    total_timesteps  | 3046061  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 736515   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3050000, episode_reward=-5.00 +/- 3.03\n",
      "Episode length: 1125.40 +/- 128.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | -5       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 737499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -3.67    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4664     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8481     |\n",
      "|    total_timesteps  | 3051300  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 737824   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.76    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4668     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8491     |\n",
      "|    total_timesteps  | 3055744  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 738935   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3060000, episode_reward=-2.60 +/- 4.59\n",
      "Episode length: 1109.20 +/- 296.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -2.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 739999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.84    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4672     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8512     |\n",
      "|    total_timesteps  | 3061077  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 740269   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.61    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4676     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8523     |\n",
      "|    total_timesteps  | 3065753  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 741438   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3070000, episode_reward=-4.60 +/- 5.16\n",
      "Episode length: 1064.60 +/- 377.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -4.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 742499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -3.8     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4680     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8544     |\n",
      "|    total_timesteps  | 3071091  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 742772   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.84    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4684     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8554     |\n",
      "|    total_timesteps  | 3075441  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0263   |\n",
      "|    n_updates        | 743860   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.45    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4688     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8564     |\n",
      "|    total_timesteps  | 3079909  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0078   |\n",
      "|    n_updates        | 744977   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3080000, episode_reward=2.20 +/- 2.99\n",
      "Episode length: 1293.20 +/- 123.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.29e+03 |\n",
      "|    mean_reward      | 2.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 744999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -3.39    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4692     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8584     |\n",
      "|    total_timesteps  | 3084366  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00633  |\n",
      "|    n_updates        | 746091   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -3.6     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4696     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8595     |\n",
      "|    total_timesteps  | 3089028  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 747256   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3090000, episode_reward=-3.40 +/- 5.00\n",
      "Episode length: 1004.20 +/- 373.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 747499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -3.71    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4700     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8615     |\n",
      "|    total_timesteps  | 3094597  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0087   |\n",
      "|    n_updates        | 748649   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -3.84    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4704     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8627     |\n",
      "|    total_timesteps  | 3099487  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 749871   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3100000, episode_reward=-7.80 +/- 5.42\n",
      "Episode length: 887.80 +/- 236.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 888      |\n",
      "|    mean_reward      | -7.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00897  |\n",
      "|    n_updates        | 749999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -3.86    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4708     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8643     |\n",
      "|    total_timesteps  | 3103461  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 750865   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.2e+03  |\n",
      "|    ep_rew_mean      | -4       |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4712     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8653     |\n",
      "|    total_timesteps  | 3107754  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00798  |\n",
      "|    n_updates        | 751938   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3110000, episode_reward=2.00 +/- 7.82\n",
      "Episode length: 893.80 +/- 428.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 894      |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 752499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -4.07    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4716     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8673     |\n",
      "|    total_timesteps  | 3113572  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0307   |\n",
      "|    n_updates        | 753392   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -4.18    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4720     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 8685     |\n",
      "|    total_timesteps  | 3118818  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00574  |\n",
      "|    n_updates        | 754704   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3120000, episode_reward=-5.00 +/- 4.77\n",
      "Episode length: 975.80 +/- 486.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 976      |\n",
      "|    mean_reward      | -5       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00647  |\n",
      "|    n_updates        | 754999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.01    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4724     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8708     |\n",
      "|    total_timesteps  | 3125173  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 756293   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.04    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4728     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8718     |\n",
      "|    total_timesteps  | 3129511  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00819  |\n",
      "|    n_updates        | 757377   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3130000, episode_reward=-1.60 +/- 7.42\n",
      "Episode length: 1010.80 +/- 233.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | -1.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 757499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.43    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4732     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8737     |\n",
      "|    total_timesteps  | 3134691  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 758672   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.59    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4736     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8749     |\n",
      "|    total_timesteps  | 3139679  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 759919   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3140000, episode_reward=-3.60 +/- 8.59\n",
      "Episode length: 1112.40 +/- 219.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -3.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 759999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.45    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4740     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8770     |\n",
      "|    total_timesteps  | 3144991  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 761247   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.62    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4744     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8780     |\n",
      "|    total_timesteps  | 3149400  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 762349   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3150000, episode_reward=-0.80 +/- 3.19\n",
      "Episode length: 1155.00 +/- 259.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 762499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -4.23    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4748     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8802     |\n",
      "|    total_timesteps  | 3155242  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 763810   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -4.25    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4752     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8813     |\n",
      "|    total_timesteps  | 3159855  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 764963   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3160000, episode_reward=-6.00 +/- 1.90\n",
      "Episode length: 1180.40 +/- 95.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -6       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 764999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.28    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4756     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8833     |\n",
      "|    total_timesteps  | 3164540  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0266   |\n",
      "|    n_updates        | 766134   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.06    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4760     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8843     |\n",
      "|    total_timesteps  | 3169049  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 767262   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3170000, episode_reward=-2.20 +/- 5.56\n",
      "Episode length: 972.40 +/- 437.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 972      |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00712  |\n",
      "|    n_updates        | 767499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4       |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4764     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8863     |\n",
      "|    total_timesteps  | 3174526  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00884  |\n",
      "|    n_updates        | 768631   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.86    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4768     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8874     |\n",
      "|    total_timesteps  | 3179029  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00943  |\n",
      "|    n_updates        | 769757   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3180000, episode_reward=-4.00 +/- 7.13\n",
      "Episode length: 1181.00 +/- 208.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -4       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00651  |\n",
      "|    n_updates        | 769999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.93    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4772     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 8894     |\n",
      "|    total_timesteps  | 3183689  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 770922   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.11    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4776     |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 8904     |\n",
      "|    total_timesteps  | 3188102  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0065   |\n",
      "|    n_updates        | 772025   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3190000, episode_reward=-3.60 +/- 4.18\n",
      "Episode length: 1001.40 +/- 460.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00682  |\n",
      "|    n_updates        | 772499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.23    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4780     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 8925     |\n",
      "|    total_timesteps  | 3193815  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 773453   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.07    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4784     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 8936     |\n",
      "|    total_timesteps  | 3198547  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00546  |\n",
      "|    n_updates        | 774636   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3200000, episode_reward=-6.20 +/- 3.92\n",
      "Episode length: 950.60 +/- 199.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 951      |\n",
      "|    mean_reward      | -6.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00816  |\n",
      "|    n_updates        | 774999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -4.61    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4788     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 8955     |\n",
      "|    total_timesteps  | 3203625  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 775906   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -4.79    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4792     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 8966     |\n",
      "|    total_timesteps  | 3208101  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00871  |\n",
      "|    n_updates        | 777025   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3210000, episode_reward=0.60 +/- 2.73\n",
      "Episode length: 1099.20 +/- 335.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00725  |\n",
      "|    n_updates        | 777499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -4.69    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4796     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 8987     |\n",
      "|    total_timesteps  | 3213809  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 778452   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -4.68    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4800     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 8999     |\n",
      "|    total_timesteps  | 3218654  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 779663   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3220000, episode_reward=0.40 +/- 7.28\n",
      "Episode length: 1174.80 +/- 162.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 779999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -4.73    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4804     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 9019     |\n",
      "|    total_timesteps  | 3223659  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 780914   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -4.39    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4808     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 9030     |\n",
      "|    total_timesteps  | 3228187  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 782046   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3230000, episode_reward=-4.60 +/- 2.33\n",
      "Episode length: 1106.40 +/- 287.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -4.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 782499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -4.65    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4812     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 9049     |\n",
      "|    total_timesteps  | 3232724  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 783180   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -4.5     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4816     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 9060     |\n",
      "|    total_timesteps  | 3237515  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 784378   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3240000, episode_reward=-2.80 +/- 2.48\n",
      "Episode length: 1133.00 +/- 516.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | -2.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 784999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -4.4     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4820     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 9082     |\n",
      "|    total_timesteps  | 3243463  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0322   |\n",
      "|    n_updates        | 785865   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.34    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4824     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 9093     |\n",
      "|    total_timesteps  | 3248092  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 787022   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3250000, episode_reward=-1.80 +/- 6.27\n",
      "Episode length: 1105.40 +/- 302.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00758  |\n",
      "|    n_updates        | 787499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.56    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4828     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9111     |\n",
      "|    total_timesteps  | 3252284  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 788070   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.58    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4832     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 9121     |\n",
      "|    total_timesteps  | 3256815  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0272   |\n",
      "|    n_updates        | 789203   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3260000, episode_reward=-1.00 +/- 6.16\n",
      "Episode length: 1055.00 +/- 311.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -1       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 789999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.6     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4836     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9142     |\n",
      "|    total_timesteps  | 3262338  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0065   |\n",
      "|    n_updates        | 790584   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.58    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4840     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9154     |\n",
      "|    total_timesteps  | 3267442  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 791860   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3270000, episode_reward=-0.20 +/- 7.08\n",
      "Episode length: 1149.20 +/- 150.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | -0.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 792499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.56    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4844     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9174     |\n",
      "|    total_timesteps  | 3272516  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00498  |\n",
      "|    n_updates        | 793128   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.64    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4848     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9186     |\n",
      "|    total_timesteps  | 3277378  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 794344   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3280000, episode_reward=2.20 +/- 4.49\n",
      "Episode length: 1263.80 +/- 383.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 2.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 794999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -4.57    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4852     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9206     |\n",
      "|    total_timesteps  | 3282264  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00703  |\n",
      "|    n_updates        | 795565   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.31    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4856     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9219     |\n",
      "|    total_timesteps  | 3287598  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00857  |\n",
      "|    n_updates        | 796899   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3290000, episode_reward=1.20 +/- 6.43\n",
      "Episode length: 1008.20 +/- 490.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0363   |\n",
      "|    n_updates        | 797499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -4.25    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4860     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9239     |\n",
      "|    total_timesteps  | 3293188  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 798296   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.29    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4864     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9249     |\n",
      "|    total_timesteps  | 3297455  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00549  |\n",
      "|    n_updates        | 799363   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3300000, episode_reward=-1.20 +/- 3.43\n",
      "Episode length: 1397.40 +/- 105.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.4e+03  |\n",
      "|    mean_reward      | -1.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 799999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -4.04    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4868     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9271     |\n",
      "|    total_timesteps  | 3302380  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 800594   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.82    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4872     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9282     |\n",
      "|    total_timesteps  | 3307096  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00642  |\n",
      "|    n_updates        | 801773   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3310000, episode_reward=-2.60 +/- 2.06\n",
      "Episode length: 1267.20 +/- 231.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | -2.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 802499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -3.77    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4876     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9304     |\n",
      "|    total_timesteps  | 3312377  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 803094   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -3.33    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4880     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 9316     |\n",
      "|    total_timesteps  | 3317497  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.007    |\n",
      "|    n_updates        | 804374   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3320000, episode_reward=-4.00 +/- 8.12\n",
      "Episode length: 966.00 +/- 381.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 966      |\n",
      "|    mean_reward      | -4       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 804999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -3.48    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4884     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9336     |\n",
      "|    total_timesteps  | 3322620  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 805654   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -3.26    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4888     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9347     |\n",
      "|    total_timesteps  | 3327509  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 806877   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3330000, episode_reward=-5.00 +/- 2.61\n",
      "Episode length: 1123.80 +/- 282.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -5       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 807499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -3.24    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4892     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9366     |\n",
      "|    total_timesteps  | 3332124  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 808030   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -3.4     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4896     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9377     |\n",
      "|    total_timesteps  | 3336859  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00853  |\n",
      "|    n_updates        | 809214   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3340000, episode_reward=-2.20 +/- 7.25\n",
      "Episode length: 1101.00 +/- 225.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 809999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -3.31    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4900     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9399     |\n",
      "|    total_timesteps  | 3342920  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00856  |\n",
      "|    n_updates        | 810729   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -3.02    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4904     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9409     |\n",
      "|    total_timesteps  | 3347240  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 811809   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3350000, episode_reward=-3.40 +/- 6.95\n",
      "Episode length: 918.00 +/- 353.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 918      |\n",
      "|    mean_reward      | -3.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 812499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -3.02    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4908     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9429     |\n",
      "|    total_timesteps  | 3352747  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 813186   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -2.56    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4912     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9439     |\n",
      "|    total_timesteps  | 3357249  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00301  |\n",
      "|    n_updates        | 814312   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3360000, episode_reward=3.60 +/- 5.08\n",
      "Episode length: 1141.40 +/- 205.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 814999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -2.73    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4916     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9460     |\n",
      "|    total_timesteps  | 3362433  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00803  |\n",
      "|    n_updates        | 815608   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -2.73    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4920     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9471     |\n",
      "|    total_timesteps  | 3366965  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00952  |\n",
      "|    n_updates        | 816741   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3370000, episode_reward=-3.80 +/- 4.45\n",
      "Episode length: 929.20 +/- 235.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 929      |\n",
      "|    mean_reward      | -3.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 817499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -2.83    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4924     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9491     |\n",
      "|    total_timesteps  | 3372532  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 818132   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -2.51    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4928     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9501     |\n",
      "|    total_timesteps  | 3377158  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00734  |\n",
      "|    n_updates        | 819289   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3380000, episode_reward=1.40 +/- 6.89\n",
      "Episode length: 1205.20 +/- 235.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00846  |\n",
      "|    n_updates        | 819999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -2.13    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4932     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9524     |\n",
      "|    total_timesteps  | 3382877  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00828  |\n",
      "|    n_updates        | 820719   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -1.99    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4936     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9534     |\n",
      "|    total_timesteps  | 3387335  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00367  |\n",
      "|    n_updates        | 821833   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3390000, episode_reward=2.40 +/- 3.44\n",
      "Episode length: 1141.20 +/- 495.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0356   |\n",
      "|    n_updates        | 822499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.94    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4940     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9558     |\n",
      "|    total_timesteps  | 3393715  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00915  |\n",
      "|    n_updates        | 823428   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.77    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4944     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9569     |\n",
      "|    total_timesteps  | 3398630  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 824657   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3400000, episode_reward=3.20 +/- 9.54\n",
      "Episode length: 1109.80 +/- 173.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00307  |\n",
      "|    n_updates        | 824999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.55    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4948     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9588     |\n",
      "|    total_timesteps  | 3403038  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0084   |\n",
      "|    n_updates        | 825759   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -1.58    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4952     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 9598     |\n",
      "|    total_timesteps  | 3407639  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00394  |\n",
      "|    n_updates        | 826909   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3410000, episode_reward=1.40 +/- 10.61\n",
      "Episode length: 732.20 +/- 406.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 732      |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00564  |\n",
      "|    n_updates        | 827499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.4     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4956     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9617     |\n",
      "|    total_timesteps  | 3413460  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 828364   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -1.62    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4960     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9630     |\n",
      "|    total_timesteps  | 3418645  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00562  |\n",
      "|    n_updates        | 829661   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3420000, episode_reward=-1.20 +/- 5.08\n",
      "Episode length: 1138.00 +/- 106.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | -1.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 829999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.72    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4964     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9650     |\n",
      "|    total_timesteps  | 3423476  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00618  |\n",
      "|    n_updates        | 830868   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -2.09    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4968     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9661     |\n",
      "|    total_timesteps  | 3428600  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00549  |\n",
      "|    n_updates        | 832149   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3430000, episode_reward=-3.60 +/- 7.50\n",
      "Episode length: 1017.80 +/- 262.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -3.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 832499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -2.09    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4972     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9680     |\n",
      "|    total_timesteps  | 3433392  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00666  |\n",
      "|    n_updates        | 833347   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -2.03    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4976     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9691     |\n",
      "|    total_timesteps  | 3438265  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 834566   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3440000, episode_reward=-2.80 +/- 7.83\n",
      "Episode length: 1096.20 +/- 230.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -2.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00994  |\n",
      "|    n_updates        | 834999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.87    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4980     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9711     |\n",
      "|    total_timesteps  | 3443304  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 835825   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.63    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4984     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9724     |\n",
      "|    total_timesteps  | 3448541  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0061   |\n",
      "|    n_updates        | 837135   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3450000, episode_reward=-2.80 +/- 6.24\n",
      "Episode length: 1106.40 +/- 111.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -2.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00882  |\n",
      "|    n_updates        | 837499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.69    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4988     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9744     |\n",
      "|    total_timesteps  | 3453849  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00806  |\n",
      "|    n_updates        | 838462   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.67    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4992     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9756     |\n",
      "|    total_timesteps  | 3458943  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 839735   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3460000, episode_reward=1.00 +/- 4.69\n",
      "Episode length: 1075.20 +/- 481.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00651  |\n",
      "|    n_updates        | 839999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.22    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4996     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9777     |\n",
      "|    total_timesteps  | 3464518  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 841129   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.16    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5000     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9789     |\n",
      "|    total_timesteps  | 3469543  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.009    |\n",
      "|    n_updates        | 842385   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3470000, episode_reward=-0.20 +/- 6.68\n",
      "Episode length: 1054.80 +/- 276.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | -0.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00635  |\n",
      "|    n_updates        | 842499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.16    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5004     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9809     |\n",
      "|    total_timesteps  | 3474864  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 843715   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3480000, episode_reward=0.80 +/- 5.42\n",
      "Episode length: 1217.40 +/- 170.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 844999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5008     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9833     |\n",
      "|    total_timesteps  | 3481328  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0097   |\n",
      "|    n_updates        | 845331   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.73    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5012     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 9844     |\n",
      "|    total_timesteps  | 3485949  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 846487   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3490000, episode_reward=0.00 +/- 4.34\n",
      "Episode length: 1201.60 +/- 229.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 0        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 847499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.39    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5016     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 9865     |\n",
      "|    total_timesteps  | 3491273  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00567  |\n",
      "|    n_updates        | 847818   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.21    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5020     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 9877     |\n",
      "|    total_timesteps  | 3496146  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00916  |\n",
      "|    n_updates        | 849036   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3500000, episode_reward=2.20 +/- 4.45\n",
      "Episode length: 1235.20 +/- 137.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 2.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 849999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.19    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5024     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 9898     |\n",
      "|    total_timesteps  | 3501114  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 850278   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.29    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5028     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 9909     |\n",
      "|    total_timesteps  | 3505997  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00405  |\n",
      "|    n_updates        | 851499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3510000, episode_reward=2.00 +/- 2.53\n",
      "Episode length: 1375.20 +/- 110.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.38e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00774  |\n",
      "|    n_updates        | 852499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.52    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5032     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 9931     |\n",
      "|    total_timesteps  | 3511230  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 852807   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5036     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 9942     |\n",
      "|    total_timesteps  | 3515544  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0287   |\n",
      "|    n_updates        | 853885   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3520000, episode_reward=5.20 +/- 8.93\n",
      "Episode length: 1070.80 +/- 83.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 854999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.53    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5040     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 9962     |\n",
      "|    total_timesteps  | 3520936  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 855233   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.71    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5044     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 9974     |\n",
      "|    total_timesteps  | 3525994  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00385  |\n",
      "|    n_updates        | 856498   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3530000, episode_reward=0.00 +/- 7.77\n",
      "Episode length: 1072.00 +/- 305.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 0        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0405   |\n",
      "|    n_updates        | 857499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -2.05    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5048     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 9993     |\n",
      "|    total_timesteps  | 3530815  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00842  |\n",
      "|    n_updates        | 857703   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.66    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5052     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 10004    |\n",
      "|    total_timesteps  | 3535525  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00623  |\n",
      "|    n_updates        | 858881   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3540000, episode_reward=-0.80 +/- 7.88\n",
      "Episode length: 1020.40 +/- 302.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 859999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.66    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5056     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 10025    |\n",
      "|    total_timesteps  | 3541325  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 860331   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.66    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5060     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 10036    |\n",
      "|    total_timesteps  | 3545888  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 861471   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3550000, episode_reward=-1.80 +/- 4.83\n",
      "Episode length: 1287.80 +/- 254.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.29e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 862499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.64    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5064     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 10059    |\n",
      "|    total_timesteps  | 3551490  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 862872   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.52    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5068     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 10070    |\n",
      "|    total_timesteps  | 3556123  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 864030   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3560000, episode_reward=2.20 +/- 6.62\n",
      "Episode length: 1142.60 +/- 86.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 2.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 864999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.56    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5072     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10090    |\n",
      "|    total_timesteps  | 3561197  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00529  |\n",
      "|    n_updates        | 865299   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.57    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5076     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 10102    |\n",
      "|    total_timesteps  | 3566501  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00377  |\n",
      "|    n_updates        | 866625   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3570000, episode_reward=-8.80 +/- 3.49\n",
      "Episode length: 1019.60 +/- 133.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -8.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 867499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.8     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5080     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10123    |\n",
      "|    total_timesteps  | 3571875  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 867968   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.94    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5084     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10134    |\n",
      "|    total_timesteps  | 3576442  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 869110   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3580000, episode_reward=-1.80 +/- 4.12\n",
      "Episode length: 1148.20 +/- 399.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00905  |\n",
      "|    n_updates        | 869999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.93    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5088     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10156    |\n",
      "|    total_timesteps  | 3582411  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.005    |\n",
      "|    n_updates        | 870602   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.84    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5092     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10168    |\n",
      "|    total_timesteps  | 3587575  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 871893   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3590000, episode_reward=-5.80 +/- 6.73\n",
      "Episode length: 1114.20 +/- 270.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -5.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00713  |\n",
      "|    n_updates        | 872499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -2.08    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5096     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10187    |\n",
      "|    total_timesteps  | 3592258  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0091   |\n",
      "|    n_updates        | 873064   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -2.01    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5100     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10199    |\n",
      "|    total_timesteps  | 3597347  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 874336   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3600000, episode_reward=-3.80 +/- 8.23\n",
      "Episode length: 1183.40 +/- 149.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -3.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 874999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.88    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5104     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10219    |\n",
      "|    total_timesteps  | 3602393  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 875598   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.64    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5108     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10230    |\n",
      "|    total_timesteps  | 3607148  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0061   |\n",
      "|    n_updates        | 876786   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3610000, episode_reward=-4.40 +/- 4.03\n",
      "Episode length: 1131.00 +/- 298.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | -4.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 877499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.66    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5112     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10251    |\n",
      "|    total_timesteps  | 3612562  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 878140   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.79    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5116     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10263    |\n",
      "|    total_timesteps  | 3617648  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.028    |\n",
      "|    n_updates        | 879411   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3620000, episode_reward=-3.80 +/- 4.66\n",
      "Episode length: 1149.40 +/- 336.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | -3.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 879999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -2.24    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5120     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10285    |\n",
      "|    total_timesteps  | 3623189  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00819  |\n",
      "|    n_updates        | 880797   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -2.27    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5124     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10298    |\n",
      "|    total_timesteps  | 3628603  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 882150   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3630000, episode_reward=-7.40 +/- 7.63\n",
      "Episode length: 1074.20 +/- 146.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -7.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00737  |\n",
      "|    n_updates        | 882499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -2.15    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5128     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10318    |\n",
      "|    total_timesteps  | 3633727  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 883431   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.88    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5132     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10330    |\n",
      "|    total_timesteps  | 3638840  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00963  |\n",
      "|    n_updates        | 884709   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3640000, episode_reward=-0.40 +/- 5.35\n",
      "Episode length: 1069.00 +/- 505.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00537  |\n",
      "|    n_updates        | 884999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.91    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5136     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 10353    |\n",
      "|    total_timesteps  | 3645438  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 886359   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3650000, episode_reward=1.60 +/- 3.77\n",
      "Episode length: 1056.20 +/- 342.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00821  |\n",
      "|    n_updates        | 887499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.68    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5140     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10375    |\n",
      "|    total_timesteps  | 3651257  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 887814   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.13    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5144     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10384    |\n",
      "|    total_timesteps  | 3655165  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 888791   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3660000, episode_reward=-0.80 +/- 6.79\n",
      "Episode length: 911.20 +/- 451.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 911      |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0269   |\n",
      "|    n_updates        | 889999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.1     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5148     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10404    |\n",
      "|    total_timesteps  | 3660789  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00732  |\n",
      "|    n_updates        | 890197   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.19    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5152     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10415    |\n",
      "|    total_timesteps  | 3665714  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00594  |\n",
      "|    n_updates        | 891428   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3670000, episode_reward=1.00 +/- 8.67\n",
      "Episode length: 989.40 +/- 328.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 989      |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00426  |\n",
      "|    n_updates        | 892499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.24    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5156     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10436    |\n",
      "|    total_timesteps  | 3671278  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 892819   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.79    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5160     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10447    |\n",
      "|    total_timesteps  | 3676019  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 894004   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3680000, episode_reward=-5.60 +/- 7.74\n",
      "Episode length: 935.20 +/- 250.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 935      |\n",
      "|    mean_reward      | -5.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0254   |\n",
      "|    n_updates        | 894999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.59    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5164     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10467    |\n",
      "|    total_timesteps  | 3681517  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00795  |\n",
      "|    n_updates        | 895379   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.47    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5168     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10479    |\n",
      "|    total_timesteps  | 3686644  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00749  |\n",
      "|    n_updates        | 896660   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3690000, episode_reward=-1.80 +/- 6.62\n",
      "Episode length: 1012.40 +/- 171.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0051   |\n",
      "|    n_updates        | 897499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.4     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5172     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10499    |\n",
      "|    total_timesteps  | 3692199  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 898049   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.46    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5176     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10512    |\n",
      "|    total_timesteps  | 3697393  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00635  |\n",
      "|    n_updates        | 899348   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3700000, episode_reward=0.40 +/- 3.77\n",
      "Episode length: 1120.00 +/- 124.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00552  |\n",
      "|    n_updates        | 899999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.31    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5180     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10531    |\n",
      "|    total_timesteps  | 3702188  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00641  |\n",
      "|    n_updates        | 900546   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5184     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10541    |\n",
      "|    total_timesteps  | 3706247  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 901561   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3710000, episode_reward=0.20 +/- 7.98\n",
      "Episode length: 980.00 +/- 235.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 980      |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 902499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5188     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10559    |\n",
      "|    total_timesteps  | 3711110  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 902777   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.65     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5192     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10570    |\n",
      "|    total_timesteps  | 3715875  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 903968   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3720000, episode_reward=1.40 +/- 1.36\n",
      "Episode length: 1116.60 +/- 448.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00924  |\n",
      "|    n_updates        | 904999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5196     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10592    |\n",
      "|    total_timesteps  | 3721328  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00682  |\n",
      "|    n_updates        | 905331   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5200     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10602    |\n",
      "|    total_timesteps  | 3725828  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 906456   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5204     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10612    |\n",
      "|    total_timesteps  | 3729803  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 907450   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3730000, episode_reward=-4.00 +/- 6.23\n",
      "Episode length: 1076.20 +/- 164.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | -4       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00844  |\n",
      "|    n_updates        | 907499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.34     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5208     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10632    |\n",
      "|    total_timesteps  | 3734944  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00845  |\n",
      "|    n_updates        | 908735   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5212     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10643    |\n",
      "|    total_timesteps  | 3739573  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00842  |\n",
      "|    n_updates        | 909893   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3740000, episode_reward=2.80 +/- 9.91\n",
      "Episode length: 992.00 +/- 115.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 992      |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 909999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.31     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5216     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10663    |\n",
      "|    total_timesteps  | 3745206  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00497  |\n",
      "|    n_updates        | 911301   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5220     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10673    |\n",
      "|    total_timesteps  | 3749304  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 912325   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3750000, episode_reward=-1.60 +/- 3.88\n",
      "Episode length: 1106.00 +/- 298.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -1.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00539  |\n",
      "|    n_updates        | 912499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5224     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10693    |\n",
      "|    total_timesteps  | 3754589  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 913647   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5228     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10705    |\n",
      "|    total_timesteps  | 3759345  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00883  |\n",
      "|    n_updates        | 914836   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3760000, episode_reward=-1.40 +/- 2.24\n",
      "Episode length: 1203.80 +/- 286.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | -1.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0312   |\n",
      "|    n_updates        | 914999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.49     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5232     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10726    |\n",
      "|    total_timesteps  | 3764757  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 916189   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5236     |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 10738    |\n",
      "|    total_timesteps  | 3769974  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 917493   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3770000, episode_reward=-3.40 +/- 5.61\n",
      "Episode length: 1179.40 +/- 84.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -3.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00775  |\n",
      "|    n_updates        | 917499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | 0.12     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5240     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10757    |\n",
      "|    total_timesteps  | 3774201  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0045   |\n",
      "|    n_updates        | 918550   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -0.26    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5244     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10768    |\n",
      "|    total_timesteps  | 3778926  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 919731   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3780000, episode_reward=0.20 +/- 7.76\n",
      "Episode length: 1060.40 +/- 196.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0267   |\n",
      "|    n_updates        | 919999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5248     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10787    |\n",
      "|    total_timesteps  | 3783843  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00752  |\n",
      "|    n_updates        | 920960   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5252     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10800    |\n",
      "|    total_timesteps  | 3789063  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 922265   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3790000, episode_reward=1.60 +/- 5.95\n",
      "Episode length: 953.20 +/- 383.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 953      |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 922499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5256     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10820    |\n",
      "|    total_timesteps  | 3794897  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 923724   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -0.17    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5260     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10832    |\n",
      "|    total_timesteps  | 3799849  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 924962   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3800000, episode_reward=5.00 +/- 3.63\n",
      "Episode length: 1170.20 +/- 107.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 5        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 924999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -0.32    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5264     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10852    |\n",
      "|    total_timesteps  | 3804578  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 926144   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -0.48    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5268     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10863    |\n",
      "|    total_timesteps  | 3809648  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 927411   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3810000, episode_reward=3.00 +/- 4.60\n",
      "Episode length: 1204.00 +/- 290.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00862  |\n",
      "|    n_updates        | 927499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -0.39    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5272     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10886    |\n",
      "|    total_timesteps  | 3815462  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 928865   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3820000, episode_reward=0.60 +/- 3.26\n",
      "Episode length: 1221.40 +/- 191.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 929999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -0.31    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5276     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10908    |\n",
      "|    total_timesteps  | 3821250  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00808  |\n",
      "|    n_updates        | 930312   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -0.38    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5280     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10919    |\n",
      "|    total_timesteps  | 3825989  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 931497   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3830000, episode_reward=-2.20 +/- 4.17\n",
      "Episode length: 1264.00 +/- 185.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 932499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -0.9     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5284     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10941    |\n",
      "|    total_timesteps  | 3831392  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 932847   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -1.11    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5288     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10952    |\n",
      "|    total_timesteps  | 3836040  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0292   |\n",
      "|    n_updates        | 934009   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3840000, episode_reward=2.40 +/- 4.59\n",
      "Episode length: 1087.40 +/- 438.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00845  |\n",
      "|    n_updates        | 934999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.18    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5292     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10975    |\n",
      "|    total_timesteps  | 3842317  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 935579   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -1.2     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5296     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 10986    |\n",
      "|    total_timesteps  | 3846738  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 936684   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3850000, episode_reward=2.60 +/- 5.54\n",
      "Episode length: 1096.60 +/- 478.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00685  |\n",
      "|    n_updates        | 937499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.55    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5300     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11007    |\n",
      "|    total_timesteps  | 3852461  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00778  |\n",
      "|    n_updates        | 938115   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.53    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5304     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 11019    |\n",
      "|    total_timesteps  | 3857462  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 939365   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3860000, episode_reward=-0.80 +/- 4.87\n",
      "Episode length: 1255.00 +/- 168.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 939999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.8     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5308     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11039    |\n",
      "|    total_timesteps  | 3862140  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0053   |\n",
      "|    n_updates        | 940534   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.7     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5312     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11050    |\n",
      "|    total_timesteps  | 3866975  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00694  |\n",
      "|    n_updates        | 941743   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3870000, episode_reward=-2.00 +/- 5.18\n",
      "Episode length: 1202.00 +/- 310.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 942499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.64    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5316     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11072    |\n",
      "|    total_timesteps  | 3872291  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00592  |\n",
      "|    n_updates        | 943072   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.47    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5320     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11083    |\n",
      "|    total_timesteps  | 3877301  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 944325   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3880000, episode_reward=-2.40 +/- 5.61\n",
      "Episode length: 1266.80 +/- 147.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | -2.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 944999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.5     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5324     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11105    |\n",
      "|    total_timesteps  | 3882531  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00939  |\n",
      "|    n_updates        | 945632   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.3     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5328     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11116    |\n",
      "|    total_timesteps  | 3887211  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00523  |\n",
      "|    n_updates        | 946802   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3890000, episode_reward=-3.80 +/- 7.11\n",
      "Episode length: 1057.20 +/- 176.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -3.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0405   |\n",
      "|    n_updates        | 947499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.42    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5332     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11136    |\n",
      "|    total_timesteps  | 3892296  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0381   |\n",
      "|    n_updates        | 948073   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.37    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5336     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11147    |\n",
      "|    total_timesteps  | 3897148  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 949286   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3900000, episode_reward=0.20 +/- 6.85\n",
      "Episode length: 1066.60 +/- 173.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 949999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.28    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5340     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11168    |\n",
      "|    total_timesteps  | 3902619  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00898  |\n",
      "|    n_updates        | 950654   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.19    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5344     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11179    |\n",
      "|    total_timesteps  | 3907531  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 951882   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3910000, episode_reward=0.80 +/- 3.54\n",
      "Episode length: 1342.80 +/- 78.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 952499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.34    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5348     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11200    |\n",
      "|    total_timesteps  | 3912234  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 953058   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.19    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5352     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11210    |\n",
      "|    total_timesteps  | 3916471  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 954117   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3920000, episode_reward=1.00 +/- 5.80\n",
      "Episode length: 1335.20 +/- 172.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 954999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.24    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5356     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11231    |\n",
      "|    total_timesteps  | 3921270  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00708  |\n",
      "|    n_updates        | 955317   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.38    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5360     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11243    |\n",
      "|    total_timesteps  | 3926169  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 956542   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3930000, episode_reward=-2.60 +/- 6.50\n",
      "Episode length: 1128.60 +/- 145.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | -2.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00601  |\n",
      "|    n_updates        | 957499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.17    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5364     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11263    |\n",
      "|    total_timesteps  | 3931378  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00571  |\n",
      "|    n_updates        | 957844   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.05    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5368     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11275    |\n",
      "|    total_timesteps  | 3936322  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 959080   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3940000, episode_reward=3.00 +/- 6.78\n",
      "Episode length: 936.40 +/- 417.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 936      |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 959999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.08    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5372     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11296    |\n",
      "|    total_timesteps  | 3942723  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00513  |\n",
      "|    n_updates        | 960680   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.24    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5376     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 11307    |\n",
      "|    total_timesteps  | 3947319  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0407   |\n",
      "|    n_updates        | 961829   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3950000, episode_reward=2.40 +/- 5.39\n",
      "Episode length: 1136.20 +/- 207.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00381  |\n",
      "|    n_updates        | 962499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -1.29    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5380     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11327    |\n",
      "|    total_timesteps  | 3952159  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 963039   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -0.89    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5384     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11337    |\n",
      "|    total_timesteps  | 3956560  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 964139   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3960000, episode_reward=3.60 +/- 5.00\n",
      "Episode length: 1094.20 +/- 244.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 964999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.82    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5388     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11358    |\n",
      "|    total_timesteps  | 3962274  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00825  |\n",
      "|    n_updates        | 965568   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -0.59    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5392     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11370    |\n",
      "|    total_timesteps  | 3967133  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00889  |\n",
      "|    n_updates        | 966783   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3970000, episode_reward=-3.20 +/- 4.02\n",
      "Episode length: 1193.60 +/- 261.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | -3.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 967499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.51    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5396     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11391    |\n",
      "|    total_timesteps  | 3972479  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00865  |\n",
      "|    n_updates        | 968119   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -0.15    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5400     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11403    |\n",
      "|    total_timesteps  | 3977398  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 969349   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3980000, episode_reward=-4.40 +/- 5.68\n",
      "Episode length: 1191.40 +/- 213.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | -4.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 969999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5404     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11423    |\n",
      "|    total_timesteps  | 3982405  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00712  |\n",
      "|    n_updates        | 970601   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.42     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5408     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11434    |\n",
      "|    total_timesteps  | 3987336  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 971833   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3990000, episode_reward=-1.40 +/- 6.12\n",
      "Episode length: 1295.40 +/- 134.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.3e+03  |\n",
      "|    mean_reward      | -1.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 972499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5412     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11456    |\n",
      "|    total_timesteps  | 3992628  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00724  |\n",
      "|    n_updates        | 973156   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.44     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5416     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11466    |\n",
      "|    total_timesteps  | 3997124  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 974280   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4000000, episode_reward=0.80 +/- 7.55\n",
      "Episode length: 1136.00 +/- 253.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 974999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5420     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11487    |\n",
      "|    total_timesteps  | 4002273  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00403  |\n",
      "|    n_updates        | 975568   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5424     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11499    |\n",
      "|    total_timesteps  | 4007450  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 976862   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4010000, episode_reward=-3.00 +/- 2.76\n",
      "Episode length: 1213.00 +/- 151.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | -3       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 977499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.28     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5428     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11520    |\n",
      "|    total_timesteps  | 4012520  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 978129   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5432     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11532    |\n",
      "|    total_timesteps  | 4017574  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 979393   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4020000, episode_reward=1.40 +/- 4.84\n",
      "Episode length: 1261.40 +/- 138.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00706  |\n",
      "|    n_updates        | 979999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.29     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5436     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11551    |\n",
      "|    total_timesteps  | 4021913  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00893  |\n",
      "|    n_updates        | 980478   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.62     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5440     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11562    |\n",
      "|    total_timesteps  | 4026633  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00715  |\n",
      "|    n_updates        | 981658   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4030000, episode_reward=-3.00 +/- 3.16\n",
      "Episode length: 1240.20 +/- 187.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | -3       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 982499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5444     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11583    |\n",
      "|    total_timesteps  | 4031398  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 982849   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5448     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11594    |\n",
      "|    total_timesteps  | 4036458  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 984114   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4040000, episode_reward=2.40 +/- 5.71\n",
      "Episode length: 1171.60 +/- 95.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 984999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5452     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11614    |\n",
      "|    total_timesteps  | 4041114  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 985278   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.29     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5456     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 11626    |\n",
      "|    total_timesteps  | 4046354  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00293  |\n",
      "|    n_updates        | 986588   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4050000, episode_reward=0.60 +/- 7.28\n",
      "Episode length: 1136.80 +/- 124.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00407  |\n",
      "|    n_updates        | 987499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5460     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11646    |\n",
      "|    total_timesteps  | 4051375  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00698  |\n",
      "|    n_updates        | 987843   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5464     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11658    |\n",
      "|    total_timesteps  | 4056436  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 989108   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4060000, episode_reward=4.40 +/- 4.22\n",
      "Episode length: 999.00 +/- 410.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 999      |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 989999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.36     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5468     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11678    |\n",
      "|    total_timesteps  | 4062019  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00699  |\n",
      "|    n_updates        | 990504   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | 0.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5472     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11688    |\n",
      "|    total_timesteps  | 4066158  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00389  |\n",
      "|    n_updates        | 991539   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4070000, episode_reward=-3.60 +/- 4.88\n",
      "Episode length: 999.60 +/- 524.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00748  |\n",
      "|    n_updates        | 992499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5476     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11709    |\n",
      "|    total_timesteps  | 4072254  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00696  |\n",
      "|    n_updates        | 993063   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5480     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11720    |\n",
      "|    total_timesteps  | 4076637  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 994159   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4080000, episode_reward=4.60 +/- 5.00\n",
      "Episode length: 1000.20 +/- 401.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 994999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.21    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5484     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11741    |\n",
      "|    total_timesteps  | 4082660  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 995664   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -0.22    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5488     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11752    |\n",
      "|    total_timesteps  | 4087287  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00403  |\n",
      "|    n_updates        | 996821   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4090000, episode_reward=-2.00 +/- 4.34\n",
      "Episode length: 1185.80 +/- 433.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 997499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -0.48    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5492     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11772    |\n",
      "|    total_timesteps  | 4092287  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 998071   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -0.67    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5496     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11783    |\n",
      "|    total_timesteps  | 4096815  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 999203   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4100000, episode_reward=3.40 +/- 1.62\n",
      "Episode length: 1306.60 +/- 235.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 999999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -0.86    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5500     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11806    |\n",
      "|    total_timesteps  | 4102640  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00548  |\n",
      "|    n_updates        | 1000659  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -1.17    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5504     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11817    |\n",
      "|    total_timesteps  | 4107299  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 1001824  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4110000, episode_reward=2.80 +/- 5.74\n",
      "Episode length: 1095.40 +/- 109.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 1002499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -0.8     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5508     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11837    |\n",
      "|    total_timesteps  | 4112369  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00872  |\n",
      "|    n_updates        | 1003092  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -0.91    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5512     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11850    |\n",
      "|    total_timesteps  | 4117697  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00841  |\n",
      "|    n_updates        | 1004424  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4120000, episode_reward=-4.00 +/- 6.36\n",
      "Episode length: 887.00 +/- 442.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 887      |\n",
      "|    mean_reward      | -4       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00897  |\n",
      "|    n_updates        | 1004999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.87    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5516     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11869    |\n",
      "|    total_timesteps  | 4123240  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00845  |\n",
      "|    n_updates        | 1005809  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -0.96    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5520     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11883    |\n",
      "|    total_timesteps  | 4128936  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00945  |\n",
      "|    n_updates        | 1007233  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4130000, episode_reward=-0.20 +/- 3.97\n",
      "Episode length: 1034.40 +/- 431.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -0.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00927  |\n",
      "|    n_updates        | 1007499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.08    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5524     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11904    |\n",
      "|    total_timesteps  | 4134794  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 1008698  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.05    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5528     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11914    |\n",
      "|    total_timesteps  | 4139240  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 1009809  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4140000, episode_reward=-0.80 +/- 6.71\n",
      "Episode length: 1025.40 +/- 364.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0031   |\n",
      "|    n_updates        | 1009999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.29    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5532     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11936    |\n",
      "|    total_timesteps  | 4145287  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00803  |\n",
      "|    n_updates        | 1011321  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4150000, episode_reward=0.20 +/- 6.94\n",
      "Episode length: 963.00 +/- 292.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 963      |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0208   |\n",
      "|    n_updates        | 1012499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.15    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5536     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11956    |\n",
      "|    total_timesteps  | 4150866  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 1012716  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.35    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5540     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11967    |\n",
      "|    total_timesteps  | 4155661  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00391  |\n",
      "|    n_updates        | 1013915  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4160000, episode_reward=2.60 +/- 6.71\n",
      "Episode length: 918.40 +/- 438.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 918      |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00683  |\n",
      "|    n_updates        | 1014999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.49    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5544     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11987    |\n",
      "|    total_timesteps  | 4160888  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 1015221  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.62    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5548     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 11997    |\n",
      "|    total_timesteps  | 4165241  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00529  |\n",
      "|    n_updates        | 1016310  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4170000, episode_reward=-1.80 +/- 4.35\n",
      "Episode length: 1101.40 +/- 570.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 1017499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.74    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5552     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 12019    |\n",
      "|    total_timesteps  | 4171312  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0055   |\n",
      "|    n_updates        | 1017827  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.82    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5556     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 12030    |\n",
      "|    total_timesteps  | 4175874  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0057   |\n",
      "|    n_updates        | 1018968  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4180000, episode_reward=-4.60 +/- 5.99\n",
      "Episode length: 1056.20 +/- 265.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -4.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00611  |\n",
      "|    n_updates        | 1019999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.99    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5560     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12050    |\n",
      "|    total_timesteps  | 4181262  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00849  |\n",
      "|    n_updates        | 1020315  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -2.02    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5564     |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 12062    |\n",
      "|    total_timesteps  | 4186301  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00493  |\n",
      "|    n_updates        | 1021575  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4190000, episode_reward=0.80 +/- 5.49\n",
      "Episode length: 1170.40 +/- 117.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0237   |\n",
      "|    n_updates        | 1022499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -2.27    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5568     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12082    |\n",
      "|    total_timesteps  | 4191144  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0054   |\n",
      "|    n_updates        | 1022785  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -2.2     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5572     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12094    |\n",
      "|    total_timesteps  | 4196168  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 1024041  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4200000, episode_reward=-1.40 +/- 3.26\n",
      "Episode length: 1159.20 +/- 492.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | -1.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 1024999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -2.24    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5576     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12117    |\n",
      "|    total_timesteps  | 4202688  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00343  |\n",
      "|    n_updates        | 1025671  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -2.26    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5580     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12129    |\n",
      "|    total_timesteps  | 4207353  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00536  |\n",
      "|    n_updates        | 1026838  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4210000, episode_reward=2.00 +/- 3.69\n",
      "Episode length: 1152.60 +/- 74.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 1027499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -2.16    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5584     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12149    |\n",
      "|    total_timesteps  | 4212294  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00622  |\n",
      "|    n_updates        | 1028073  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -2.24    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5588     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12160    |\n",
      "|    total_timesteps  | 4217091  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00668  |\n",
      "|    n_updates        | 1029272  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4220000, episode_reward=4.00 +/- 6.20\n",
      "Episode length: 1147.20 +/- 270.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 1029999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -2.02    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5592     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12181    |\n",
      "|    total_timesteps  | 4222588  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00773  |\n",
      "|    n_updates        | 1030646  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -2.21    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5596     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12192    |\n",
      "|    total_timesteps  | 4227274  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 1031818  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4230000, episode_reward=-3.20 +/- 4.66\n",
      "Episode length: 1113.20 +/- 51.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -3.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 1032499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.97    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5600     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12213    |\n",
      "|    total_timesteps  | 4232655  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00941  |\n",
      "|    n_updates        | 1033163  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.64    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5604     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12225    |\n",
      "|    total_timesteps  | 4237746  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 1034436  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4240000, episode_reward=-5.40 +/- 4.27\n",
      "Episode length: 1027.40 +/- 513.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -5.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 1034999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.96    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5608     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12247    |\n",
      "|    total_timesteps  | 4243777  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1035944  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.83    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5612     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12258    |\n",
      "|    total_timesteps  | 4248669  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00313  |\n",
      "|    n_updates        | 1037167  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4250000, episode_reward=4.60 +/- 2.42\n",
      "Episode length: 1257.40 +/- 62.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 1037499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.72    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5616     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12279    |\n",
      "|    total_timesteps  | 4253592  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0075   |\n",
      "|    n_updates        | 1038397  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.79    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5620     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12290    |\n",
      "|    total_timesteps  | 4258273  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00638  |\n",
      "|    n_updates        | 1039568  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4260000, episode_reward=-0.80 +/- 3.19\n",
      "Episode length: 1383.20 +/- 295.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.38e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00768  |\n",
      "|    n_updates        | 1039999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.63    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5624     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12313    |\n",
      "|    total_timesteps  | 4263824  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00844  |\n",
      "|    n_updates        | 1040955  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.63    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5628     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12326    |\n",
      "|    total_timesteps  | 4269096  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 1042273  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4270000, episode_reward=-1.80 +/- 7.33\n",
      "Episode length: 976.80 +/- 347.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 977      |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 1042499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.4     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5632     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12347    |\n",
      "|    total_timesteps  | 4275129  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 1043782  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.56    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5636     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12358    |\n",
      "|    total_timesteps  | 4279667  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 1044916  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4280000, episode_reward=1.00 +/- 4.73\n",
      "Episode length: 1238.00 +/- 147.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 1044999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.82    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5640     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12380    |\n",
      "|    total_timesteps  | 4285235  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 1046308  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4290000, episode_reward=2.40 +/- 2.50\n",
      "Episode length: 1083.80 +/- 486.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 1047499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.48    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5644     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12403    |\n",
      "|    total_timesteps  | 4291415  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0081   |\n",
      "|    n_updates        | 1047853  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.65    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5648     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12415    |\n",
      "|    total_timesteps  | 4296799  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 1049199  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4300000, episode_reward=4.60 +/- 7.14\n",
      "Episode length: 1158.80 +/- 29.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 1049999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.46    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5652     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12437    |\n",
      "|    total_timesteps  | 4302500  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 1050624  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.46    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5656     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 12448    |\n",
      "|    total_timesteps  | 4307217  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00893  |\n",
      "|    n_updates        | 1051804  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4310000, episode_reward=0.00 +/- 7.87\n",
      "Episode length: 1185.80 +/- 168.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 0        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 1052499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.18    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5660     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12469    |\n",
      "|    total_timesteps  | 4312499  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00523  |\n",
      "|    n_updates        | 1053124  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.3     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5664     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12480    |\n",
      "|    total_timesteps  | 4317124  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00528  |\n",
      "|    n_updates        | 1054280  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4320000, episode_reward=-1.00 +/- 6.42\n",
      "Episode length: 1169.40 +/- 184.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -1       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00483  |\n",
      "|    n_updates        | 1054999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.93    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5668     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12500    |\n",
      "|    total_timesteps  | 4322295  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 1055573  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.01    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5672     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12513    |\n",
      "|    total_timesteps  | 4327768  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 1056941  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4330000, episode_reward=5.20 +/- 4.02\n",
      "Episode length: 1010.00 +/- 439.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 1057499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.94    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5676     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12534    |\n",
      "|    total_timesteps  | 4333237  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 1058309  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.85    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5680     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12545    |\n",
      "|    total_timesteps  | 4338055  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 1059513  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4340000, episode_reward=1.40 +/- 5.31\n",
      "Episode length: 1138.80 +/- 218.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00892  |\n",
      "|    n_updates        | 1059999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.04    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5684     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12565    |\n",
      "|    total_timesteps  | 4343057  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 1060764  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.01    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5688     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12576    |\n",
      "|    total_timesteps  | 4347819  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00648  |\n",
      "|    n_updates        | 1061954  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4350000, episode_reward=-5.80 +/- 6.85\n",
      "Episode length: 1016.40 +/- 349.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -5.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00671  |\n",
      "|    n_updates        | 1062499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1       |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5692     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12596    |\n",
      "|    total_timesteps  | 4353259  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 1063314  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.71    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5696     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12607    |\n",
      "|    total_timesteps  | 4358033  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 1064508  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4360000, episode_reward=-0.80 +/- 3.12\n",
      "Episode length: 1230.60 +/- 341.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00914  |\n",
      "|    n_updates        | 1064999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.76    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5700     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12630    |\n",
      "|    total_timesteps  | 4363584  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00839  |\n",
      "|    n_updates        | 1065895  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.16    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5704     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12640    |\n",
      "|    total_timesteps  | 4368178  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00992  |\n",
      "|    n_updates        | 1067044  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4370000, episode_reward=-1.80 +/- 7.93\n",
      "Episode length: 1083.20 +/- 357.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 1067499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.3     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5708     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12661    |\n",
      "|    total_timesteps  | 4373768  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 1068441  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5712     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12673    |\n",
      "|    total_timesteps  | 4378845  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0059   |\n",
      "|    n_updates        | 1069711  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4380000, episode_reward=-3.20 +/- 3.54\n",
      "Episode length: 1029.60 +/- 464.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -3.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 1069999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.32    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5716     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12695    |\n",
      "|    total_timesteps  | 4384782  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00537  |\n",
      "|    n_updates        | 1071195  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.87    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5720     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12705    |\n",
      "|    total_timesteps  | 4389356  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 1072338  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4390000, episode_reward=1.20 +/- 6.24\n",
      "Episode length: 1104.80 +/- 274.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 1072499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.76    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5724     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12726    |\n",
      "|    total_timesteps  | 4394727  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 1073681  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.76    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5728     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12737    |\n",
      "|    total_timesteps  | 4399195  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0413   |\n",
      "|    n_updates        | 1074798  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4400000, episode_reward=0.80 +/- 9.99\n",
      "Episode length: 902.00 +/- 342.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 902      |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 1074999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.65    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5732     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12756    |\n",
      "|    total_timesteps  | 4404621  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 1076155  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.86    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5736     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12768    |\n",
      "|    total_timesteps  | 4409786  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0303   |\n",
      "|    n_updates        | 1077446  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4410000, episode_reward=-1.60 +/- 7.99\n",
      "Episode length: 1130.80 +/- 120.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | -1.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00664  |\n",
      "|    n_updates        | 1077499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.87    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5740     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12790    |\n",
      "|    total_timesteps  | 4415311  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 1078827  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.17    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5744     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12801    |\n",
      "|    total_timesteps  | 4419981  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 1079995  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4420000, episode_reward=-4.80 +/- 3.92\n",
      "Episode length: 1349.40 +/- 214.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.35e+03 |\n",
      "|    mean_reward      | -4.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0066   |\n",
      "|    n_updates        | 1079999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.13    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5748     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12823    |\n",
      "|    total_timesteps  | 4425058  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00753  |\n",
      "|    n_updates        | 1081264  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4430000, episode_reward=1.20 +/- 6.71\n",
      "Episode length: 1022.40 +/- 469.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 1082499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.25    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5752     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 12845    |\n",
      "|    total_timesteps  | 4431288  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0263   |\n",
      "|    n_updates        | 1082821  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.09    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5756     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 12856    |\n",
      "|    total_timesteps  | 4435846  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 1083961  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4440000, episode_reward=7.40 +/- 4.50\n",
      "Episode length: 1168.00 +/- 230.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 7.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00638  |\n",
      "|    n_updates        | 1084999  |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.39    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5760     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 12877    |\n",
      "|    total_timesteps  | 4441469  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 1085367  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.42    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5764     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 12889    |\n",
      "|    total_timesteps  | 4446213  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00665  |\n",
      "|    n_updates        | 1086553  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4450000, episode_reward=1.00 +/- 4.05\n",
      "Episode length: 1217.60 +/- 106.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 1087499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.25    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5768     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 12909    |\n",
      "|    total_timesteps  | 4451277  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00673  |\n",
      "|    n_updates        | 1087819  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.19    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5772     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 12921    |\n",
      "|    total_timesteps  | 4456379  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00907  |\n",
      "|    n_updates        | 1089094  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4460000, episode_reward=1.40 +/- 8.04\n",
      "Episode length: 1021.80 +/- 314.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 1089999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.17    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5776     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 12944    |\n",
      "|    total_timesteps  | 4462728  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00864  |\n",
      "|    n_updates        | 1090681  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.09    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5780     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 12956    |\n",
      "|    total_timesteps  | 4467771  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00909  |\n",
      "|    n_updates        | 1091942  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4470000, episode_reward=2.00 +/- 3.58\n",
      "Episode length: 1148.20 +/- 360.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00997  |\n",
      "|    n_updates        | 1092499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.07    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5784     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 12978    |\n",
      "|    total_timesteps  | 4473658  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 1093414  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1       |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5788     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 12988    |\n",
      "|    total_timesteps  | 4477943  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 1094485  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4480000, episode_reward=5.40 +/- 2.80\n",
      "Episode length: 1056.80 +/- 387.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 5.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 1094999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.29    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5792     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13009    |\n",
      "|    total_timesteps  | 4483643  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 1095910  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.31    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5796     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13022    |\n",
      "|    total_timesteps  | 4489121  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 1097280  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4490000, episode_reward=7.00 +/- 2.28\n",
      "Episode length: 1001.20 +/- 316.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 7        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 1097499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.77    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5800     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13042    |\n",
      "|    total_timesteps  | 4494303  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 1098575  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.69    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5804     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13052    |\n",
      "|    total_timesteps  | 4498750  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 1099687  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4500000, episode_reward=-3.80 +/- 4.31\n",
      "Episode length: 1050.20 +/- 516.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | -3.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0272   |\n",
      "|    n_updates        | 1099999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.71    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5808     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13074    |\n",
      "|    total_timesteps  | 4504792  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00597  |\n",
      "|    n_updates        | 1101197  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.7     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5812     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13085    |\n",
      "|    total_timesteps  | 4509434  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 1102358  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4510000, episode_reward=-1.80 +/- 4.66\n",
      "Episode length: 1112.20 +/- 267.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 1102499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.56    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5816     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13106    |\n",
      "|    total_timesteps  | 4514861  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00451  |\n",
      "|    n_updates        | 1103715  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.6     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5820     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13117    |\n",
      "|    total_timesteps  | 4519712  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00715  |\n",
      "|    n_updates        | 1104927  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4520000, episode_reward=-3.20 +/- 5.31\n",
      "Episode length: 1176.00 +/- 268.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -3.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00727  |\n",
      "|    n_updates        | 1104999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.81    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5824     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13138    |\n",
      "|    total_timesteps  | 4524950  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00999  |\n",
      "|    n_updates        | 1106237  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.78    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5828     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13150    |\n",
      "|    total_timesteps  | 4529875  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00935  |\n",
      "|    n_updates        | 1107468  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4530000, episode_reward=0.20 +/- 5.84\n",
      "Episode length: 1213.60 +/- 142.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00633  |\n",
      "|    n_updates        | 1107499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.99    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5832     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13170    |\n",
      "|    total_timesteps  | 4535064  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00529  |\n",
      "|    n_updates        | 1108765  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.72    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5836     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13181    |\n",
      "|    total_timesteps  | 4539486  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00968  |\n",
      "|    n_updates        | 1109871  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4540000, episode_reward=-5.20 +/- 6.88\n",
      "Episode length: 1065.40 +/- 244.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -5.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00772  |\n",
      "|    n_updates        | 1109999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.41    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5840     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13202    |\n",
      "|    total_timesteps  | 4545131  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 1111282  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4550000, episode_reward=4.40 +/- 2.33\n",
      "Episode length: 1058.60 +/- 356.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00872  |\n",
      "|    n_updates        | 1112499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.46    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5844     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13224    |\n",
      "|    total_timesteps  | 4551223  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00789  |\n",
      "|    n_updates        | 1112805  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.38    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5848     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13235    |\n",
      "|    total_timesteps  | 4556114  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 1114028  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4560000, episode_reward=0.40 +/- 5.78\n",
      "Episode length: 999.80 +/- 403.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00478  |\n",
      "|    n_updates        | 1114999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.49    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5852     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13257    |\n",
      "|    total_timesteps  | 4562464  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00561  |\n",
      "|    n_updates        | 1115615  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.6     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5856     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13267    |\n",
      "|    total_timesteps  | 4566955  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0347   |\n",
      "|    n_updates        | 1116738  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4570000, episode_reward=4.00 +/- 2.00\n",
      "Episode length: 1123.60 +/- 362.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0034   |\n",
      "|    n_updates        | 1117499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.24    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5860     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13289    |\n",
      "|    total_timesteps  | 4572654  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00898  |\n",
      "|    n_updates        | 1118163  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.12    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5864     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13301    |\n",
      "|    total_timesteps  | 4577826  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 1119456  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4580000, episode_reward=0.40 +/- 9.60\n",
      "Episode length: 1062.40 +/- 180.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00449  |\n",
      "|    n_updates        | 1119999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.36    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5868     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13320    |\n",
      "|    total_timesteps  | 4582653  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 1120663  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.37    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5872     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 13333    |\n",
      "|    total_timesteps  | 4587920  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 1121979  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4590000, episode_reward=1.80 +/- 5.19\n",
      "Episode length: 1266.00 +/- 113.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00498  |\n",
      "|    n_updates        | 1122499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.54    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5876     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13353    |\n",
      "|    total_timesteps  | 4592665  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00806  |\n",
      "|    n_updates        | 1123166  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.44    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5880     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13364    |\n",
      "|    total_timesteps  | 4597168  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0281   |\n",
      "|    n_updates        | 1124291  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4600000, episode_reward=-6.40 +/- 5.82\n",
      "Episode length: 1106.40 +/- 271.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -6.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 1124999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.22    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5884     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13384    |\n",
      "|    total_timesteps  | 4602478  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 1125619  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.11    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5888     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13396    |\n",
      "|    total_timesteps  | 4607379  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00622  |\n",
      "|    n_updates        | 1126844  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4610000, episode_reward=-0.20 +/- 3.25\n",
      "Episode length: 1308.40 +/- 124.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | -0.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00486  |\n",
      "|    n_updates        | 1127499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.76    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5892     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13417    |\n",
      "|    total_timesteps  | 4612110  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 1128027  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.65    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5896     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13428    |\n",
      "|    total_timesteps  | 4617147  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0291   |\n",
      "|    n_updates        | 1129286  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4620000, episode_reward=4.00 +/- 6.57\n",
      "Episode length: 1161.80 +/- 255.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 1129999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5900     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13448    |\n",
      "|    total_timesteps  | 4621925  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 1130481  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5904     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13459    |\n",
      "|    total_timesteps  | 4626581  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00346  |\n",
      "|    n_updates        | 1131645  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4630000, episode_reward=2.40 +/- 3.61\n",
      "Episode length: 992.60 +/- 396.70\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 993      |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00939  |\n",
      "|    n_updates        | 1132499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5908     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13479    |\n",
      "|    total_timesteps  | 4632198  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00264  |\n",
      "|    n_updates        | 1133049  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5912     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13491    |\n",
      "|    total_timesteps  | 4636994  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0406   |\n",
      "|    n_updates        | 1134248  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4640000, episode_reward=-3.40 +/- 8.59\n",
      "Episode length: 1030.20 +/- 256.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -3.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00567  |\n",
      "|    n_updates        | 1134999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.34     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5916     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13512    |\n",
      "|    total_timesteps  | 4642811  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00545  |\n",
      "|    n_updates        | 1135702  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5920     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13524    |\n",
      "|    total_timesteps  | 4647914  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00793  |\n",
      "|    n_updates        | 1136978  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4650000, episode_reward=5.60 +/- 6.28\n",
      "Episode length: 1015.40 +/- 416.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0196   |\n",
      "|    n_updates        | 1137499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5924     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13543    |\n",
      "|    total_timesteps  | 4653105  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 1138276  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.19     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5928     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13555    |\n",
      "|    total_timesteps  | 4658249  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00475  |\n",
      "|    n_updates        | 1139562  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4660000, episode_reward=-3.20 +/- 5.34\n",
      "Episode length: 1283.40 +/- 140.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | -3.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 1139999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.29     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5932     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13576    |\n",
      "|    total_timesteps  | 4663016  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00891  |\n",
      "|    n_updates        | 1140753  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5936     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13587    |\n",
      "|    total_timesteps  | 4667861  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 1141965  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4670000, episode_reward=2.40 +/- 7.42\n",
      "Episode length: 1009.60 +/- 372.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00687  |\n",
      "|    n_updates        | 1142499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.08    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5940     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13608    |\n",
      "|    total_timesteps  | 4673532  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 1143382  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -0.01    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5944     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13620    |\n",
      "|    total_timesteps  | 4678722  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 1144680  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4680000, episode_reward=-2.80 +/- 5.08\n",
      "Episode length: 1199.40 +/- 112.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | -2.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 1144999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5948     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13639    |\n",
      "|    total_timesteps  | 4683105  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0268   |\n",
      "|    n_updates        | 1145776  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5952     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13651    |\n",
      "|    total_timesteps  | 4687934  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00578  |\n",
      "|    n_updates        | 1146983  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4690000, episode_reward=-5.80 +/- 5.38\n",
      "Episode length: 1063.40 +/- 371.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -5.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 1147499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.19     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5956     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13671    |\n",
      "|    total_timesteps  | 4693418  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 1148354  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5960     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13681    |\n",
      "|    total_timesteps  | 4697644  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00639  |\n",
      "|    n_updates        | 1149410  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4700000, episode_reward=-2.00 +/- 5.59\n",
      "Episode length: 1353.40 +/- 112.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.35e+03 |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00437  |\n",
      "|    n_updates        | 1149999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.27     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5964     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13703    |\n",
      "|    total_timesteps  | 4702683  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00435  |\n",
      "|    n_updates        | 1150670  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.15     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5968     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13714    |\n",
      "|    total_timesteps  | 4707434  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0301   |\n",
      "|    n_updates        | 1151858  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4710000, episode_reward=-2.80 +/- 4.87\n",
      "Episode length: 1301.60 +/- 157.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.3e+03  |\n",
      "|    mean_reward      | -2.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00664  |\n",
      "|    n_updates        | 1152499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.11     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5972     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13736    |\n",
      "|    total_timesteps  | 4712530  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00789  |\n",
      "|    n_updates        | 1153132  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5976     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13747    |\n",
      "|    total_timesteps  | 4717326  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 1154331  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4720000, episode_reward=3.40 +/- 5.82\n",
      "Episode length: 1278.80 +/- 126.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0301   |\n",
      "|    n_updates        | 1154999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5980     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13767    |\n",
      "|    total_timesteps  | 4722069  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1155517  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.13     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5984     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13778    |\n",
      "|    total_timesteps  | 4726775  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00524  |\n",
      "|    n_updates        | 1156693  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4730000, episode_reward=0.00 +/- 8.76\n",
      "Episode length: 935.00 +/- 347.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 935      |\n",
      "|    mean_reward      | 0        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1157499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5988     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13798    |\n",
      "|    total_timesteps  | 4732211  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 1158052  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -0.24    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5992     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 13809    |\n",
      "|    total_timesteps  | 4736641  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00974  |\n",
      "|    n_updates        | 1159160  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4740000, episode_reward=-1.00 +/- 7.97\n",
      "Episode length: 997.20 +/- 519.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 997      |\n",
      "|    mean_reward      | -1       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 1159999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.27    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5996     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13831    |\n",
      "|    total_timesteps  | 4742787  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 1160696  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.57    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6000     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13843    |\n",
      "|    total_timesteps  | 4747883  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 1161970  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4750000, episode_reward=4.00 +/- 4.77\n",
      "Episode length: 1062.60 +/- 398.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 1162499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.41    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6004     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13866    |\n",
      "|    total_timesteps  | 4754305  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 1163576  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -0.6     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6008     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13877    |\n",
      "|    total_timesteps  | 4759213  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0065   |\n",
      "|    n_updates        | 1164803  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4760000, episode_reward=5.20 +/- 4.17\n",
      "Episode length: 1185.20 +/- 165.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00358  |\n",
      "|    n_updates        | 1164999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -0.79    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6012     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13897    |\n",
      "|    total_timesteps  | 4763937  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0331   |\n",
      "|    n_updates        | 1165984  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.76    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6016     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13909    |\n",
      "|    total_timesteps  | 4769037  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00379  |\n",
      "|    n_updates        | 1167259  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4770000, episode_reward=-0.40 +/- 7.84\n",
      "Episode length: 1002.00 +/- 333.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 1167499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.61    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6020     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13929    |\n",
      "|    total_timesteps  | 4774228  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 1168556  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.93    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6024     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13939    |\n",
      "|    total_timesteps  | 4778687  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0367   |\n",
      "|    n_updates        | 1169671  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4780000, episode_reward=-1.00 +/- 5.90\n",
      "Episode length: 1173.60 +/- 88.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -1       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 1169999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.9     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6028     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13960    |\n",
      "|    total_timesteps  | 4783880  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00775  |\n",
      "|    n_updates        | 1170969  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.99    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6032     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13973    |\n",
      "|    total_timesteps  | 4789329  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 1172332  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4790000, episode_reward=7.80 +/- 4.40\n",
      "Episode length: 1089.80 +/- 234.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 7.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0075   |\n",
      "|    n_updates        | 1172499  |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -1.03    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6036     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 13996    |\n",
      "|    total_timesteps  | 4795217  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00849  |\n",
      "|    n_updates        | 1173804  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.82    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6040     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14008    |\n",
      "|    total_timesteps  | 4799976  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 1174993  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4800000, episode_reward=1.40 +/- 7.74\n",
      "Episode length: 1179.00 +/- 209.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1174999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.91    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6044     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14029    |\n",
      "|    total_timesteps  | 4805035  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00741  |\n",
      "|    n_updates        | 1176258  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4810000, episode_reward=4.00 +/- 4.24\n",
      "Episode length: 1028.60 +/- 492.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00717  |\n",
      "|    n_updates        | 1177499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.3     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6048     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14050    |\n",
      "|    total_timesteps  | 4811153  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 1177788  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.14    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6052     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14063    |\n",
      "|    total_timesteps  | 4816433  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 1179108  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4820000, episode_reward=0.40 +/- 4.41\n",
      "Episode length: 1156.20 +/- 390.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00787  |\n",
      "|    n_updates        | 1179999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.82    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6056     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14083    |\n",
      "|    total_timesteps  | 4821214  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00628  |\n",
      "|    n_updates        | 1180303  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.08    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6060     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14095    |\n",
      "|    total_timesteps  | 4826301  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 1181575  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4830000, episode_reward=-3.20 +/- 7.19\n",
      "Episode length: 1173.60 +/- 210.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -3.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 1182499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.01    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6064     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14115    |\n",
      "|    total_timesteps  | 4831122  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00435  |\n",
      "|    n_updates        | 1182780  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.07    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6068     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14126    |\n",
      "|    total_timesteps  | 4835869  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00988  |\n",
      "|    n_updates        | 1183967  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4840000, episode_reward=1.80 +/- 5.49\n",
      "Episode length: 1263.40 +/- 250.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 1184999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.98    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6072     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14148    |\n",
      "|    total_timesteps  | 4841123  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1185280  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.89    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6076     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14160    |\n",
      "|    total_timesteps  | 4846137  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0315   |\n",
      "|    n_updates        | 1186534  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4850000, episode_reward=0.80 +/- 2.40\n",
      "Episode length: 1254.20 +/- 365.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.25e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00769  |\n",
      "|    n_updates        | 1187499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.73    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6080     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14182    |\n",
      "|    total_timesteps  | 4851461  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 1187865  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -1.03    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6084     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14193    |\n",
      "|    total_timesteps  | 4856282  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 1189070  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4860000, episode_reward=1.00 +/- 5.93\n",
      "Episode length: 1220.00 +/- 251.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00784  |\n",
      "|    n_updates        | 1189999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.03    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6088     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14214    |\n",
      "|    total_timesteps  | 4861367  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0269   |\n",
      "|    n_updates        | 1190341  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.71    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6092     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14226    |\n",
      "|    total_timesteps  | 4866358  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00546  |\n",
      "|    n_updates        | 1191589  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4870000, episode_reward=3.00 +/- 8.44\n",
      "Episode length: 1061.20 +/- 234.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00915  |\n",
      "|    n_updates        | 1192499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1       |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6096     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14245    |\n",
      "|    total_timesteps  | 4871059  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 1192764  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.98    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6100     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 14256    |\n",
      "|    total_timesteps  | 4875779  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 1193944  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4880000, episode_reward=-2.60 +/- 4.76\n",
      "Episode length: 1062.20 +/- 462.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -2.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00485  |\n",
      "|    n_updates        | 1194999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.09    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6104     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14280    |\n",
      "|    total_timesteps  | 4882501  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0317   |\n",
      "|    n_updates        | 1195625  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.18    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6108     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14291    |\n",
      "|    total_timesteps  | 4887350  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 1196837  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4890000, episode_reward=-2.60 +/- 6.80\n",
      "Episode length: 1209.00 +/- 263.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | -2.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00991  |\n",
      "|    n_updates        | 1197499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.15    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6112     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14312    |\n",
      "|    total_timesteps  | 4892474  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 1198118  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.09    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6116     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14325    |\n",
      "|    total_timesteps  | 4898033  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 1199508  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4900000, episode_reward=0.40 +/- 7.39\n",
      "Episode length: 1119.20 +/- 308.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00601  |\n",
      "|    n_updates        | 1199999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.99    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6120     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14347    |\n",
      "|    total_timesteps  | 4903832  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 1200957  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.52    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6124     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14359    |\n",
      "|    total_timesteps  | 4908649  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 1202162  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4910000, episode_reward=-5.00 +/- 5.55\n",
      "Episode length: 1194.80 +/- 99.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | -5       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 1202499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.47    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6128     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14380    |\n",
      "|    total_timesteps  | 4914181  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00665  |\n",
      "|    n_updates        | 1203545  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.37    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6132     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14391    |\n",
      "|    total_timesteps  | 4918740  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 1204684  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4920000, episode_reward=9.00 +/- 2.61\n",
      "Episode length: 1061.00 +/- 91.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 9        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00233  |\n",
      "|    n_updates        | 1204999  |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.21    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6136     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14411    |\n",
      "|    total_timesteps  | 4923871  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00372  |\n",
      "|    n_updates        | 1205967  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6140     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14422    |\n",
      "|    total_timesteps  | 4928451  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0325   |\n",
      "|    n_updates        | 1207112  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4930000, episode_reward=-1.60 +/- 5.54\n",
      "Episode length: 1146.00 +/- 273.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | -1.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00342  |\n",
      "|    n_updates        | 1207499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6144     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14443    |\n",
      "|    total_timesteps  | 4933770  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00578  |\n",
      "|    n_updates        | 1208442  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6148     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14454    |\n",
      "|    total_timesteps  | 4938671  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00711  |\n",
      "|    n_updates        | 1209667  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4940000, episode_reward=-0.80 +/- 3.97\n",
      "Episode length: 1017.00 +/- 527.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00895  |\n",
      "|    n_updates        | 1209999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6152     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14476    |\n",
      "|    total_timesteps  | 4944854  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00686  |\n",
      "|    n_updates        | 1211213  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6156     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14487    |\n",
      "|    total_timesteps  | 4949622  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00745  |\n",
      "|    n_updates        | 1212405  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4950000, episode_reward=-0.40 +/- 3.20\n",
      "Episode length: 1251.00 +/- 148.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.25e+03 |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00417  |\n",
      "|    n_updates        | 1212499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6160     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14510    |\n",
      "|    total_timesteps  | 4955084  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 1213770  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4960000, episode_reward=-3.60 +/- 8.80\n",
      "Episode length: 953.80 +/- 384.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 954      |\n",
      "|    mean_reward      | -3.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00852  |\n",
      "|    n_updates        | 1214999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6164     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14531    |\n",
      "|    total_timesteps  | 4961348  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00637  |\n",
      "|    n_updates        | 1215336  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.16     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6168     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14544    |\n",
      "|    total_timesteps  | 4966571  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00988  |\n",
      "|    n_updates        | 1216642  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4970000, episode_reward=1.80 +/- 4.31\n",
      "Episode length: 1337.80 +/- 202.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1217499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6172     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14565    |\n",
      "|    total_timesteps  | 4971355  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00671  |\n",
      "|    n_updates        | 1217838  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6176     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14575    |\n",
      "|    total_timesteps  | 4975881  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1218970  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4980000, episode_reward=3.60 +/- 5.12\n",
      "Episode length: 1244.20 +/- 251.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00656  |\n",
      "|    n_updates        | 1219999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1        |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6180     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14597    |\n",
      "|    total_timesteps  | 4981269  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 1220317  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.09     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6184     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14610    |\n",
      "|    total_timesteps  | 4986884  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 1221720  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4990000, episode_reward=4.60 +/- 4.50\n",
      "Episode length: 1162.20 +/- 266.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0077   |\n",
      "|    n_updates        | 1222499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.25     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6188     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14632    |\n",
      "|    total_timesteps  | 4992463  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 1223115  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.02     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6192     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14643    |\n",
      "|    total_timesteps  | 4997232  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 1224307  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5000000, episode_reward=4.20 +/- 6.31\n",
      "Episode length: 1239.00 +/- 157.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00939  |\n",
      "|    n_updates        | 1224999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.36     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6196     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14665    |\n",
      "|    total_timesteps  | 5002752  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 1225687  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.31     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6200     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14678    |\n",
      "|    total_timesteps  | 5008007  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0297   |\n",
      "|    n_updates        | 1227001  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5010000, episode_reward=-3.80 +/- 6.62\n",
      "Episode length: 1105.00 +/- 286.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -3.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 1227499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6204     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14699    |\n",
      "|    total_timesteps  | 5013641  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 1228410  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6208     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14710    |\n",
      "|    total_timesteps  | 5018408  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 1229601  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5020000, episode_reward=4.80 +/- 6.11\n",
      "Episode length: 1189.00 +/- 66.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00422  |\n",
      "|    n_updates        | 1229999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6212     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14731    |\n",
      "|    total_timesteps  | 5023608  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 1230901  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6216     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14744    |\n",
      "|    total_timesteps  | 5028880  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00358  |\n",
      "|    n_updates        | 1232219  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5030000, episode_reward=3.60 +/- 5.31\n",
      "Episode length: 1077.20 +/- 483.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 1232499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6220     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14766    |\n",
      "|    total_timesteps  | 5035005  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 1233751  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6224     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 14777    |\n",
      "|    total_timesteps  | 5039801  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00979  |\n",
      "|    n_updates        | 1234950  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5040000, episode_reward=7.00 +/- 4.86\n",
      "Episode length: 1078.40 +/- 216.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 7        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00569  |\n",
      "|    n_updates        | 1234999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.15     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6228     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14796    |\n",
      "|    total_timesteps  | 5044199  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 1236049  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.15     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6232     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14806    |\n",
      "|    total_timesteps  | 5048482  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00762  |\n",
      "|    n_updates        | 1237120  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5050000, episode_reward=5.60 +/- 4.50\n",
      "Episode length: 1141.00 +/- 204.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1237499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6236     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14826    |\n",
      "|    total_timesteps  | 5053666  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 1238416  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.17     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6240     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14838    |\n",
      "|    total_timesteps  | 5058703  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00826  |\n",
      "|    n_updates        | 1239675  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5060000, episode_reward=-4.00 +/- 6.54\n",
      "Episode length: 1099.60 +/- 232.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -4       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 1239999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.11     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6244     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14858    |\n",
      "|    total_timesteps  | 5063716  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00601  |\n",
      "|    n_updates        | 1240928  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6248     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14869    |\n",
      "|    total_timesteps  | 5068483  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 1242120  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5070000, episode_reward=-2.40 +/- 2.58\n",
      "Episode length: 1226.00 +/- 160.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -2.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 1242499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 1.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6252     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14889    |\n",
      "|    total_timesteps  | 5073303  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00714  |\n",
      "|    n_updates        | 1243325  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6256     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14901    |\n",
      "|    total_timesteps  | 5078187  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1244546  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5080000, episode_reward=3.40 +/- 8.80\n",
      "Episode length: 926.60 +/- 206.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 927      |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.029    |\n",
      "|    n_updates        | 1244999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6260     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14920    |\n",
      "|    total_timesteps  | 5083631  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 1245907  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6264     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14932    |\n",
      "|    total_timesteps  | 5088404  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00481  |\n",
      "|    n_updates        | 1247100  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5090000, episode_reward=-2.40 +/- 7.86\n",
      "Episode length: 1033.40 +/- 104.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -2.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00594  |\n",
      "|    n_updates        | 1247499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.48     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6268     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14952    |\n",
      "|    total_timesteps  | 5093748  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.007    |\n",
      "|    n_updates        | 1248436  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6272     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14963    |\n",
      "|    total_timesteps  | 5098554  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 1249638  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5100000, episode_reward=4.60 +/- 3.88\n",
      "Episode length: 1018.60 +/- 503.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 1249999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.27     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6276     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14985    |\n",
      "|    total_timesteps  | 5104455  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00471  |\n",
      "|    n_updates        | 1251113  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6280     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 14994    |\n",
      "|    total_timesteps  | 5108382  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 1252095  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5110000, episode_reward=0.60 +/- 5.04\n",
      "Episode length: 1262.60 +/- 176.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 1252499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6284     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15016    |\n",
      "|    total_timesteps  | 5113876  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1253468  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6288     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15027    |\n",
      "|    total_timesteps  | 5118426  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00499  |\n",
      "|    n_updates        | 1254606  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5120000, episode_reward=-1.40 +/- 4.96\n",
      "Episode length: 1128.60 +/- 266.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | -1.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00847  |\n",
      "|    n_updates        | 1254999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.43     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6292     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15046    |\n",
      "|    total_timesteps  | 5123289  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00754  |\n",
      "|    n_updates        | 1255822  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6296     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15058    |\n",
      "|    total_timesteps  | 5128113  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00553  |\n",
      "|    n_updates        | 1257028  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5130000, episode_reward=4.60 +/- 7.06\n",
      "Episode length: 985.60 +/- 251.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 986      |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00475  |\n",
      "|    n_updates        | 1257499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6300     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15076    |\n",
      "|    total_timesteps  | 5132688  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 1258171  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6304     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15087    |\n",
      "|    total_timesteps  | 5137519  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00513  |\n",
      "|    n_updates        | 1259379  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5140000, episode_reward=4.00 +/- 3.52\n",
      "Episode length: 1223.40 +/- 130.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00569  |\n",
      "|    n_updates        | 1259999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6308     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15107    |\n",
      "|    total_timesteps  | 5142333  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00746  |\n",
      "|    n_updates        | 1260583  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.65     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6312     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15120    |\n",
      "|    total_timesteps  | 5147515  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 1261878  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5150000, episode_reward=2.60 +/- 6.86\n",
      "Episode length: 1042.80 +/- 331.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 1262499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.49     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6316     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15139    |\n",
      "|    total_timesteps  | 5152578  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00586  |\n",
      "|    n_updates        | 1263144  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | 0.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6320     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15151    |\n",
      "|    total_timesteps  | 5157577  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 1264394  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5160000, episode_reward=-2.20 +/- 5.31\n",
      "Episode length: 1021.80 +/- 505.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0068   |\n",
      "|    n_updates        | 1264999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | 0.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6324     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15174    |\n",
      "|    total_timesteps  | 5164200  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 1266049  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6328     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15186    |\n",
      "|    total_timesteps  | 5169369  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 1267342  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5170000, episode_reward=-0.60 +/- 5.54\n",
      "Episode length: 1029.60 +/- 373.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -0.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00296  |\n",
      "|    n_updates        | 1267499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6332     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15207    |\n",
      "|    total_timesteps  | 5174923  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00267  |\n",
      "|    n_updates        | 1268730  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | 0.27     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6336     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15216    |\n",
      "|    total_timesteps  | 5179101  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00793  |\n",
      "|    n_updates        | 1269775  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5180000, episode_reward=0.40 +/- 8.48\n",
      "Episode length: 968.20 +/- 378.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 968      |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0275   |\n",
      "|    n_updates        | 1269999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.19     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6340     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15237    |\n",
      "|    total_timesteps  | 5184927  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 1271231  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -0.07    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6344     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15248    |\n",
      "|    total_timesteps  | 5189635  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00802  |\n",
      "|    n_updates        | 1272408  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5190000, episode_reward=1.20 +/- 5.53\n",
      "Episode length: 1180.80 +/- 171.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00418  |\n",
      "|    n_updates        | 1272499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 0.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6348     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15270    |\n",
      "|    total_timesteps  | 5194952  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 1273737  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5200000, episode_reward=3.20 +/- 5.04\n",
      "Episode length: 951.80 +/- 440.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 952      |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 1274999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.06    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6352     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15292    |\n",
      "|    total_timesteps  | 5201363  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00567  |\n",
      "|    n_updates        | 1275340  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.16     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6356     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15303    |\n",
      "|    total_timesteps  | 5206113  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00301  |\n",
      "|    n_updates        | 1276528  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5210000, episode_reward=1.00 +/- 8.27\n",
      "Episode length: 1142.60 +/- 152.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1277499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.02    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6360     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15323    |\n",
      "|    total_timesteps  | 5211357  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1277839  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6364     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15334    |\n",
      "|    total_timesteps  | 5215927  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 1278981  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5220000, episode_reward=3.00 +/- 7.54\n",
      "Episode length: 1014.20 +/- 220.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0298   |\n",
      "|    n_updates        | 1279999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.17     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6368     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15354    |\n",
      "|    total_timesteps  | 5221138  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1280284  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6372     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15365    |\n",
      "|    total_timesteps  | 5225869  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00425  |\n",
      "|    n_updates        | 1281467  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5230000, episode_reward=-2.60 +/- 4.18\n",
      "Episode length: 1194.00 +/- 395.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | -2.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00745  |\n",
      "|    n_updates        | 1282499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.41     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6376     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15390    |\n",
      "|    total_timesteps  | 5232743  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 1283185  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6380     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15401    |\n",
      "|    total_timesteps  | 5237491  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00447  |\n",
      "|    n_updates        | 1284372  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5240000, episode_reward=-0.40 +/- 5.78\n",
      "Episode length: 1140.80 +/- 176.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0092   |\n",
      "|    n_updates        | 1284999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.16     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6384     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15421    |\n",
      "|    total_timesteps  | 5242501  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 1285625  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.12     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6388     |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 15434    |\n",
      "|    total_timesteps  | 5247929  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00678  |\n",
      "|    n_updates        | 1286982  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5250000, episode_reward=-0.20 +/- 7.11\n",
      "Episode length: 965.20 +/- 500.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 965      |\n",
      "|    mean_reward      | -0.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 1287499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.36     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6392     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15454    |\n",
      "|    total_timesteps  | 5253622  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00462  |\n",
      "|    n_updates        | 1288405  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.28     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6396     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15465    |\n",
      "|    total_timesteps  | 5258248  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 1289561  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5260000, episode_reward=-0.60 +/- 5.99\n",
      "Episode length: 1377.40 +/- 198.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.38e+03 |\n",
      "|    mean_reward      | -0.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 1289999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6400     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15488    |\n",
      "|    total_timesteps  | 5263721  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1290930  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6404     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15500    |\n",
      "|    total_timesteps  | 5268701  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 1292175  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5270000, episode_reward=4.80 +/- 8.66\n",
      "Episode length: 1258.60 +/- 190.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00411  |\n",
      "|    n_updates        | 1292499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6408     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15521    |\n",
      "|    total_timesteps  | 5273581  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00353  |\n",
      "|    n_updates        | 1293395  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6412     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15533    |\n",
      "|    total_timesteps  | 5278565  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 1294641  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5280000, episode_reward=7.00 +/- 2.97\n",
      "Episode length: 1177.20 +/- 144.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 7        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 1294999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6416     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15554    |\n",
      "|    total_timesteps  | 5284199  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1296049  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6420     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15566    |\n",
      "|    total_timesteps  | 5289054  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00458  |\n",
      "|    n_updates        | 1297263  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5290000, episode_reward=8.60 +/- 3.61\n",
      "Episode length: 1075.20 +/- 345.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 8.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 1297499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.29     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6424     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15587    |\n",
      "|    total_timesteps  | 5295007  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00696  |\n",
      "|    n_updates        | 1298751  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5300000, episode_reward=5.60 +/- 3.56\n",
      "Episode length: 1043.00 +/- 401.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 1299999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6428     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15609    |\n",
      "|    total_timesteps  | 5301209  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00411  |\n",
      "|    n_updates        | 1300302  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.25     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6432     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15620    |\n",
      "|    total_timesteps  | 5305967  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00296  |\n",
      "|    n_updates        | 1301491  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5310000, episode_reward=2.60 +/- 5.75\n",
      "Episode length: 1196.40 +/- 276.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 1302499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.36     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6436     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15641    |\n",
      "|    total_timesteps  | 5311185  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00633  |\n",
      "|    n_updates        | 1302796  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6440     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15653    |\n",
      "|    total_timesteps  | 5316106  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00462  |\n",
      "|    n_updates        | 1304026  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5320000, episode_reward=-2.20 +/- 4.92\n",
      "Episode length: 1140.60 +/- 294.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00917  |\n",
      "|    n_updates        | 1304999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.3      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6444     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15674    |\n",
      "|    total_timesteps  | 5321219  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 1305304  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.02    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6448     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15686    |\n",
      "|    total_timesteps  | 5326335  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1306583  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5330000, episode_reward=-2.00 +/- 6.26\n",
      "Episode length: 1069.80 +/- 456.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00879  |\n",
      "|    n_updates        | 1307499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6452     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15709    |\n",
      "|    total_timesteps  | 5332622  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00638  |\n",
      "|    n_updates        | 1308155  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.02    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6456     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15719    |\n",
      "|    total_timesteps  | 5337202  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0053   |\n",
      "|    n_updates        | 1309300  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5340000, episode_reward=0.20 +/- 7.30\n",
      "Episode length: 1221.00 +/- 144.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00438  |\n",
      "|    n_updates        | 1309999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.09    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6460     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15741    |\n",
      "|    total_timesteps  | 5342451  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1310612  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -0.32    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6464     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15754    |\n",
      "|    total_timesteps  | 5347796  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00934  |\n",
      "|    n_updates        | 1311948  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5350000, episode_reward=-2.40 +/- 4.45\n",
      "Episode length: 1046.80 +/- 526.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | -2.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 1312499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -0.42    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6468     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15775    |\n",
      "|    total_timesteps  | 5353658  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 1313414  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -0.28    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6472     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15784    |\n",
      "|    total_timesteps  | 5357624  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00473  |\n",
      "|    n_updates        | 1314405  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5360000, episode_reward=6.40 +/- 5.54\n",
      "Episode length: 914.00 +/- 444.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 914      |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1314999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.46    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6476     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15806    |\n",
      "|    total_timesteps  | 5363982  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 1315995  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -0.43    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6480     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15818    |\n",
      "|    total_timesteps  | 5369015  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0059   |\n",
      "|    n_updates        | 1317253  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5370000, episode_reward=3.40 +/- 8.31\n",
      "Episode length: 928.20 +/- 435.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 928      |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00298  |\n",
      "|    n_updates        | 1317499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -0.39    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6484     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15838    |\n",
      "|    total_timesteps  | 5374772  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00638  |\n",
      "|    n_updates        | 1318692  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5380000, episode_reward=0.20 +/- 6.05\n",
      "Episode length: 951.20 +/- 487.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 951      |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 1319999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -0.49    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6488     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15860    |\n",
      "|    total_timesteps  | 5381083  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00961  |\n",
      "|    n_updates        | 1320270  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -0.83    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6492     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15872    |\n",
      "|    total_timesteps  | 5386131  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00787  |\n",
      "|    n_updates        | 1321532  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5390000, episode_reward=1.40 +/- 5.20\n",
      "Episode length: 1205.20 +/- 114.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 1322499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -0.77    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6496     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15893    |\n",
      "|    total_timesteps  | 5390998  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 1322749  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -0.48    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6500     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15904    |\n",
      "|    total_timesteps  | 5395907  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00728  |\n",
      "|    n_updates        | 1323976  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5400000, episode_reward=-4.00 +/- 5.40\n",
      "Episode length: 1025.60 +/- 258.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -4       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 1324999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -0.69    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6504     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15924    |\n",
      "|    total_timesteps  | 5401381  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1325345  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.16    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6508     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15935    |\n",
      "|    total_timesteps  | 5406004  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00651  |\n",
      "|    n_updates        | 1326500  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5410000, episode_reward=-0.60 +/- 6.83\n",
      "Episode length: 1171.00 +/- 127.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -0.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 1327499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -1.4     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6512     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15956    |\n",
      "|    total_timesteps  | 5411241  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 1327810  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.62    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6516     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15969    |\n",
      "|    total_timesteps  | 5416615  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0324   |\n",
      "|    n_updates        | 1329153  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5420000, episode_reward=-2.00 +/- 5.48\n",
      "Episode length: 1116.40 +/- 226.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 1329999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -1.77    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6520     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 15991    |\n",
      "|    total_timesteps  | 5422376  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00538  |\n",
      "|    n_updates        | 1330593  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -1.55    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6524     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 16003    |\n",
      "|    total_timesteps  | 5427598  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00992  |\n",
      "|    n_updates        | 1331899  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5430000, episode_reward=5.20 +/- 5.71\n",
      "Episode length: 1001.40 +/- 478.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 1332499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.35    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6528     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 16024    |\n",
      "|    total_timesteps  | 5433456  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.007    |\n",
      "|    n_updates        | 1333363  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.44    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6532     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 16035    |\n",
      "|    total_timesteps  | 5438201  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0066   |\n",
      "|    n_updates        | 1334550  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5440000, episode_reward=2.60 +/- 6.15\n",
      "Episode length: 1135.40 +/- 226.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00706  |\n",
      "|    n_updates        | 1334999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -1.4     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6536     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 16057    |\n",
      "|    total_timesteps  | 5443791  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00893  |\n",
      "|    n_updates        | 1335947  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -0.99    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6540     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 16068    |\n",
      "|    total_timesteps  | 5448290  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1337072  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5450000, episode_reward=0.20 +/- 9.54\n",
      "Episode length: 1169.40 +/- 235.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0237   |\n",
      "|    n_updates        | 1337499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.28    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6544     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16088    |\n",
      "|    total_timesteps  | 5453233  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00719  |\n",
      "|    n_updates        | 1338308  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.09    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6548     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 16100    |\n",
      "|    total_timesteps  | 5458352  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00578  |\n",
      "|    n_updates        | 1339587  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5460000, episode_reward=1.20 +/- 6.31\n",
      "Episode length: 1037.60 +/- 269.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0249   |\n",
      "|    n_updates        | 1339999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -1.38    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6552     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16120    |\n",
      "|    total_timesteps  | 5463528  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 1340881  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.25    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6556     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16132    |\n",
      "|    total_timesteps  | 5468729  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00825  |\n",
      "|    n_updates        | 1342182  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5470000, episode_reward=4.20 +/- 3.92\n",
      "Episode length: 1203.00 +/- 204.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 1342499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.8     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6560     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16152    |\n",
      "|    total_timesteps  | 5473537  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00771  |\n",
      "|    n_updates        | 1343384  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.52    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6564     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16164    |\n",
      "|    total_timesteps  | 5478679  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00576  |\n",
      "|    n_updates        | 1344669  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5480000, episode_reward=3.00 +/- 6.72\n",
      "Episode length: 1169.60 +/- 182.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00468  |\n",
      "|    n_updates        | 1344999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.49    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6568     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16185    |\n",
      "|    total_timesteps  | 5483991  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1345997  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -0.64    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6572     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16196    |\n",
      "|    total_timesteps  | 5488508  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0334   |\n",
      "|    n_updates        | 1347126  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5490000, episode_reward=-1.80 +/- 6.05\n",
      "Episode length: 1227.60 +/- 364.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00296  |\n",
      "|    n_updates        | 1347499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.57    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6576     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16217    |\n",
      "|    total_timesteps  | 5493455  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1348363  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.43    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6580     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16229    |\n",
      "|    total_timesteps  | 5498507  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00376  |\n",
      "|    n_updates        | 1349626  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5500000, episode_reward=-2.20 +/- 4.35\n",
      "Episode length: 1171.40 +/- 141.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1349999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.3     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6584     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16250    |\n",
      "|    total_timesteps  | 5503883  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00321  |\n",
      "|    n_updates        | 1350970  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.11    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6588     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16261    |\n",
      "|    total_timesteps  | 5508632  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 1352157  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5510000, episode_reward=0.80 +/- 7.03\n",
      "Episode length: 1218.00 +/- 311.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 1352499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 0.17     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6592     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16283    |\n",
      "|    total_timesteps  | 5514109  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 1353527  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.06    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6596     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16294    |\n",
      "|    total_timesteps  | 5518722  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 1354680  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5520000, episode_reward=7.60 +/- 6.50\n",
      "Episode length: 882.60 +/- 358.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 883      |\n",
      "|    mean_reward      | 7.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 1354999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.3     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6600     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16315    |\n",
      "|    total_timesteps  | 5524774  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 1356193  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -0.12    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6604     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16325    |\n",
      "|    total_timesteps  | 5528989  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00914  |\n",
      "|    n_updates        | 1357247  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5530000, episode_reward=2.80 +/- 3.87\n",
      "Episode length: 1022.80 +/- 492.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00522  |\n",
      "|    n_updates        | 1357499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6608     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16348    |\n",
      "|    total_timesteps  | 5535562  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00639  |\n",
      "|    n_updates        | 1358890  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5540000, episode_reward=3.20 +/- 3.12\n",
      "Episode length: 1183.80 +/- 367.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00546  |\n",
      "|    n_updates        | 1359999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -0.18    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6612     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16370    |\n",
      "|    total_timesteps  | 5541374  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 1360343  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -0.06    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6616     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16381    |\n",
      "|    total_timesteps  | 5546081  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0293   |\n",
      "|    n_updates        | 1361520  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5550000, episode_reward=0.40 +/- 8.71\n",
      "Episode length: 1061.00 +/- 435.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00484  |\n",
      "|    n_updates        | 1362499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.15     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6620     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16405    |\n",
      "|    total_timesteps  | 5552588  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 1363146  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6624     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16416    |\n",
      "|    total_timesteps  | 5557571  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 1364392  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5560000, episode_reward=5.80 +/- 2.32\n",
      "Episode length: 1074.40 +/- 108.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 5.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00635  |\n",
      "|    n_updates        | 1364999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.3      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6628     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16435    |\n",
      "|    total_timesteps  | 5562298  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00817  |\n",
      "|    n_updates        | 1365574  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6632     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16447    |\n",
      "|    total_timesteps  | 5567353  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 1366838  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5570000, episode_reward=5.80 +/- 6.49\n",
      "Episode length: 1099.80 +/- 101.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 5.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00852  |\n",
      "|    n_updates        | 1367499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.49     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6636     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16468    |\n",
      "|    total_timesteps  | 5572595  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00803  |\n",
      "|    n_updates        | 1368148  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6640     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16479    |\n",
      "|    total_timesteps  | 5577404  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00871  |\n",
      "|    n_updates        | 1369350  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5580000, episode_reward=6.40 +/- 3.44\n",
      "Episode length: 1158.60 +/- 105.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00601  |\n",
      "|    n_updates        | 1369999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6644     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16499    |\n",
      "|    total_timesteps  | 5582286  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 1370571  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6648     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16511    |\n",
      "|    total_timesteps  | 5587713  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00742  |\n",
      "|    n_updates        | 1371928  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5590000, episode_reward=-1.60 +/- 5.57\n",
      "Episode length: 1137.80 +/- 439.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | -1.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00543  |\n",
      "|    n_updates        | 1372499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.52     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6652     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16533    |\n",
      "|    total_timesteps  | 5593629  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00517  |\n",
      "|    n_updates        | 1373407  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6656     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16545    |\n",
      "|    total_timesteps  | 5598653  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00419  |\n",
      "|    n_updates        | 1374663  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5600000, episode_reward=5.80 +/- 7.08\n",
      "Episode length: 1269.80 +/- 243.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | 5.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00984  |\n",
      "|    n_updates        | 1374999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6660     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16567    |\n",
      "|    total_timesteps  | 5603715  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00971  |\n",
      "|    n_updates        | 1375928  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.22     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6664     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16580    |\n",
      "|    total_timesteps  | 5609316  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 1377328  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5610000, episode_reward=2.80 +/- 7.55\n",
      "Episode length: 1189.60 +/- 364.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00451  |\n",
      "|    n_updates        | 1377499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6668     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16602    |\n",
      "|    total_timesteps  | 5614779  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 1378694  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6672     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16613    |\n",
      "|    total_timesteps  | 5619395  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0196   |\n",
      "|    n_updates        | 1379848  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5620000, episode_reward=8.20 +/- 4.31\n",
      "Episode length: 1042.80 +/- 153.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 8.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 1379999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6676     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16633    |\n",
      "|    total_timesteps  | 5624762  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 1381190  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5630000, episode_reward=3.00 +/- 4.56\n",
      "Episode length: 1087.60 +/- 345.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00907  |\n",
      "|    n_updates        | 1382499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.3      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6680     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16656    |\n",
      "|    total_timesteps  | 5631141  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 1382785  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6684     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16669    |\n",
      "|    total_timesteps  | 5636346  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00944  |\n",
      "|    n_updates        | 1384086  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5640000, episode_reward=3.00 +/- 5.55\n",
      "Episode length: 958.60 +/- 419.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 959      |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00884  |\n",
      "|    n_updates        | 1384999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.29     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6688     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16690    |\n",
      "|    total_timesteps  | 5642388  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 1385596  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.25     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6692     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16702    |\n",
      "|    total_timesteps  | 5647532  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0392   |\n",
      "|    n_updates        | 1386882  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5650000, episode_reward=4.80 +/- 3.97\n",
      "Episode length: 1126.20 +/- 354.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00986  |\n",
      "|    n_updates        | 1387499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.86     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6696     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16723    |\n",
      "|    total_timesteps  | 5652999  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 1388249  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.1      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6700     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16735    |\n",
      "|    total_timesteps  | 5658116  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0268   |\n",
      "|    n_updates        | 1389528  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5660000, episode_reward=8.20 +/- 5.31\n",
      "Episode length: 1119.40 +/- 261.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 8.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 1389999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6704     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16756    |\n",
      "|    total_timesteps  | 5663657  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 1390914  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6708     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16768    |\n",
      "|    total_timesteps  | 5668524  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00804  |\n",
      "|    n_updates        | 1392130  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5670000, episode_reward=2.80 +/- 5.88\n",
      "Episode length: 1158.00 +/- 245.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00649  |\n",
      "|    n_updates        | 1392499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6712     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16789    |\n",
      "|    total_timesteps  | 5673789  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1393447  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.93     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6716     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 16801    |\n",
      "|    total_timesteps  | 5678918  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0265   |\n",
      "|    n_updates        | 1394729  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5680000, episode_reward=4.00 +/- 7.51\n",
      "Episode length: 1183.80 +/- 422.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00643  |\n",
      "|    n_updates        | 1394999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.93     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6720     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16823    |\n",
      "|    total_timesteps  | 5684787  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0049   |\n",
      "|    n_updates        | 1396196  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.97     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6724     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16835    |\n",
      "|    total_timesteps  | 5689666  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1397416  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5690000, episode_reward=4.80 +/- 2.79\n",
      "Episode length: 1322.80 +/- 249.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00259  |\n",
      "|    n_updates        | 1397499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6728     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16854    |\n",
      "|    total_timesteps  | 5693941  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 1398485  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.99     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6732     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16866    |\n",
      "|    total_timesteps  | 5698771  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00943  |\n",
      "|    n_updates        | 1399692  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5700000, episode_reward=7.60 +/- 5.04\n",
      "Episode length: 1193.20 +/- 261.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 7.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 1399999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.89     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6736     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16887    |\n",
      "|    total_timesteps  | 5703971  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00412  |\n",
      "|    n_updates        | 1400992  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.89     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6740     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16898    |\n",
      "|    total_timesteps  | 5708892  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1402222  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5710000, episode_reward=3.40 +/- 6.41\n",
      "Episode length: 1250.80 +/- 353.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.25e+03 |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00533  |\n",
      "|    n_updates        | 1402499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.36     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6744     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16919    |\n",
      "|    total_timesteps  | 5713841  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 1403460  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6748     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16932    |\n",
      "|    total_timesteps  | 5719427  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 1404856  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5720000, episode_reward=3.40 +/- 6.28\n",
      "Episode length: 1171.20 +/- 268.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00424  |\n",
      "|    n_updates        | 1404999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6752     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16953    |\n",
      "|    total_timesteps  | 5724639  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 1406159  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.62     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6756     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16966    |\n",
      "|    total_timesteps  | 5729785  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 1407446  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5730000, episode_reward=5.60 +/- 5.54\n",
      "Episode length: 1183.40 +/- 176.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 1407499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6760     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 16986    |\n",
      "|    total_timesteps  | 5735013  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1408753  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5740000, episode_reward=-0.40 +/- 7.86\n",
      "Episode length: 982.60 +/- 433.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 983      |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 1409999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.63     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6764     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17008    |\n",
      "|    total_timesteps  | 5741272  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 1410317  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6768     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17021    |\n",
      "|    total_timesteps  | 5746543  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00733  |\n",
      "|    n_updates        | 1411635  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5750000, episode_reward=-2.40 +/- 8.09\n",
      "Episode length: 1034.80 +/- 247.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -2.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 1412499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6772     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17042    |\n",
      "|    total_timesteps  | 5752391  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 1413097  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.11     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6776     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17053    |\n",
      "|    total_timesteps  | 5757012  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00438  |\n",
      "|    n_updates        | 1414252  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5760000, episode_reward=8.40 +/- 1.74\n",
      "Episode length: 1007.60 +/- 346.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 8.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00426  |\n",
      "|    n_updates        | 1414999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6780     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17073    |\n",
      "|    total_timesteps  | 5762490  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00576  |\n",
      "|    n_updates        | 1415622  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6784     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17085    |\n",
      "|    total_timesteps  | 5767515  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 1416878  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5770000, episode_reward=2.40 +/- 2.65\n",
      "Episode length: 1087.00 +/- 459.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 1417499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6788     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17108    |\n",
      "|    total_timesteps  | 5773793  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0065   |\n",
      "|    n_updates        | 1418448  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6792     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17121    |\n",
      "|    total_timesteps  | 5779465  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 1419866  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5780000, episode_reward=-1.00 +/- 7.62\n",
      "Episode length: 1122.00 +/- 328.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -1       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00754  |\n",
      "|    n_updates        | 1419999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.22     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6796     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17141    |\n",
      "|    total_timesteps  | 5784446  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 1421111  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6800     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17154    |\n",
      "|    total_timesteps  | 5789716  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00673  |\n",
      "|    n_updates        | 1422428  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5790000, episode_reward=3.00 +/- 5.10\n",
      "Episode length: 1344.00 +/- 239.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 1422499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.92     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6804     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17176    |\n",
      "|    total_timesteps  | 5794915  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00713  |\n",
      "|    n_updates        | 1423728  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5800000, episode_reward=-2.00 +/- 12.46\n",
      "Episode length: 811.80 +/- 441.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 812      |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.006    |\n",
      "|    n_updates        | 1424999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.86     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6808     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17197    |\n",
      "|    total_timesteps  | 5801204  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 1425300  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.01     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6812     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17207    |\n",
      "|    total_timesteps  | 5805742  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 1426435  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5810000, episode_reward=3.40 +/- 5.68\n",
      "Episode length: 1042.40 +/- 525.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00422  |\n",
      "|    n_updates        | 1427499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.96     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6816     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17231    |\n",
      "|    total_timesteps  | 5812721  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00574  |\n",
      "|    n_updates        | 1428180  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6820     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17243    |\n",
      "|    total_timesteps  | 5817788  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00456  |\n",
      "|    n_updates        | 1429446  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5820000, episode_reward=-0.60 +/- 5.95\n",
      "Episode length: 1067.80 +/- 453.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -0.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0071   |\n",
      "|    n_updates        | 1429999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.13     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6824     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17265    |\n",
      "|    total_timesteps  | 5823937  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00592  |\n",
      "|    n_updates        | 1430984  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.04     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6828     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17278    |\n",
      "|    total_timesteps  | 5829394  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 1432348  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5830000, episode_reward=1.60 +/- 5.54\n",
      "Episode length: 1084.20 +/- 292.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00704  |\n",
      "|    n_updates        | 1432499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 1.84     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6832     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17299    |\n",
      "|    total_timesteps  | 5834645  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00448  |\n",
      "|    n_updates        | 1433661  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.34     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6836     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17308    |\n",
      "|    total_timesteps  | 5838670  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00346  |\n",
      "|    n_updates        | 1434667  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5840000, episode_reward=1.20 +/- 6.91\n",
      "Episode length: 951.20 +/- 464.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 951      |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1434999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 2.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6840     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17329    |\n",
      "|    total_timesteps  | 5844779  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 1436194  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 2.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6844     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17341    |\n",
      "|    total_timesteps  | 5849790  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0045   |\n",
      "|    n_updates        | 1437447  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5850000, episode_reward=7.60 +/- 3.14\n",
      "Episode length: 1262.60 +/- 222.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 7.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 1437499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.86     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6848     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17362    |\n",
      "|    total_timesteps  | 5854806  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00696  |\n",
      "|    n_updates        | 1438701  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5860000, episode_reward=4.60 +/- 4.92\n",
      "Episode length: 999.00 +/- 423.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 999      |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00278  |\n",
      "|    n_updates        | 1439999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 2.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6852     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17384    |\n",
      "|    total_timesteps  | 5861061  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 1440265  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 2.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6856     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17396    |\n",
      "|    total_timesteps  | 5866345  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 1441586  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5870000, episode_reward=3.80 +/- 7.03\n",
      "Episode length: 1210.00 +/- 165.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00427  |\n",
      "|    n_updates        | 1442499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 2.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6860     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17417    |\n",
      "|    total_timesteps  | 5871174  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 1442793  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6864     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17428    |\n",
      "|    total_timesteps  | 5875968  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0026   |\n",
      "|    n_updates        | 1443991  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5880000, episode_reward=0.00 +/- 3.74\n",
      "Episode length: 1283.60 +/- 278.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 0        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00969  |\n",
      "|    n_updates        | 1444999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.42     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6868     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17450    |\n",
      "|    total_timesteps  | 5881353  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0307   |\n",
      "|    n_updates        | 1445338  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6872     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17461    |\n",
      "|    total_timesteps  | 5885821  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00498  |\n",
      "|    n_updates        | 1446455  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5890000, episode_reward=3.00 +/- 2.28\n",
      "Episode length: 1221.60 +/- 217.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00524  |\n",
      "|    n_updates        | 1447499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.34     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6876     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17483    |\n",
      "|    total_timesteps  | 5891327  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 1447831  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6880     |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 17493    |\n",
      "|    total_timesteps  | 5895663  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00706  |\n",
      "|    n_updates        | 1448915  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5900000, episode_reward=-1.60 +/- 2.58\n",
      "Episode length: 1222.80 +/- 454.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | -1.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 1449999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6884     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17515    |\n",
      "|    total_timesteps  | 5901427  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00457  |\n",
      "|    n_updates        | 1450356  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6888     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17528    |\n",
      "|    total_timesteps  | 5906638  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1451659  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5910000, episode_reward=1.60 +/- 6.95\n",
      "Episode length: 1098.60 +/- 394.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00803  |\n",
      "|    n_updates        | 1452499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6892     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17549    |\n",
      "|    total_timesteps  | 5912264  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 1453065  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6896     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17561    |\n",
      "|    total_timesteps  | 5917517  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00672  |\n",
      "|    n_updates        | 1454379  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5920000, episode_reward=7.60 +/- 4.41\n",
      "Episode length: 885.00 +/- 429.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 885      |\n",
      "|    mean_reward      | 7.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00818  |\n",
      "|    n_updates        | 1454999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.41     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6900     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17582    |\n",
      "|    total_timesteps  | 5923547  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00917  |\n",
      "|    n_updates        | 1455886  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.13     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6904     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17595    |\n",
      "|    total_timesteps  | 5929013  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00998  |\n",
      "|    n_updates        | 1457253  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5930000, episode_reward=-1.00 +/- 4.86\n",
      "Episode length: 1097.80 +/- 460.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -1       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 1457499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.13     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6908     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17616    |\n",
      "|    total_timesteps  | 5934700  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00977  |\n",
      "|    n_updates        | 1458674  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.84     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6912     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17628    |\n",
      "|    total_timesteps  | 5939741  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 1459935  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5940000, episode_reward=4.20 +/- 3.66\n",
      "Episode length: 1308.00 +/- 234.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0081   |\n",
      "|    n_updates        | 1459999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6916     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17650    |\n",
      "|    total_timesteps  | 5944778  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00841  |\n",
      "|    n_updates        | 1461194  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.67     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6920     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17661    |\n",
      "|    total_timesteps  | 5949505  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 1462376  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5950000, episode_reward=3.80 +/- 5.91\n",
      "Episode length: 1193.40 +/- 244.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00991  |\n",
      "|    n_updates        | 1462499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6924     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17683    |\n",
      "|    total_timesteps  | 5955139  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00752  |\n",
      "|    n_updates        | 1463784  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5960000, episode_reward=1.40 +/- 4.80\n",
      "Episode length: 1006.80 +/- 487.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00732  |\n",
      "|    n_updates        | 1464999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.61     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6928     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17705    |\n",
      "|    total_timesteps  | 5961240  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 1465309  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6932     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17717    |\n",
      "|    total_timesteps  | 5966421  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00777  |\n",
      "|    n_updates        | 1466605  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5970000, episode_reward=3.80 +/- 4.17\n",
      "Episode length: 976.40 +/- 414.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 976      |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00693  |\n",
      "|    n_updates        | 1467499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6936     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17739    |\n",
      "|    total_timesteps  | 5972549  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 1468137  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6940     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17751    |\n",
      "|    total_timesteps  | 5977806  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1469451  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5980000, episode_reward=-2.20 +/- 6.65\n",
      "Episode length: 1083.20 +/- 326.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00633  |\n",
      "|    n_updates        | 1469999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 0.48     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6944     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17773    |\n",
      "|    total_timesteps  | 5983688  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 1470921  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 0.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6948     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17785    |\n",
      "|    total_timesteps  | 5988867  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00638  |\n",
      "|    n_updates        | 1472216  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5990000, episode_reward=1.40 +/- 6.59\n",
      "Episode length: 1139.40 +/- 156.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0072   |\n",
      "|    n_updates        | 1472499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 0.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6952     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17805    |\n",
      "|    total_timesteps  | 5993591  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00817  |\n",
      "|    n_updates        | 1473397  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6956     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17816    |\n",
      "|    total_timesteps  | 5998531  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1474632  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6000000, episode_reward=2.40 +/- 5.35\n",
      "Episode length: 1345.40 +/- 126.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.35e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 1474999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 0.65     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6960     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17842    |\n",
      "|    total_timesteps  | 6004112  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00554  |\n",
      "|    n_updates        | 1476027  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6964     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17854    |\n",
      "|    total_timesteps  | 6008998  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00958  |\n",
      "|    n_updates        | 1477249  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6010000, episode_reward=2.80 +/- 6.52\n",
      "Episode length: 962.40 +/- 308.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 962      |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 1477499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6968     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17876    |\n",
      "|    total_timesteps  | 6015007  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 1478751  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6020000, episode_reward=0.60 +/- 8.11\n",
      "Episode length: 1141.40 +/- 336.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00394  |\n",
      "|    n_updates        | 1479999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 1.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6972     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17900    |\n",
      "|    total_timesteps  | 6021019  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0338   |\n",
      "|    n_updates        | 1480254  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6976     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17910    |\n",
      "|    total_timesteps  | 6025264  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 1481315  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6030000, episode_reward=0.60 +/- 6.83\n",
      "Episode length: 1106.80 +/- 413.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00946  |\n",
      "|    n_updates        | 1482499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 1.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6980     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17933    |\n",
      "|    total_timesteps  | 6031179  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0273   |\n",
      "|    n_updates        | 1482794  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 1.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6984     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17945    |\n",
      "|    total_timesteps  | 6036342  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1484085  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6040000, episode_reward=2.80 +/- 6.79\n",
      "Episode length: 1168.20 +/- 108.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1484999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 1.41     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6988     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17965    |\n",
      "|    total_timesteps  | 6041274  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 1485318  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6992     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 17979    |\n",
      "|    total_timesteps  | 6046278  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0061   |\n",
      "|    n_updates        | 1486569  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6050000, episode_reward=6.00 +/- 4.56\n",
      "Episode length: 1152.60 +/- 100.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 6        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 1487499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6996     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 18000    |\n",
      "|    total_timesteps  | 6051024  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 1487755  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7000     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 18012    |\n",
      "|    total_timesteps  | 6056036  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 1489008  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6060000, episode_reward=4.00 +/- 5.76\n",
      "Episode length: 1177.60 +/- 321.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00377  |\n",
      "|    n_updates        | 1489999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.75     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7004     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 18034    |\n",
      "|    total_timesteps  | 6061157  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 1490289  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.63     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7008     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 18045    |\n",
      "|    total_timesteps  | 6065673  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 1491418  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6070000, episode_reward=3.80 +/- 4.07\n",
      "Episode length: 1120.60 +/- 357.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 1492499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.15     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7012     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18068    |\n",
      "|    total_timesteps  | 6070944  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 1492735  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7016     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 18079    |\n",
      "|    total_timesteps  | 6075627  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 1493906  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6080000, episode_reward=1.80 +/- 6.40\n",
      "Episode length: 1114.20 +/- 223.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1494999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.25     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7020     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18101    |\n",
      "|    total_timesteps  | 6081370  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00685  |\n",
      "|    n_updates        | 1495342  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7024     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 18113    |\n",
      "|    total_timesteps  | 6086548  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 1496636  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6090000, episode_reward=0.20 +/- 5.71\n",
      "Episode length: 1127.40 +/- 452.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00734  |\n",
      "|    n_updates        | 1497499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.02     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7028     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18135    |\n",
      "|    total_timesteps  | 6092527  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00521  |\n",
      "|    n_updates        | 1498131  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.86     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7032     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18145    |\n",
      "|    total_timesteps  | 6096489  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 1499122  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6100000, episode_reward=1.60 +/- 3.38\n",
      "Episode length: 1077.40 +/- 396.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 1499999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7036     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18166    |\n",
      "|    total_timesteps  | 6102335  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 1500583  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 1.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7040     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18177    |\n",
      "|    total_timesteps  | 6107083  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00905  |\n",
      "|    n_updates        | 1501770  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6110000, episode_reward=0.20 +/- 3.31\n",
      "Episode length: 1135.00 +/- 455.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 1502499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 1.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7044     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18198    |\n",
      "|    total_timesteps  | 6112294  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00721  |\n",
      "|    n_updates        | 1503073  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 1.41     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7048     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18211    |\n",
      "|    total_timesteps  | 6117829  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 1504457  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6120000, episode_reward=-0.40 +/- 7.76\n",
      "Episode length: 992.00 +/- 276.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 992      |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 1504999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.46     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7052     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18231    |\n",
      "|    total_timesteps  | 6123482  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 1505870  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.94     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7056     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18242    |\n",
      "|    total_timesteps  | 6128064  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 1507015  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6130000, episode_reward=5.20 +/- 3.19\n",
      "Episode length: 1159.20 +/- 290.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 1507499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7060     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18264    |\n",
      "|    total_timesteps  | 6133941  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 1508485  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7064     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18276    |\n",
      "|    total_timesteps  | 6139128  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00504  |\n",
      "|    n_updates        | 1509781  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6140000, episode_reward=4.60 +/- 4.08\n",
      "Episode length: 1088.20 +/- 319.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00932  |\n",
      "|    n_updates        | 1509999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.49     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7068     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18299    |\n",
      "|    total_timesteps  | 6145216  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00994  |\n",
      "|    n_updates        | 1511303  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6150000, episode_reward=8.60 +/- 4.03\n",
      "Episode length: 977.20 +/- 308.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 977      |\n",
      "|    mean_reward      | 8.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 1512499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7072     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18320    |\n",
      "|    total_timesteps  | 6151095  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00955  |\n",
      "|    n_updates        | 1512773  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7076     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18332    |\n",
      "|    total_timesteps  | 6156409  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 1514102  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6160000, episode_reward=-1.80 +/- 2.64\n",
      "Episode length: 1116.00 +/- 486.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 1514999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7080     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18355    |\n",
      "|    total_timesteps  | 6162196  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0041   |\n",
      "|    n_updates        | 1515548  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7084     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18366    |\n",
      "|    total_timesteps  | 6166835  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00373  |\n",
      "|    n_updates        | 1516708  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6170000, episode_reward=6.80 +/- 5.84\n",
      "Episode length: 1011.00 +/- 245.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 6.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00681  |\n",
      "|    n_updates        | 1517499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7088     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18387    |\n",
      "|    total_timesteps  | 6172329  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00617  |\n",
      "|    n_updates        | 1518082  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.28     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7092     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18399    |\n",
      "|    total_timesteps  | 6177282  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00865  |\n",
      "|    n_updates        | 1519320  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6180000, episode_reward=3.60 +/- 3.26\n",
      "Episode length: 1162.40 +/- 252.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1519999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7096     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18421    |\n",
      "|    total_timesteps  | 6182421  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 1520605  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7100     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18433    |\n",
      "|    total_timesteps  | 6187346  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1521836  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6190000, episode_reward=1.20 +/- 6.37\n",
      "Episode length: 1206.20 +/- 135.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00666  |\n",
      "|    n_updates        | 1522499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.61     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7104     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18455    |\n",
      "|    total_timesteps  | 6192657  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 1523164  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.85     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7108     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18467    |\n",
      "|    total_timesteps  | 6197472  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 1524367  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6200000, episode_reward=2.00 +/- 5.51\n",
      "Episode length: 1016.00 +/- 437.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 1524999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7112     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18490    |\n",
      "|    total_timesteps  | 6203338  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 1525834  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.28     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7116     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18503    |\n",
      "|    total_timesteps  | 6208725  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00826  |\n",
      "|    n_updates        | 1527181  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6210000, episode_reward=8.20 +/- 3.06\n",
      "Episode length: 1195.80 +/- 172.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 8.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 1527499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7120     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18524    |\n",
      "|    total_timesteps  | 6213935  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00643  |\n",
      "|    n_updates        | 1528483  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.42     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7124     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18537    |\n",
      "|    total_timesteps  | 6219265  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 1529816  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6220000, episode_reward=-1.60 +/- 6.28\n",
      "Episode length: 1034.80 +/- 363.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -1.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 1529999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7128     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18557    |\n",
      "|    total_timesteps  | 6224940  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 1531234  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6230000, episode_reward=0.20 +/- 7.11\n",
      "Episode length: 1014.40 +/- 417.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 1532499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 1.48     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7132     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18580    |\n",
      "|    total_timesteps  | 6231197  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 1532799  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.69     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7136     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18593    |\n",
      "|    total_timesteps  | 6236735  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00781  |\n",
      "|    n_updates        | 1534183  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6240000, episode_reward=4.40 +/- 4.03\n",
      "Episode length: 1116.20 +/- 416.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 1534999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 1.65     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7140     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18614    |\n",
      "|    total_timesteps  | 6242149  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00413  |\n",
      "|    n_updates        | 1535537  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7144     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18626    |\n",
      "|    total_timesteps  | 6247131  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 1536782  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6250000, episode_reward=2.00 +/- 5.02\n",
      "Episode length: 1239.80 +/- 77.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00779  |\n",
      "|    n_updates        | 1537499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.04     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7148     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18648    |\n",
      "|    total_timesteps  | 6252721  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00763  |\n",
      "|    n_updates        | 1538180  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.96     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7152     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18659    |\n",
      "|    total_timesteps  | 6257502  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 1539375  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6260000, episode_reward=1.20 +/- 9.41\n",
      "Episode length: 908.40 +/- 360.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 908      |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 1539999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 1.61     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7156     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18680    |\n",
      "|    total_timesteps  | 6263442  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0338   |\n",
      "|    n_updates        | 1540860  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.7      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7160     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18691    |\n",
      "|    total_timesteps  | 6268274  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1542068  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6270000, episode_reward=2.80 +/- 5.49\n",
      "Episode length: 1227.20 +/- 232.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 1542499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.92     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7164     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18712    |\n",
      "|    total_timesteps  | 6273457  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00538  |\n",
      "|    n_updates        | 1543364  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7168     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18722    |\n",
      "|    total_timesteps  | 6277766  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00943  |\n",
      "|    n_updates        | 1544441  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6280000, episode_reward=2.80 +/- 5.56\n",
      "Episode length: 1134.20 +/- 307.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 1544999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.01     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7172     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18744    |\n",
      "|    total_timesteps  | 6283405  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00546  |\n",
      "|    n_updates        | 1545851  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.89     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7176     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18756    |\n",
      "|    total_timesteps  | 6288464  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1547115  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6290000, episode_reward=6.40 +/- 3.20\n",
      "Episode length: 1205.00 +/- 194.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 1547499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.42     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7180     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18777    |\n",
      "|    total_timesteps  | 6293556  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 1548388  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7184     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18789    |\n",
      "|    total_timesteps  | 6298400  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 1549599  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6300000, episode_reward=2.00 +/- 7.59\n",
      "Episode length: 1213.20 +/- 175.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 1549999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7188     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18809    |\n",
      "|    total_timesteps  | 6303281  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 1550820  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7192     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18820    |\n",
      "|    total_timesteps  | 6307948  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 1551986  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6310000, episode_reward=-1.20 +/- 8.45\n",
      "Episode length: 1093.60 +/- 342.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | -1.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00539  |\n",
      "|    n_updates        | 1552499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7196     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18842    |\n",
      "|    total_timesteps  | 6313803  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 1553450  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.46     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7200     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18853    |\n",
      "|    total_timesteps  | 6318616  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00454  |\n",
      "|    n_updates        | 1554653  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6320000, episode_reward=2.40 +/- 7.81\n",
      "Episode length: 1233.40 +/- 134.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 1554999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.42     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7204     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18875    |\n",
      "|    total_timesteps  | 6323883  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 1555970  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7208     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18887    |\n",
      "|    total_timesteps  | 6329297  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 1557324  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6330000, episode_reward=7.00 +/- 4.94\n",
      "Episode length: 1040.60 +/- 328.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 7        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00608  |\n",
      "|    n_updates        | 1557499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7212     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18909    |\n",
      "|    total_timesteps  | 6335286  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00777  |\n",
      "|    n_updates        | 1558821  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6340000, episode_reward=1.80 +/- 7.83\n",
      "Episode length: 1013.20 +/- 345.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00689  |\n",
      "|    n_updates        | 1559999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.01     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7216     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 18931    |\n",
      "|    total_timesteps  | 6341520  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00936  |\n",
      "|    n_updates        | 1560379  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.22     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7220     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 18943    |\n",
      "|    total_timesteps  | 6346609  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 1561652  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6350000, episode_reward=1.40 +/- 4.59\n",
      "Episode length: 1194.40 +/- 334.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 1562499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7224     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 18967    |\n",
      "|    total_timesteps  | 6352596  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00478  |\n",
      "|    n_updates        | 1563148  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7228     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 18979    |\n",
      "|    total_timesteps  | 6357991  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1564497  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6360000, episode_reward=4.00 +/- 3.35\n",
      "Episode length: 1106.20 +/- 431.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 1564999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7232     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19000    |\n",
      "|    total_timesteps  | 6363377  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 1565844  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.44     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7236     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19012    |\n",
      "|    total_timesteps  | 6368528  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00917  |\n",
      "|    n_updates        | 1567131  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6370000, episode_reward=5.60 +/- 5.85\n",
      "Episode length: 1266.20 +/- 173.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00823  |\n",
      "|    n_updates        | 1567499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7240     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19034    |\n",
      "|    total_timesteps  | 6373889  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00408  |\n",
      "|    n_updates        | 1568472  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7244     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19047    |\n",
      "|    total_timesteps  | 6379290  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 1569822  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6380000, episode_reward=1.00 +/- 5.02\n",
      "Episode length: 1159.60 +/- 429.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 1569999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7248     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19068    |\n",
      "|    total_timesteps  | 6384593  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00372  |\n",
      "|    n_updates        | 1571148  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7252     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19080    |\n",
      "|    total_timesteps  | 6389776  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1572443  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6390000, episode_reward=4.80 +/- 3.49\n",
      "Episode length: 1402.80 +/- 314.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.4e+03  |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1572499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.95     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7256     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19102    |\n",
      "|    total_timesteps  | 6394780  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 1573694  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7260     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19114    |\n",
      "|    total_timesteps  | 6399895  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00779  |\n",
      "|    n_updates        | 1574973  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6400000, episode_reward=1.40 +/- 5.54\n",
      "Episode length: 1269.60 +/- 136.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00987  |\n",
      "|    n_updates        | 1574999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.91     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7264     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19136    |\n",
      "|    total_timesteps  | 6405188  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00752  |\n",
      "|    n_updates        | 1576296  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7268     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19147    |\n",
      "|    total_timesteps  | 6409976  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00892  |\n",
      "|    n_updates        | 1577493  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6410000, episode_reward=-1.80 +/- 5.42\n",
      "Episode length: 1261.40 +/- 204.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00813  |\n",
      "|    n_updates        | 1577499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7272     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19170    |\n",
      "|    total_timesteps  | 6415913  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00948  |\n",
      "|    n_updates        | 1578978  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6420000, episode_reward=0.40 +/- 6.80\n",
      "Episode length: 1129.40 +/- 320.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 1579999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.11     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7276     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19191    |\n",
      "|    total_timesteps  | 6421295  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00975  |\n",
      "|    n_updates        | 1580323  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7280     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19203    |\n",
      "|    total_timesteps  | 6426106  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00881  |\n",
      "|    n_updates        | 1581526  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6430000, episode_reward=2.00 +/- 7.69\n",
      "Episode length: 963.40 +/- 500.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 963      |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 1582499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.6      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7284     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19226    |\n",
      "|    total_timesteps  | 6432749  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00623  |\n",
      "|    n_updates        | 1583187  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7288     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19236    |\n",
      "|    total_timesteps  | 6437174  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00704  |\n",
      "|    n_updates        | 1584293  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6440000, episode_reward=0.60 +/- 6.28\n",
      "Episode length: 1198.00 +/- 196.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00738  |\n",
      "|    n_updates        | 1584999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.82     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7292     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19257    |\n",
      "|    total_timesteps  | 6442226  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 1585556  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7296     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19268    |\n",
      "|    total_timesteps  | 6446920  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00332  |\n",
      "|    n_updates        | 1586729  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6450000, episode_reward=3.80 +/- 8.18\n",
      "Episode length: 1140.20 +/- 291.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00915  |\n",
      "|    n_updates        | 1587499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.03     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7300     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19290    |\n",
      "|    total_timesteps  | 6452766  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 1588191  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7304     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19301    |\n",
      "|    total_timesteps  | 6457682  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.025    |\n",
      "|    n_updates        | 1589420  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6460000, episode_reward=6.40 +/- 4.45\n",
      "Episode length: 1022.60 +/- 323.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0087   |\n",
      "|    n_updates        | 1589999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7308     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19323    |\n",
      "|    total_timesteps  | 6463663  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 1590915  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.49     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7312     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19334    |\n",
      "|    total_timesteps  | 6468722  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00715  |\n",
      "|    n_updates        | 1592180  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6470000, episode_reward=-0.40 +/- 3.32\n",
      "Episode length: 1273.20 +/- 157.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0429   |\n",
      "|    n_updates        | 1592499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.81     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7316     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19355    |\n",
      "|    total_timesteps  | 6473486  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 1593371  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.7      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7320     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19367    |\n",
      "|    total_timesteps  | 6478669  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00839  |\n",
      "|    n_updates        | 1594667  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6480000, episode_reward=2.40 +/- 6.15\n",
      "Episode length: 1002.20 +/- 471.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0223   |\n",
      "|    n_updates        | 1594999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7324     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19390    |\n",
      "|    total_timesteps  | 6485189  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 1596297  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6490000, episode_reward=1.00 +/- 7.27\n",
      "Episode length: 1162.60 +/- 406.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0235   |\n",
      "|    n_updates        | 1597499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.67     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7328     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19413    |\n",
      "|    total_timesteps  | 6491239  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00474  |\n",
      "|    n_updates        | 1597809  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.89     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7332     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19424    |\n",
      "|    total_timesteps  | 6495784  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 1598945  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6500000, episode_reward=5.20 +/- 2.32\n",
      "Episode length: 1220.80 +/- 123.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0405   |\n",
      "|    n_updates        | 1599999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.8      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7336     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19445    |\n",
      "|    total_timesteps  | 6501168  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 1600291  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.63     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7340     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19457    |\n",
      "|    total_timesteps  | 6506256  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 1601563  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6510000, episode_reward=4.80 +/- 6.11\n",
      "Episode length: 1257.20 +/- 221.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 1602499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.79     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7344     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19478    |\n",
      "|    total_timesteps  | 6510932  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0029   |\n",
      "|    n_updates        | 1602732  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7348     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19490    |\n",
      "|    total_timesteps  | 6516044  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 1604010  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6520000, episode_reward=0.80 +/- 5.19\n",
      "Episode length: 1247.60 +/- 305.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.25e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00739  |\n",
      "|    n_updates        | 1604999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7352     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19511    |\n",
      "|    total_timesteps  | 6521450  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 1605362  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.92     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7356     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19522    |\n",
      "|    total_timesteps  | 6526086  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00592  |\n",
      "|    n_updates        | 1606521  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6530000, episode_reward=6.40 +/- 5.28\n",
      "Episode length: 957.40 +/- 453.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 957      |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1607499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.67     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7360     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19545    |\n",
      "|    total_timesteps  | 6532570  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 1608142  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7364     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19555    |\n",
      "|    total_timesteps  | 6536835  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00844  |\n",
      "|    n_updates        | 1609208  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6540000, episode_reward=0.80 +/- 5.34\n",
      "Episode length: 1096.60 +/- 161.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 1609999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.27     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7368     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19576    |\n",
      "|    total_timesteps  | 6542564  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 1610640  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.04     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7372     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19588    |\n",
      "|    total_timesteps  | 6547625  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 1611906  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6550000, episode_reward=0.60 +/- 4.96\n",
      "Episode length: 1120.40 +/- 521.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00537  |\n",
      "|    n_updates        | 1612499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.82     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7376     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19611    |\n",
      "|    total_timesteps  | 6553696  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 1613423  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7380     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19622    |\n",
      "|    total_timesteps  | 6558311  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00481  |\n",
      "|    n_updates        | 1614577  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6560000, episode_reward=6.00 +/- 2.61\n",
      "Episode length: 1193.60 +/- 202.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 6        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 1614999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7384     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19644    |\n",
      "|    total_timesteps  | 6564113  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 1616028  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7388     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19658    |\n",
      "|    total_timesteps  | 6569820  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00679  |\n",
      "|    n_updates        | 1617454  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6570000, episode_reward=6.40 +/- 3.72\n",
      "Episode length: 1122.60 +/- 179.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 1617499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.12     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7392     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19679    |\n",
      "|    total_timesteps  | 6575304  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 1618825  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6580000, episode_reward=4.80 +/- 4.49\n",
      "Episode length: 1013.20 +/- 464.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0396   |\n",
      "|    n_updates        | 1619999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.13     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7396     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19699    |\n",
      "|    total_timesteps  | 6581031  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0087   |\n",
      "|    n_updates        | 1620257  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.82     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7400     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19709    |\n",
      "|    total_timesteps  | 6585191  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 1621297  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6590000, episode_reward=6.00 +/- 4.60\n",
      "Episode length: 997.20 +/- 433.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 997      |\n",
      "|    mean_reward      | 6        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0061   |\n",
      "|    n_updates        | 1622499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7404     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19731    |\n",
      "|    total_timesteps  | 6591154  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 1622788  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7408     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19741    |\n",
      "|    total_timesteps  | 6595735  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 1623933  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6600000, episode_reward=4.60 +/- 5.92\n",
      "Episode length: 1100.80 +/- 185.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 1624999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7412     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19762    |\n",
      "|    total_timesteps  | 6601083  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 1625270  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7416     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19774    |\n",
      "|    total_timesteps  | 6606075  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 1626518  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6610000, episode_reward=0.80 +/- 10.19\n",
      "Episode length: 1059.80 +/- 206.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00412  |\n",
      "|    n_updates        | 1627499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7420     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 19794    |\n",
      "|    total_timesteps  | 6611308  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0095   |\n",
      "|    n_updates        | 1627826  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7424     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19807    |\n",
      "|    total_timesteps  | 6616910  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0087   |\n",
      "|    n_updates        | 1629227  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6620000, episode_reward=-1.80 +/- 6.49\n",
      "Episode length: 1086.60 +/- 423.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 1629999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7428     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 19830    |\n",
      "|    total_timesteps  | 6623071  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00492  |\n",
      "|    n_updates        | 1630767  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7432     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19841    |\n",
      "|    total_timesteps  | 6627946  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 1631986  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6630000, episode_reward=2.60 +/- 5.61\n",
      "Episode length: 1241.60 +/- 133.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 1632499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7436     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 19862    |\n",
      "|    total_timesteps  | 6633003  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00453  |\n",
      "|    n_updates        | 1633250  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7440     |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 19874    |\n",
      "|    total_timesteps  | 6638349  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00979  |\n",
      "|    n_updates        | 1634587  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6640000, episode_reward=-2.20 +/- 6.49\n",
      "Episode length: 994.40 +/- 319.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 994      |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0264   |\n",
      "|    n_updates        | 1634999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.31     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7444     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 19893    |\n",
      "|    total_timesteps  | 6643265  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00463  |\n",
      "|    n_updates        | 1635816  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.15     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7448     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 19905    |\n",
      "|    total_timesteps  | 6648121  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00278  |\n",
      "|    n_updates        | 1637030  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6650000, episode_reward=1.80 +/- 7.11\n",
      "Episode length: 1011.40 +/- 405.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1637499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7452     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 19925    |\n",
      "|    total_timesteps  | 6653753  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 1638438  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 0.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7456     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 19937    |\n",
      "|    total_timesteps  | 6658801  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00668  |\n",
      "|    n_updates        | 1639700  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6660000, episode_reward=1.00 +/- 4.10\n",
      "Episode length: 1192.80 +/- 573.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 1639999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.43     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7460     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 19960    |\n",
      "|    total_timesteps  | 6664713  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 1641178  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6670000, episode_reward=4.80 +/- 5.42\n",
      "Episode length: 1075.20 +/- 371.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 1642499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 0.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7464     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 19982    |\n",
      "|    total_timesteps  | 6670873  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00463  |\n",
      "|    n_updates        | 1642718  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 0.6      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7468     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 19992    |\n",
      "|    total_timesteps  | 6675197  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00612  |\n",
      "|    n_updates        | 1643799  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6680000, episode_reward=-0.40 +/- 7.86\n",
      "Episode length: 997.00 +/- 414.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 997      |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1644999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 0.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7472     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20014    |\n",
      "|    total_timesteps  | 6681261  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 1645315  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7476     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20025    |\n",
      "|    total_timesteps  | 6685894  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00753  |\n",
      "|    n_updates        | 1646473  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6690000, episode_reward=2.40 +/- 7.61\n",
      "Episode length: 1097.40 +/- 157.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 1647499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 0.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7480     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20045    |\n",
      "|    total_timesteps  | 6691285  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 1647821  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7484     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20057    |\n",
      "|    total_timesteps  | 6696037  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 1649009  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6700000, episode_reward=2.20 +/- 8.08\n",
      "Episode length: 1203.60 +/- 79.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 2.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00642  |\n",
      "|    n_updates        | 1649999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7488     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20078    |\n",
      "|    total_timesteps  | 6701239  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 1650309  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7492     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20089    |\n",
      "|    total_timesteps  | 6706225  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 1651556  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6710000, episode_reward=3.60 +/- 5.54\n",
      "Episode length: 1018.60 +/- 447.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 1652499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7496     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20112    |\n",
      "|    total_timesteps  | 6712694  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0379   |\n",
      "|    n_updates        | 1653173  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7500     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20124    |\n",
      "|    total_timesteps  | 6717645  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 1654411  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6720000, episode_reward=4.40 +/- 4.96\n",
      "Episode length: 1022.20 +/- 404.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 1654999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7504     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20145    |\n",
      "|    total_timesteps  | 6723330  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00509  |\n",
      "|    n_updates        | 1655832  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7508     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20157    |\n",
      "|    total_timesteps  | 6728235  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 1657058  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6730000, episode_reward=-1.80 +/- 5.64\n",
      "Episode length: 1163.60 +/- 298.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00523  |\n",
      "|    n_updates        | 1657499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 0.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7512     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20178    |\n",
      "|    total_timesteps  | 6733640  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 1658409  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7516     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20189    |\n",
      "|    total_timesteps  | 6738117  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0243   |\n",
      "|    n_updates        | 1659529  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6740000, episode_reward=7.40 +/- 3.61\n",
      "Episode length: 1149.20 +/- 94.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 7.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00458  |\n",
      "|    n_updates        | 1659999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7520     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20206    |\n",
      "|    total_timesteps  | 6741972  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 1660492  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7524     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20217    |\n",
      "|    total_timesteps  | 6746588  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00344  |\n",
      "|    n_updates        | 1661646  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6750000, episode_reward=6.80 +/- 4.02\n",
      "Episode length: 1069.40 +/- 338.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 6.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00521  |\n",
      "|    n_updates        | 1662499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.48     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7528     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20239    |\n",
      "|    total_timesteps  | 6752608  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00837  |\n",
      "|    n_updates        | 1663151  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7532     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20251    |\n",
      "|    total_timesteps  | 6757620  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 1664404  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6760000, episode_reward=3.00 +/- 5.02\n",
      "Episode length: 1043.00 +/- 490.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00617  |\n",
      "|    n_updates        | 1664999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.42     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7536     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20274    |\n",
      "|    total_timesteps  | 6764145  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 1666036  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 0.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7540     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20286    |\n",
      "|    total_timesteps  | 6769359  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00832  |\n",
      "|    n_updates        | 1667339  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6770000, episode_reward=0.00 +/- 6.39\n",
      "Episode length: 1056.60 +/- 412.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 0        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00467  |\n",
      "|    n_updates        | 1667499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7544     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20308    |\n",
      "|    total_timesteps  | 6775114  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00613  |\n",
      "|    n_updates        | 1668778  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7548     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20318    |\n",
      "|    total_timesteps  | 6779639  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00816  |\n",
      "|    n_updates        | 1669909  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6780000, episode_reward=2.40 +/- 9.91\n",
      "Episode length: 1106.60 +/- 250.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 1669999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.65     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7552     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20340    |\n",
      "|    total_timesteps  | 6785542  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 1671385  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6790000, episode_reward=6.40 +/- 5.16\n",
      "Episode length: 1078.00 +/- 233.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 1672499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7556     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20361    |\n",
      "|    total_timesteps  | 6791138  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 1672784  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.09     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7560     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20374    |\n",
      "|    total_timesteps  | 6796392  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0086   |\n",
      "|    n_updates        | 1674097  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6800000, episode_reward=1.60 +/- 7.20\n",
      "Episode length: 1104.80 +/- 413.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 1674999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7564     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20396    |\n",
      "|    total_timesteps  | 6802530  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00733  |\n",
      "|    n_updates        | 1675632  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.12     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7568     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20407    |\n",
      "|    total_timesteps  | 6806840  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 1676709  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6810000, episode_reward=-0.80 +/- 5.11\n",
      "Episode length: 1178.00 +/- 286.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00588  |\n",
      "|    n_updates        | 1677499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7572     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20429    |\n",
      "|    total_timesteps  | 6812543  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1678135  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7576     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20440    |\n",
      "|    total_timesteps  | 6817474  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 1679368  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6820000, episode_reward=6.40 +/- 3.61\n",
      "Episode length: 1201.20 +/- 185.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1679999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7580     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20460    |\n",
      "|    total_timesteps  | 6822448  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00779  |\n",
      "|    n_updates        | 1680611  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7584     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20471    |\n",
      "|    total_timesteps  | 6827064  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 1681765  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6830000, episode_reward=-0.60 +/- 7.23\n",
      "Episode length: 1043.00 +/- 227.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | -0.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 1682499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.79     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7588     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20492    |\n",
      "|    total_timesteps  | 6832536  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00774  |\n",
      "|    n_updates        | 1683133  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.52     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7592     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20503    |\n",
      "|    total_timesteps  | 6837443  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00691  |\n",
      "|    n_updates        | 1684360  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6840000, episode_reward=0.40 +/- 6.53\n",
      "Episode length: 1101.00 +/- 496.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00353  |\n",
      "|    n_updates        | 1684999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7596     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20526    |\n",
      "|    total_timesteps  | 6843921  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 1685980  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.81     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7600     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20538    |\n",
      "|    total_timesteps  | 6848688  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1687171  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6850000, episode_reward=4.80 +/- 2.99\n",
      "Episode length: 1036.80 +/- 527.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00323  |\n",
      "|    n_updates        | 1687499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7604     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20560    |\n",
      "|    total_timesteps  | 6855240  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0235   |\n",
      "|    n_updates        | 1688809  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6860000, episode_reward=0.60 +/- 5.24\n",
      "Episode length: 1125.80 +/- 455.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00516  |\n",
      "|    n_updates        | 1689999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.16     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7608     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20582    |\n",
      "|    total_timesteps  | 6861124  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00931  |\n",
      "|    n_updates        | 1690280  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7612     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20594    |\n",
      "|    total_timesteps  | 6866105  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1691526  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6870000, episode_reward=-1.20 +/- 5.64\n",
      "Episode length: 1210.20 +/- 182.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | -1.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00486  |\n",
      "|    n_updates        | 1692499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7616     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20616    |\n",
      "|    total_timesteps  | 6871301  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00458  |\n",
      "|    n_updates        | 1692825  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.36     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7620     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20627    |\n",
      "|    total_timesteps  | 6875950  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 1693987  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6880000, episode_reward=3.60 +/- 7.17\n",
      "Episode length: 1100.00 +/- 240.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 1694999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.94     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7624     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20647    |\n",
      "|    total_timesteps  | 6881244  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0043   |\n",
      "|    n_updates        | 1695310  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.05     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7628     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20657    |\n",
      "|    total_timesteps  | 6885491  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 1696372  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6890000, episode_reward=3.20 +/- 6.18\n",
      "Episode length: 1193.00 +/- 267.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00478  |\n",
      "|    n_updates        | 1697499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7632     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20680    |\n",
      "|    total_timesteps  | 6891428  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 1697856  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7636     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20692    |\n",
      "|    total_timesteps  | 6896611  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00621  |\n",
      "|    n_updates        | 1699152  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6900000, episode_reward=4.60 +/- 5.08\n",
      "Episode length: 1008.40 +/- 427.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00921  |\n",
      "|    n_updates        | 1699999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.87     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7640     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20714    |\n",
      "|    total_timesteps  | 6902646  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1700661  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.67     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7644     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20726    |\n",
      "|    total_timesteps  | 6907595  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00833  |\n",
      "|    n_updates        | 1701898  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6910000, episode_reward=4.40 +/- 4.92\n",
      "Episode length: 1264.80 +/- 171.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 1702499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7648     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20746    |\n",
      "|    total_timesteps  | 6912424  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00923  |\n",
      "|    n_updates        | 1703105  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7652     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20758    |\n",
      "|    total_timesteps  | 6917152  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1704287  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6920000, episode_reward=1.00 +/- 8.10\n",
      "Episode length: 1120.80 +/- 220.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0344   |\n",
      "|    n_updates        | 1704999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7656     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20779    |\n",
      "|    total_timesteps  | 6922834  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00904  |\n",
      "|    n_updates        | 1705708  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.61     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7660     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20789    |\n",
      "|    total_timesteps  | 6927164  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 1706790  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6930000, episode_reward=3.00 +/- 4.24\n",
      "Episode length: 1155.60 +/- 238.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0036   |\n",
      "|    n_updates        | 1707499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.63     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7664     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20811    |\n",
      "|    total_timesteps  | 6932726  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 1708181  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7668     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20822    |\n",
      "|    total_timesteps  | 6937511  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00555  |\n",
      "|    n_updates        | 1709377  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6940000, episode_reward=-3.60 +/- 5.08\n",
      "Episode length: 1167.80 +/- 64.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -3.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 1709999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7672     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20844    |\n",
      "|    total_timesteps  | 6942981  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00895  |\n",
      "|    n_updates        | 1710745  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7676     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20855    |\n",
      "|    total_timesteps  | 6947627  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00511  |\n",
      "|    n_updates        | 1711906  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6950000, episode_reward=4.80 +/- 8.61\n",
      "Episode length: 903.80 +/- 448.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 904      |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 1712499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7680     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20876    |\n",
      "|    total_timesteps  | 6953843  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 1713460  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7684     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20889    |\n",
      "|    total_timesteps  | 6959465  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00619  |\n",
      "|    n_updates        | 1714866  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6960000, episode_reward=7.80 +/- 2.93\n",
      "Episode length: 1009.20 +/- 210.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 7.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1714999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7688     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20910    |\n",
      "|    total_timesteps  | 6965103  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00313  |\n",
      "|    n_updates        | 1716275  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6970000, episode_reward=3.40 +/- 8.31\n",
      "Episode length: 1027.00 +/- 395.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00489  |\n",
      "|    n_updates        | 1717499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.89     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7692     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20932    |\n",
      "|    total_timesteps  | 6971325  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1717831  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.87     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7696     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20944    |\n",
      "|    total_timesteps  | 6976410  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1719102  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6980000, episode_reward=-1.20 +/- 5.19\n",
      "Episode length: 1069.60 +/- 382.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -1.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00753  |\n",
      "|    n_updates        | 1719999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.75     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7700     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20965    |\n",
      "|    total_timesteps  | 6981897  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00592  |\n",
      "|    n_updates        | 1720474  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7704     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 20978    |\n",
      "|    total_timesteps  | 6987338  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 1721834  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6990000, episode_reward=4.40 +/- 5.46\n",
      "Episode length: 1277.40 +/- 218.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00469  |\n",
      "|    n_updates        | 1722499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7708     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 20999    |\n",
      "|    total_timesteps  | 6992579  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 1723144  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.62     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7712     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 21011    |\n",
      "|    total_timesteps  | 6997740  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1724434  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7000000, episode_reward=3.40 +/- 6.71\n",
      "Episode length: 1279.20 +/- 332.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 1724999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7716     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21031    |\n",
      "|    total_timesteps  | 7002170  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0043   |\n",
      "|    n_updates        | 1725542  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.86     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7720     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21042    |\n",
      "|    total_timesteps  | 7006902  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00428  |\n",
      "|    n_updates        | 1726725  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7010000, episode_reward=4.20 +/- 1.60\n",
      "Episode length: 1274.40 +/- 319.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 1727499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.82     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7724     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21064    |\n",
      "|    total_timesteps  | 7012331  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0257   |\n",
      "|    n_updates        | 1728082  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7728     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21075    |\n",
      "|    total_timesteps  | 7016928  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 1729231  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7020000, episode_reward=0.80 +/- 5.46\n",
      "Episode length: 1116.00 +/- 504.70\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0428   |\n",
      "|    n_updates        | 1729999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.34     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7732     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21097    |\n",
      "|    total_timesteps  | 7022841  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 1730710  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7736     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21108    |\n",
      "|    total_timesteps  | 7027565  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 1731891  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7030000, episode_reward=4.80 +/- 3.19\n",
      "Episode length: 993.00 +/- 466.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 993      |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00695  |\n",
      "|    n_updates        | 1732499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7740     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21129    |\n",
      "|    total_timesteps  | 7033068  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00805  |\n",
      "|    n_updates        | 1733266  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7744     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21140    |\n",
      "|    total_timesteps  | 7037781  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00369  |\n",
      "|    n_updates        | 1734445  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7040000, episode_reward=7.40 +/- 3.20\n",
      "Episode length: 977.80 +/- 290.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 978      |\n",
      "|    mean_reward      | 7.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00653  |\n",
      "|    n_updates        | 1734999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7748     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21160    |\n",
      "|    total_timesteps  | 7043308  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 1735826  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7752     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21173    |\n",
      "|    total_timesteps  | 7048756  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00621  |\n",
      "|    n_updates        | 1737188  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7050000, episode_reward=-1.00 +/- 6.54\n",
      "Episode length: 1279.00 +/- 207.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | -1       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00601  |\n",
      "|    n_updates        | 1737499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.28     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7756     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21194    |\n",
      "|    total_timesteps  | 7053961  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 1738490  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7760     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21206    |\n",
      "|    total_timesteps  | 7058755  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1739688  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7060000, episode_reward=3.60 +/- 5.75\n",
      "Episode length: 1006.60 +/- 482.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00346  |\n",
      "|    n_updates        | 1739999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7764     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21228    |\n",
      "|    total_timesteps  | 7065046  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0063   |\n",
      "|    n_updates        | 1741261  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.17     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7768     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21239    |\n",
      "|    total_timesteps  | 7069808  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00494  |\n",
      "|    n_updates        | 1742451  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7070000, episode_reward=6.80 +/- 4.35\n",
      "Episode length: 1136.40 +/- 185.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 6.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00854  |\n",
      "|    n_updates        | 1742499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.98     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7772     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21261    |\n",
      "|    total_timesteps  | 7075315  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00456  |\n",
      "|    n_updates        | 1743828  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7080000, episode_reward=-2.60 +/- 7.39\n",
      "Episode length: 1212.80 +/- 190.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | -2.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00975  |\n",
      "|    n_updates        | 1744999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.34     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7776     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21284    |\n",
      "|    total_timesteps  | 7081179  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1745294  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7780     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21296    |\n",
      "|    total_timesteps  | 7086250  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00642  |\n",
      "|    n_updates        | 1746562  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7090000, episode_reward=3.80 +/- 4.96\n",
      "Episode length: 1055.80 +/- 485.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00699  |\n",
      "|    n_updates        | 1747499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.98     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7784     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21318    |\n",
      "|    total_timesteps  | 7092402  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 1748100  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.03     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7788     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21330    |\n",
      "|    total_timesteps  | 7097395  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00648  |\n",
      "|    n_updates        | 1749348  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7100000, episode_reward=6.20 +/- 5.60\n",
      "Episode length: 1115.60 +/- 361.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 6.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00855  |\n",
      "|    n_updates        | 1749999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7792     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21350    |\n",
      "|    total_timesteps  | 7102509  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 1750627  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.34     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7796     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21361    |\n",
      "|    total_timesteps  | 7107178  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00979  |\n",
      "|    n_updates        | 1751794  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7110000, episode_reward=6.80 +/- 3.31\n",
      "Episode length: 1181.80 +/- 163.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 6.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1752499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.48     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7800     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21383    |\n",
      "|    total_timesteps  | 7112977  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00528  |\n",
      "|    n_updates        | 1753244  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7804     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21396    |\n",
      "|    total_timesteps  | 7118367  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00706  |\n",
      "|    n_updates        | 1754591  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7120000, episode_reward=8.80 +/- 7.76\n",
      "Episode length: 1060.40 +/- 155.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 8.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00874  |\n",
      "|    n_updates        | 1754999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.19     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7808     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21415    |\n",
      "|    total_timesteps  | 7123375  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 1755843  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.34     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7812     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21428    |\n",
      "|    total_timesteps  | 7128613  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00667  |\n",
      "|    n_updates        | 1757153  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7130000, episode_reward=5.60 +/- 6.89\n",
      "Episode length: 1297.00 +/- 246.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.3e+03  |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 1757499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7816     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21448    |\n",
      "|    total_timesteps  | 7133490  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 1758372  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.79     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7820     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21461    |\n",
      "|    total_timesteps  | 7138667  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0343   |\n",
      "|    n_updates        | 1759666  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7140000, episode_reward=2.80 +/- 4.58\n",
      "Episode length: 1298.20 +/- 120.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.3e+03  |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00702  |\n",
      "|    n_updates        | 1759999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7824     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21482    |\n",
      "|    total_timesteps  | 7143686  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 1760921  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7828     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21494    |\n",
      "|    total_timesteps  | 7148689  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 1762172  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7150000, episode_reward=1.00 +/- 5.90\n",
      "Episode length: 1190.80 +/- 121.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00944  |\n",
      "|    n_updates        | 1762499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.69     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7832     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21513    |\n",
      "|    total_timesteps  | 7153203  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00516  |\n",
      "|    n_updates        | 1763300  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7836     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21526    |\n",
      "|    total_timesteps  | 7158870  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00648  |\n",
      "|    n_updates        | 1764717  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7160000, episode_reward=0.40 +/- 6.95\n",
      "Episode length: 1075.80 +/- 543.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0052   |\n",
      "|    n_updates        | 1764999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.11     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7840     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21548    |\n",
      "|    total_timesteps  | 7164897  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 1766224  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7844     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21558    |\n",
      "|    total_timesteps  | 7169221  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 1767305  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7170000, episode_reward=-0.60 +/- 5.31\n",
      "Episode length: 1124.80 +/- 360.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -0.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 1767499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.93     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7848     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21581    |\n",
      "|    total_timesteps  | 7175503  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0685   |\n",
      "|    n_updates        | 1768875  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7180000, episode_reward=2.40 +/- 3.44\n",
      "Episode length: 1118.20 +/- 412.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1769999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7852     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21604    |\n",
      "|    total_timesteps  | 7181346  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 1770336  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7856     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21615    |\n",
      "|    total_timesteps  | 7186210  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 1771552  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7190000, episode_reward=3.20 +/- 3.82\n",
      "Episode length: 1128.20 +/- 446.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 1772499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7860     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21637    |\n",
      "|    total_timesteps  | 7192111  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00632  |\n",
      "|    n_updates        | 1773027  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7864     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21650    |\n",
      "|    total_timesteps  | 7197495  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0097   |\n",
      "|    n_updates        | 1774373  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7200000, episode_reward=5.20 +/- 3.37\n",
      "Episode length: 1013.00 +/- 512.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00663  |\n",
      "|    n_updates        | 1774999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.84     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7868     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21672    |\n",
      "|    total_timesteps  | 7203636  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0096   |\n",
      "|    n_updates        | 1775908  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7872     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21682    |\n",
      "|    total_timesteps  | 7207831  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00714  |\n",
      "|    n_updates        | 1776957  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7210000, episode_reward=-2.40 +/- 6.50\n",
      "Episode length: 1129.20 +/- 271.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | -2.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00995  |\n",
      "|    n_updates        | 1777499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7876     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21703    |\n",
      "|    total_timesteps  | 7213415  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00772  |\n",
      "|    n_updates        | 1778353  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7880     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21716    |\n",
      "|    total_timesteps  | 7218592  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 1779647  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7220000, episode_reward=5.80 +/- 4.26\n",
      "Episode length: 953.00 +/- 447.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 953      |\n",
      "|    mean_reward      | 5.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00345  |\n",
      "|    n_updates        | 1779999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.01     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7884     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21739    |\n",
      "|    total_timesteps  | 7225495  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0342   |\n",
      "|    n_updates        | 1781373  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7230000, episode_reward=5.80 +/- 4.02\n",
      "Episode length: 1047.40 +/- 357.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | 5.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 1782499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7888     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21760    |\n",
      "|    total_timesteps  | 7231336  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 1782833  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7892     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21771    |\n",
      "|    total_timesteps  | 7236026  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00946  |\n",
      "|    n_updates        | 1784006  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7240000, episode_reward=7.80 +/- 6.76\n",
      "Episode length: 1049.80 +/- 181.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | 7.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00449  |\n",
      "|    n_updates        | 1784999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7896     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21791    |\n",
      "|    total_timesteps  | 7241511  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00474  |\n",
      "|    n_updates        | 1785377  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.67     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7900     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21802    |\n",
      "|    total_timesteps  | 7246241  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00544  |\n",
      "|    n_updates        | 1786560  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7250000, episode_reward=4.60 +/- 2.06\n",
      "Episode length: 1055.00 +/- 428.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 1787499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7904     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21825    |\n",
      "|    total_timesteps  | 7252476  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 1788118  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7908     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21838    |\n",
      "|    total_timesteps  | 7257721  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 1789430  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7260000, episode_reward=2.60 +/- 7.06\n",
      "Episode length: 965.40 +/- 419.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 965      |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 1789999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 1.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7912     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21860    |\n",
      "|    total_timesteps  | 7263997  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 1790999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 1.61     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7916     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21874    |\n",
      "|    total_timesteps  | 7269211  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00561  |\n",
      "|    n_updates        | 1792302  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7270000, episode_reward=-1.00 +/- 6.10\n",
      "Episode length: 1228.60 +/- 476.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -1       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00648  |\n",
      "|    n_updates        | 1792499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 1.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7920     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21898    |\n",
      "|    total_timesteps  | 7275433  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0047   |\n",
      "|    n_updates        | 1793858  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7280000, episode_reward=4.40 +/- 4.96\n",
      "Episode length: 957.60 +/- 320.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 958      |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 1794999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 1.52     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7924     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21919    |\n",
      "|    total_timesteps  | 7281445  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 1795361  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 1.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7928     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21931    |\n",
      "|    total_timesteps  | 7286525  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00738  |\n",
      "|    n_updates        | 1796631  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7290000, episode_reward=2.60 +/- 8.64\n",
      "Episode length: 879.20 +/- 371.70\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 879      |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 1797499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.39e+03 |\n",
      "|    ep_rew_mean      | 1.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7932     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21952    |\n",
      "|    total_timesteps  | 7292537  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1798134  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.39e+03 |\n",
      "|    ep_rew_mean      | 1.46     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7936     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21964    |\n",
      "|    total_timesteps  | 7297579  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00474  |\n",
      "|    n_updates        | 1799394  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7300000, episode_reward=7.60 +/- 3.01\n",
      "Episode length: 936.60 +/- 399.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 937      |\n",
      "|    mean_reward      | 7.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 1799999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.39e+03 |\n",
      "|    ep_rew_mean      | 1.19     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7940     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21985    |\n",
      "|    total_timesteps  | 7303573  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00856  |\n",
      "|    n_updates        | 1800893  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.39e+03 |\n",
      "|    ep_rew_mean      | 1.05     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7944     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 21995    |\n",
      "|    total_timesteps  | 7307966  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 1801991  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7310000, episode_reward=8.00 +/- 6.42\n",
      "Episode length: 922.60 +/- 304.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 923      |\n",
      "|    mean_reward      | 8        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00917  |\n",
      "|    n_updates        | 1802499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 1.28     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7948     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22016    |\n",
      "|    total_timesteps  | 7313932  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00819  |\n",
      "|    n_updates        | 1803482  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 1.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7952     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22028    |\n",
      "|    total_timesteps  | 7319108  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 1804776  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7320000, episode_reward=2.80 +/- 8.01\n",
      "Episode length: 921.40 +/- 466.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 921      |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0093   |\n",
      "|    n_updates        | 1804999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.39e+03 |\n",
      "|    ep_rew_mean      | 1.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7956     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22050    |\n",
      "|    total_timesteps  | 7325260  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00368  |\n",
      "|    n_updates        | 1806314  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 1.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7960     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22061    |\n",
      "|    total_timesteps  | 7329924  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 1807480  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7330000, episode_reward=5.60 +/- 4.92\n",
      "Episode length: 1223.00 +/- 123.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00631  |\n",
      "|    n_updates        | 1807499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 1.75     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7964     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22082    |\n",
      "|    total_timesteps  | 7334786  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0063   |\n",
      "|    n_updates        | 1808696  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7340000, episode_reward=3.20 +/- 5.98\n",
      "Episode length: 1028.40 +/- 514.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 1809999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 1.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7968     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22104    |\n",
      "|    total_timesteps  | 7341127  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 1810281  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 1.19     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7972     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22115    |\n",
      "|    total_timesteps  | 7345923  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 1811480  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7350000, episode_reward=6.40 +/- 2.65\n",
      "Episode length: 1224.00 +/- 215.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00603  |\n",
      "|    n_updates        | 1812499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 1.12     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7976     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22137    |\n",
      "|    total_timesteps  | 7351290  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00705  |\n",
      "|    n_updates        | 1812822  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 1.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7980     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22149    |\n",
      "|    total_timesteps  | 7356187  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 1814046  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7360000, episode_reward=3.20 +/- 2.14\n",
      "Episode length: 1099.20 +/- 365.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00652  |\n",
      "|    n_updates        | 1814999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 1.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7984     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22169    |\n",
      "|    total_timesteps  | 7361115  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00956  |\n",
      "|    n_updates        | 1815278  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 1.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7988     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22180    |\n",
      "|    total_timesteps  | 7366123  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 1816530  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7370000, episode_reward=6.40 +/- 4.22\n",
      "Episode length: 1281.80 +/- 116.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 1817499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 1.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7992     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22202    |\n",
      "|    total_timesteps  | 7371207  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 1817801  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.79     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7996     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22212    |\n",
      "|    total_timesteps  | 7375500  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00347  |\n",
      "|    n_updates        | 1818874  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7380000, episode_reward=5.20 +/- 4.83\n",
      "Episode length: 1071.00 +/- 382.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 1819999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 1.69     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8000     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22233    |\n",
      "|    total_timesteps  | 7381114  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 1820278  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.02     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8004     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 22245    |\n",
      "|    total_timesteps  | 7386095  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 1821523  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7390000, episode_reward=2.80 +/- 5.04\n",
      "Episode length: 1343.60 +/- 119.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00954  |\n",
      "|    n_updates        | 1822499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 1.93     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8008     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22267    |\n",
      "|    total_timesteps  | 7391265  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0051   |\n",
      "|    n_updates        | 1822816  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.94     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8012     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22278    |\n",
      "|    total_timesteps  | 7396004  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 1824000  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7400000, episode_reward=2.00 +/- 6.13\n",
      "Episode length: 1080.00 +/- 241.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00507  |\n",
      "|    n_updates        | 1824999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8016     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22299    |\n",
      "|    total_timesteps  | 7401493  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00477  |\n",
      "|    n_updates        | 1825373  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8020     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22312    |\n",
      "|    total_timesteps  | 7406676  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 1826668  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7410000, episode_reward=-3.00 +/- 4.34\n",
      "Episode length: 1248.80 +/- 309.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.25e+03 |\n",
      "|    mean_reward      | -3       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 1827499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.46     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8024     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22335    |\n",
      "|    total_timesteps  | 7412673  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00757  |\n",
      "|    n_updates        | 1828168  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8028     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22346    |\n",
      "|    total_timesteps  | 7417225  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 1829306  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7420000, episode_reward=2.40 +/- 7.26\n",
      "Episode length: 1209.00 +/- 158.70\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 1829999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8032     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22367    |\n",
      "|    total_timesteps  | 7422527  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 1830631  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.82     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8036     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22379    |\n",
      "|    total_timesteps  | 7427513  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00436  |\n",
      "|    n_updates        | 1831878  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7430000, episode_reward=7.40 +/- 3.77\n",
      "Episode length: 983.00 +/- 363.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 983      |\n",
      "|    mean_reward      | 7.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 1832499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8040     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22400    |\n",
      "|    total_timesteps  | 7433611  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00578  |\n",
      "|    n_updates        | 1833402  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.99     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8044     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22412    |\n",
      "|    total_timesteps  | 7438501  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 1834625  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7440000, episode_reward=3.40 +/- 4.32\n",
      "Episode length: 1116.60 +/- 293.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00543  |\n",
      "|    n_updates        | 1834999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.89     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8048     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22434    |\n",
      "|    total_timesteps  | 7444383  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 1836095  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.81     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8052     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22446    |\n",
      "|    total_timesteps  | 7449403  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1837350  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7450000, episode_reward=-2.40 +/- 7.96\n",
      "Episode length: 1053.20 +/- 311.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | -2.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00458  |\n",
      "|    n_updates        | 1837499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.85     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8056     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22466    |\n",
      "|    total_timesteps  | 7454628  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00645  |\n",
      "|    n_updates        | 1838656  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8060     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22476    |\n",
      "|    total_timesteps  | 7458625  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00544  |\n",
      "|    n_updates        | 1839656  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7460000, episode_reward=4.40 +/- 6.83\n",
      "Episode length: 1240.60 +/- 155.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00925  |\n",
      "|    n_updates        | 1839999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8064     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22497    |\n",
      "|    total_timesteps  | 7463830  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00588  |\n",
      "|    n_updates        | 1840957  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 2.93     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8068     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22507    |\n",
      "|    total_timesteps  | 7468118  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00865  |\n",
      "|    n_updates        | 1842029  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7470000, episode_reward=7.80 +/- 6.40\n",
      "Episode length: 989.80 +/- 220.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 990      |\n",
      "|    mean_reward      | 7.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 1842499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.11     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8072     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22528    |\n",
      "|    total_timesteps  | 7473457  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 1843364  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 3.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8076     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22539    |\n",
      "|    total_timesteps  | 7478316  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00653  |\n",
      "|    n_updates        | 1844578  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7480000, episode_reward=5.00 +/- 8.17\n",
      "Episode length: 1155.80 +/- 326.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 5        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00339  |\n",
      "|    n_updates        | 1844999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 3.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8080     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22560    |\n",
      "|    total_timesteps  | 7483678  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00189  |\n",
      "|    n_updates        | 1845919  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.02     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8084     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22573    |\n",
      "|    total_timesteps  | 7489215  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00469  |\n",
      "|    n_updates        | 1847303  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7490000, episode_reward=2.20 +/- 6.05\n",
      "Episode length: 1219.40 +/- 260.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 2.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00809  |\n",
      "|    n_updates        | 1847499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.12     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8088     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22594    |\n",
      "|    total_timesteps  | 7494475  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 1848618  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8092     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22607    |\n",
      "|    total_timesteps  | 7499817  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 1849954  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7500000, episode_reward=6.80 +/- 6.14\n",
      "Episode length: 1138.80 +/- 151.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 6.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 1849999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8096     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22626    |\n",
      "|    total_timesteps  | 7504446  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00664  |\n",
      "|    n_updates        | 1851111  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8100     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22637    |\n",
      "|    total_timesteps  | 7509199  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00896  |\n",
      "|    n_updates        | 1852299  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7510000, episode_reward=4.00 +/- 7.18\n",
      "Episode length: 1056.60 +/- 486.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 1852499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.46     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8104     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22658    |\n",
      "|    total_timesteps  | 7514783  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00411  |\n",
      "|    n_updates        | 1853695  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8108     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22667    |\n",
      "|    total_timesteps  | 7518768  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 1854691  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7520000, episode_reward=7.80 +/- 7.39\n",
      "Episode length: 912.60 +/- 430.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 913      |\n",
      "|    mean_reward      | 7.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 1854999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.91     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8112     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22690    |\n",
      "|    total_timesteps  | 7525439  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00663  |\n",
      "|    n_updates        | 1856359  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7530000, episode_reward=7.20 +/- 4.26\n",
      "Episode length: 900.40 +/- 348.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 900      |\n",
      "|    mean_reward      | 7.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00831  |\n",
      "|    n_updates        | 1857499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8116     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22710    |\n",
      "|    total_timesteps  | 7531396  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00778  |\n",
      "|    n_updates        | 1857848  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8120     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22723    |\n",
      "|    total_timesteps  | 7536717  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0059   |\n",
      "|    n_updates        | 1859179  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7540000, episode_reward=1.40 +/- 6.95\n",
      "Episode length: 1194.20 +/- 191.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00469  |\n",
      "|    n_updates        | 1859999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.8      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8124     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22741    |\n",
      "|    total_timesteps  | 7540959  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 1860239  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.46     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8128     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22752    |\n",
      "|    total_timesteps  | 7545486  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00944  |\n",
      "|    n_updates        | 1861371  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 2.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8132     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22763    |\n",
      "|    total_timesteps  | 7549882  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0036   |\n",
      "|    n_updates        | 1862470  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7550000, episode_reward=4.80 +/- 5.15\n",
      "Episode length: 1276.00 +/- 312.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0432   |\n",
      "|    n_updates        | 1862499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8136     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22785    |\n",
      "|    total_timesteps  | 7555452  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 1863862  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7560000, episode_reward=2.60 +/- 6.89\n",
      "Episode length: 1165.80 +/- 383.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00552  |\n",
      "|    n_updates        | 1864999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 2.41     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8140     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22807    |\n",
      "|    total_timesteps  | 7561066  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0356   |\n",
      "|    n_updates        | 1865266  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.52     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8144     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22820    |\n",
      "|    total_timesteps  | 7566414  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00629  |\n",
      "|    n_updates        | 1866603  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7570000, episode_reward=-2.60 +/- 4.27\n",
      "Episode length: 1051.00 +/- 485.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | -2.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00588  |\n",
      "|    n_updates        | 1867499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8148     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22842    |\n",
      "|    total_timesteps  | 7572500  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 1868124  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8152     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22853    |\n",
      "|    total_timesteps  | 7577334  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 1869333  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7580000, episode_reward=3.00 +/- 1.79\n",
      "Episode length: 1276.00 +/- 130.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00887  |\n",
      "|    n_updates        | 1869999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.65     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8156     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22875    |\n",
      "|    total_timesteps  | 7582751  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 1870687  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.69     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8160     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22887    |\n",
      "|    total_timesteps  | 7587497  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 1871874  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7590000, episode_reward=3.00 +/- 9.01\n",
      "Episode length: 1102.40 +/- 175.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00504  |\n",
      "|    n_updates        | 1872499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8164     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22906    |\n",
      "|    total_timesteps  | 7592191  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00924  |\n",
      "|    n_updates        | 1873047  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.75     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8168     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22917    |\n",
      "|    total_timesteps  | 7596979  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00752  |\n",
      "|    n_updates        | 1874244  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7600000, episode_reward=5.20 +/- 7.52\n",
      "Episode length: 949.40 +/- 209.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 949      |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 1874999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.81     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8172     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22937    |\n",
      "|    total_timesteps  | 7602678  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 1875669  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8176     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22950    |\n",
      "|    total_timesteps  | 7608000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00729  |\n",
      "|    n_updates        | 1876999  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7610000, episode_reward=-2.40 +/- 3.93\n",
      "Episode length: 1033.80 +/- 432.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | -2.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00731  |\n",
      "|    n_updates        | 1877499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.44     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8180     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22971    |\n",
      "|    total_timesteps  | 7613739  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 1878434  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.13     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8184     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 22982    |\n",
      "|    total_timesteps  | 7618686  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 1879671  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7620000, episode_reward=3.20 +/- 6.88\n",
      "Episode length: 1231.00 +/- 143.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00553  |\n",
      "|    n_updates        | 1879999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 1.89     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8188     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23004    |\n",
      "|    total_timesteps  | 7623783  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 1880945  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 1.99     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8192     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23015    |\n",
      "|    total_timesteps  | 7628707  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 1882176  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7630000, episode_reward=6.20 +/- 6.91\n",
      "Episode length: 1170.20 +/- 333.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 6.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 1882499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2        |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8196     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23035    |\n",
      "|    total_timesteps  | 7633291  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0055   |\n",
      "|    n_updates        | 1883322  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 1.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8200     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23047    |\n",
      "|    total_timesteps  | 7638389  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 1884597  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7640000, episode_reward=5.20 +/- 8.54\n",
      "Episode length: 1099.20 +/- 170.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00894  |\n",
      "|    n_updates        | 1884999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 1.92     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8204     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23067    |\n",
      "|    total_timesteps  | 7643776  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 1885943  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.46     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8208     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23080    |\n",
      "|    total_timesteps  | 7649026  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 1887256  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7650000, episode_reward=4.20 +/- 5.98\n",
      "Episode length: 1065.20 +/- 527.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0319   |\n",
      "|    n_updates        | 1887499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 1.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8212     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23101    |\n",
      "|    total_timesteps  | 7654664  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00403  |\n",
      "|    n_updates        | 1888665  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 1.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8216     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23113    |\n",
      "|    total_timesteps  | 7659698  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00674  |\n",
      "|    n_updates        | 1889924  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7660000, episode_reward=4.60 +/- 5.43\n",
      "Episode length: 1286.60 +/- 139.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.29e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00412  |\n",
      "|    n_updates        | 1889999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 1.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8220     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23134    |\n",
      "|    total_timesteps  | 7664715  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00427  |\n",
      "|    n_updates        | 1891178  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 1.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8224     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23145    |\n",
      "|    total_timesteps  | 7669427  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0071   |\n",
      "|    n_updates        | 1892356  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7670000, episode_reward=6.40 +/- 4.96\n",
      "Episode length: 985.00 +/- 298.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 985      |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 1892499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 1.86     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8228     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23164    |\n",
      "|    total_timesteps  | 7674343  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 1893585  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 1.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8232     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23176    |\n",
      "|    total_timesteps  | 7679306  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 1894826  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7680000, episode_reward=0.60 +/- 6.89\n",
      "Episode length: 1062.20 +/- 295.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 1894999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8236     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23198    |\n",
      "|    total_timesteps  | 7685313  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00889  |\n",
      "|    n_updates        | 1896328  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7690000, episode_reward=4.20 +/- 4.58\n",
      "Episode length: 1211.60 +/- 447.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00635  |\n",
      "|    n_updates        | 1897499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.75     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8240     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23219    |\n",
      "|    total_timesteps  | 7690764  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1897690  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.81     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8244     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23233    |\n",
      "|    total_timesteps  | 7696489  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00727  |\n",
      "|    n_updates        | 1899122  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7700000, episode_reward=1.80 +/- 4.45\n",
      "Episode length: 1120.80 +/- 426.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 1899999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8248     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23255    |\n",
      "|    total_timesteps  | 7702535  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00831  |\n",
      "|    n_updates        | 1900633  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8252     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23267    |\n",
      "|    total_timesteps  | 7707547  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00759  |\n",
      "|    n_updates        | 1901886  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7710000, episode_reward=0.80 +/- 7.47\n",
      "Episode length: 1223.00 +/- 198.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00607  |\n",
      "|    n_updates        | 1902499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8256     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23288    |\n",
      "|    total_timesteps  | 7712698  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 1903174  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.41     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8260     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23300    |\n",
      "|    total_timesteps  | 7717580  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00354  |\n",
      "|    n_updates        | 1904394  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7720000, episode_reward=5.60 +/- 7.71\n",
      "Episode length: 1199.80 +/- 166.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00564  |\n",
      "|    n_updates        | 1904999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.3      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8264     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23320    |\n",
      "|    total_timesteps  | 7722389  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 1905597  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 1.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8268     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23331    |\n",
      "|    total_timesteps  | 7727152  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1906787  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7730000, episode_reward=2.60 +/- 4.50\n",
      "Episode length: 1057.80 +/- 546.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 1907499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8272     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23353    |\n",
      "|    total_timesteps  | 7733393  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 1908348  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8276     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23365    |\n",
      "|    total_timesteps  | 7738423  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00523  |\n",
      "|    n_updates        | 1909605  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7740000, episode_reward=2.80 +/- 2.56\n",
      "Episode length: 1265.40 +/- 221.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00289  |\n",
      "|    n_updates        | 1909999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8280     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23388    |\n",
      "|    total_timesteps  | 7744022  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00439  |\n",
      "|    n_updates        | 1911005  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8284     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23399    |\n",
      "|    total_timesteps  | 7748960  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 1912239  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7750000, episode_reward=4.80 +/- 5.56\n",
      "Episode length: 1043.60 +/- 473.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 1912499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8288     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23422    |\n",
      "|    total_timesteps  | 7755468  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00377  |\n",
      "|    n_updates        | 1913866  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7760000, episode_reward=1.80 +/- 5.56\n",
      "Episode length: 1221.40 +/- 479.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 1914999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.82     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8292     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23446    |\n",
      "|    total_timesteps  | 7761478  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 1915369  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3        |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8296     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23456    |\n",
      "|    total_timesteps  | 7766085  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 1916521  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7770000, episode_reward=5.00 +/- 7.69\n",
      "Episode length: 896.20 +/- 409.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 896      |\n",
      "|    mean_reward      | 5        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0054   |\n",
      "|    n_updates        | 1917499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8300     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23478    |\n",
      "|    total_timesteps  | 7772433  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0364   |\n",
      "|    n_updates        | 1918108  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8304     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23489    |\n",
      "|    total_timesteps  | 7777086  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 1919271  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7780000, episode_reward=1.00 +/- 3.03\n",
      "Episode length: 1331.00 +/- 415.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.33e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 1919999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8308     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23511    |\n",
      "|    total_timesteps  | 7782210  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00387  |\n",
      "|    n_updates        | 1920552  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8312     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23523    |\n",
      "|    total_timesteps  | 7787506  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 1921876  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7790000, episode_reward=0.60 +/- 1.85\n",
      "Episode length: 1055.80 +/- 516.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1922499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8316     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23546    |\n",
      "|    total_timesteps  | 7793992  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 1923497  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8320     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23556    |\n",
      "|    total_timesteps  | 7798023  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 1924505  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7800000, episode_reward=1.60 +/- 2.65\n",
      "Episode length: 1170.40 +/- 433.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00542  |\n",
      "|    n_updates        | 1924999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8324     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23580    |\n",
      "|    total_timesteps  | 7804726  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00773  |\n",
      "|    n_updates        | 1926181  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8328     |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 23592    |\n",
      "|    total_timesteps  | 7809714  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 1927428  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7810000, episode_reward=3.20 +/- 6.88\n",
      "Episode length: 1214.20 +/- 209.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00513  |\n",
      "|    n_updates        | 1927499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.63     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8332     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23612    |\n",
      "|    total_timesteps  | 7814441  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00468  |\n",
      "|    n_updates        | 1928610  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.62     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8336     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23624    |\n",
      "|    total_timesteps  | 7819516  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00711  |\n",
      "|    n_updates        | 1929878  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7820000, episode_reward=7.60 +/- 7.34\n",
      "Episode length: 987.60 +/- 320.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 988      |\n",
      "|    mean_reward      | 7.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0056   |\n",
      "|    n_updates        | 1929999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8340     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23644    |\n",
      "|    total_timesteps  | 7824975  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00556  |\n",
      "|    n_updates        | 1931243  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.43     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8344     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23655    |\n",
      "|    total_timesteps  | 7829804  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 1932450  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7830000, episode_reward=6.60 +/- 4.45\n",
      "Episode length: 1158.00 +/- 127.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00702  |\n",
      "|    n_updates        | 1932499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8348     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23677    |\n",
      "|    total_timesteps  | 7835500  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00962  |\n",
      "|    n_updates        | 1933874  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7840000, episode_reward=2.40 +/- 8.52\n",
      "Episode length: 1211.00 +/- 198.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00763  |\n",
      "|    n_updates        | 1934999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8352     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23699    |\n",
      "|    total_timesteps  | 7841075  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00832  |\n",
      "|    n_updates        | 1935268  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.44     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8356     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23711    |\n",
      "|    total_timesteps  | 7846367  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 1936591  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7850000, episode_reward=3.20 +/- 0.75\n",
      "Episode length: 1321.80 +/- 338.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 1937499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8360     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23735    |\n",
      "|    total_timesteps  | 7852139  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 1938034  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8364     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23746    |\n",
      "|    total_timesteps  | 7856836  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0208   |\n",
      "|    n_updates        | 1939208  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7860000, episode_reward=2.60 +/- 5.08\n",
      "Episode length: 1230.00 +/- 131.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00996  |\n",
      "|    n_updates        | 1939999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8368     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23768    |\n",
      "|    total_timesteps  | 7862323  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00397  |\n",
      "|    n_updates        | 1940580  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8372     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23779    |\n",
      "|    total_timesteps  | 7867024  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 1941755  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7870000, episode_reward=7.20 +/- 2.93\n",
      "Episode length: 1129.00 +/- 310.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | 7.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00953  |\n",
      "|    n_updates        | 1942499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.15     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8376     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23801    |\n",
      "|    total_timesteps  | 7872757  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00268  |\n",
      "|    n_updates        | 1943189  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.11     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8380     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23813    |\n",
      "|    total_timesteps  | 7878116  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0055   |\n",
      "|    n_updates        | 1944528  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7880000, episode_reward=-2.40 +/- 5.68\n",
      "Episode length: 1152.80 +/- 175.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | -2.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 1944999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.92     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8384     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23836    |\n",
      "|    total_timesteps  | 7884135  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00795  |\n",
      "|    n_updates        | 1946033  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.02     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8388     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23848    |\n",
      "|    total_timesteps  | 7889333  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 1947333  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7890000, episode_reward=0.80 +/- 2.40\n",
      "Episode length: 1245.00 +/- 271.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 1947499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8392     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23871    |\n",
      "|    total_timesteps  | 7894993  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 1948748  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.67     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8396     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23881    |\n",
      "|    total_timesteps  | 7899330  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00669  |\n",
      "|    n_updates        | 1949832  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7900000, episode_reward=-3.20 +/- 5.78\n",
      "Episode length: 1166.00 +/- 322.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -3.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00706  |\n",
      "|    n_updates        | 1949999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8400     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23903    |\n",
      "|    total_timesteps  | 7905129  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 1951282  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8404     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23915    |\n",
      "|    total_timesteps  | 7909971  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 1952492  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7910000, episode_reward=5.20 +/- 3.87\n",
      "Episode length: 1271.20 +/- 180.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | 5.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 1952499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8408     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23936    |\n",
      "|    total_timesteps  | 7915193  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1953798  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7920000, episode_reward=7.00 +/- 4.94\n",
      "Episode length: 894.60 +/- 420.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 895      |\n",
      "|    mean_reward      | 7        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00643  |\n",
      "|    n_updates        | 1954999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8412     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23957    |\n",
      "|    total_timesteps  | 7921126  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00417  |\n",
      "|    n_updates        | 1955281  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8416     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23968    |\n",
      "|    total_timesteps  | 7925973  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0085   |\n",
      "|    n_updates        | 1956493  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7930000, episode_reward=5.00 +/- 5.22\n",
      "Episode length: 1146.40 +/- 264.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 5        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 1957499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.93     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8420     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 23989    |\n",
      "|    total_timesteps  | 7931062  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 1957765  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.05     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8424     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24000    |\n",
      "|    total_timesteps  | 7935659  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00331  |\n",
      "|    n_updates        | 1958914  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7940000, episode_reward=7.80 +/- 7.03\n",
      "Episode length: 984.00 +/- 336.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 984      |\n",
      "|    mean_reward      | 7.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00681  |\n",
      "|    n_updates        | 1959999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.97     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8428     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24020    |\n",
      "|    total_timesteps  | 7941098  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0373   |\n",
      "|    n_updates        | 1960274  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8432     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24031    |\n",
      "|    total_timesteps  | 7945848  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 1961461  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7950000, episode_reward=3.40 +/- 9.93\n",
      "Episode length: 950.80 +/- 256.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 951      |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00292  |\n",
      "|    n_updates        | 1962499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8436     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24054    |\n",
      "|    total_timesteps  | 7952594  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00324  |\n",
      "|    n_updates        | 1963148  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8440     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24066    |\n",
      "|    total_timesteps  | 7957652  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 1964412  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7960000, episode_reward=-4.00 +/- 3.74\n",
      "Episode length: 1077.20 +/- 544.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | -4       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0048   |\n",
      "|    n_updates        | 1964999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.12     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8444     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24089    |\n",
      "|    total_timesteps  | 7963823  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 1965955  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.87     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8448     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24099    |\n",
      "|    total_timesteps  | 7968217  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 1967054  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7970000, episode_reward=6.40 +/- 4.96\n",
      "Episode length: 925.00 +/- 292.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 925      |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00862  |\n",
      "|    n_updates        | 1967499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8452     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24120    |\n",
      "|    total_timesteps  | 7974268  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0079   |\n",
      "|    n_updates        | 1968566  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8456     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24130    |\n",
      "|    total_timesteps  | 7978680  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00857  |\n",
      "|    n_updates        | 1969669  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7980000, episode_reward=5.60 +/- 7.79\n",
      "Episode length: 1112.40 +/- 135.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 1969999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8460     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24150    |\n",
      "|    total_timesteps  | 7983284  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1970820  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8464     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24160    |\n",
      "|    total_timesteps  | 7987830  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 1971957  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7990000, episode_reward=10.20 +/- 2.40\n",
      "Episode length: 969.80 +/- 375.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 970      |\n",
      "|    mean_reward      | 10.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.008    |\n",
      "|    n_updates        | 1972499  |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.82     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8468     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24181    |\n",
      "|    total_timesteps  | 7993805  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 1973451  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.52     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8472     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24194    |\n",
      "|    total_timesteps  | 7999004  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00905  |\n",
      "|    n_updates        | 1974750  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8000000, episode_reward=5.80 +/- 4.35\n",
      "Episode length: 1020.40 +/- 373.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 5.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 1974999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8476     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24215    |\n",
      "|    total_timesteps  | 8004910  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 1976227  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8010000, episode_reward=0.20 +/- 2.32\n",
      "Episode length: 1100.40 +/- 437.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00961  |\n",
      "|    n_updates        | 1977499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 1.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8480     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24238    |\n",
      "|    total_timesteps  | 8011361  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 1977840  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8484     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24247    |\n",
      "|    total_timesteps  | 8015379  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 1978844  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8020000, episode_reward=3.00 +/- 4.47\n",
      "Episode length: 1327.40 +/- 94.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.33e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 1979999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.29     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8488     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24271    |\n",
      "|    total_timesteps  | 8021265  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 1980316  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8492     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24282    |\n",
      "|    total_timesteps  | 8025901  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 1981475  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8030000, episode_reward=3.60 +/- 4.76\n",
      "Episode length: 1262.20 +/- 288.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0057   |\n",
      "|    n_updates        | 1982499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8496     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24303    |\n",
      "|    total_timesteps  | 8031008  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00478  |\n",
      "|    n_updates        | 1982751  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8500     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24315    |\n",
      "|    total_timesteps  | 8035802  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 1983950  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8040000, episode_reward=3.20 +/- 4.83\n",
      "Episode length: 1180.00 +/- 156.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 1984999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.75     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8504     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24337    |\n",
      "|    total_timesteps  | 8041356  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1985338  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8508     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24349    |\n",
      "|    total_timesteps  | 8046559  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 1986639  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8050000, episode_reward=3.60 +/- 3.98\n",
      "Episode length: 1270.20 +/- 357.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 1987499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 1.89     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8512     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24372    |\n",
      "|    total_timesteps  | 8052423  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0075   |\n",
      "|    n_updates        | 1988105  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.86     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8516     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24384    |\n",
      "|    total_timesteps  | 8057617  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00933  |\n",
      "|    n_updates        | 1989404  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8060000, episode_reward=6.60 +/- 6.65\n",
      "Episode length: 1140.80 +/- 225.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0072   |\n",
      "|    n_updates        | 1989999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 1.92     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8520     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24405    |\n",
      "|    total_timesteps  | 8062875  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00837  |\n",
      "|    n_updates        | 1990718  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.1      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8524     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24416    |\n",
      "|    total_timesteps  | 8067268  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 1991816  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8070000, episode_reward=5.40 +/- 4.45\n",
      "Episode length: 1232.20 +/- 264.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | 5.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 1992499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8528     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24437    |\n",
      "|    total_timesteps  | 8072493  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0092   |\n",
      "|    n_updates        | 1993123  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8532     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24449    |\n",
      "|    total_timesteps  | 8077597  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00801  |\n",
      "|    n_updates        | 1994399  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8080000, episode_reward=2.60 +/- 7.74\n",
      "Episode length: 1087.60 +/- 427.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 1994999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.09     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8536     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24471    |\n",
      "|    total_timesteps  | 8083575  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0094   |\n",
      "|    n_updates        | 1995893  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.09     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8540     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24482    |\n",
      "|    total_timesteps  | 8088061  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00773  |\n",
      "|    n_updates        | 1997015  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=8090000, episode_reward=6.60 +/- 2.42\n",
      "Episode length: 976.00 +/- 367.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 976      |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00507  |\n",
      "|    n_updates        | 1997499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8544     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24502    |\n",
      "|    total_timesteps  | 8093894  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 1998473  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.49     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8548     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24512    |\n",
      "|    total_timesteps  | 8098059  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 1999514  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8100000, episode_reward=6.40 +/- 2.87\n",
      "Episode length: 1083.60 +/- 421.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 6.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00995  |\n",
      "|    n_updates        | 1999999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8552     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24534    |\n",
      "|    total_timesteps  | 8103810  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 2000952  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8556     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24545    |\n",
      "|    total_timesteps  | 8108488  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 2002121  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8110000, episode_reward=2.60 +/- 7.81\n",
      "Episode length: 1154.20 +/- 146.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 2002499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8560     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24566    |\n",
      "|    total_timesteps  | 8113547  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0049   |\n",
      "|    n_updates        | 2003386  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8564     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24578    |\n",
      "|    total_timesteps  | 8118652  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0038   |\n",
      "|    n_updates        | 2004662  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8120000, episode_reward=9.40 +/- 3.50\n",
      "Episode length: 1090.00 +/- 146.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 9.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 2004999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.8      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8568     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24597    |\n",
      "|    total_timesteps  | 8123572  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 2005892  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.91     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8572     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24610    |\n",
      "|    total_timesteps  | 8128867  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00482  |\n",
      "|    n_updates        | 2007216  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8130000, episode_reward=8.80 +/- 5.15\n",
      "Episode length: 1146.20 +/- 149.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 8.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 2007499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8576     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24630    |\n",
      "|    total_timesteps  | 8133835  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 2008458  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.92     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8580     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24643    |\n",
      "|    total_timesteps  | 8139253  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 2009813  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8140000, episode_reward=0.20 +/- 3.66\n",
      "Episode length: 1187.00 +/- 334.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 2009999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8584     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24664    |\n",
      "|    total_timesteps  | 8144549  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00497  |\n",
      "|    n_updates        | 2011137  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 2.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8588     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24676    |\n",
      "|    total_timesteps  | 8149707  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00571  |\n",
      "|    n_updates        | 2012426  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8150000, episode_reward=6.60 +/- 2.58\n",
      "Episode length: 1149.60 +/- 134.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 2012499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8592     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24697    |\n",
      "|    total_timesteps  | 8154851  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 2013712  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8160000, episode_reward=3.60 +/- 3.72\n",
      "Episode length: 1085.80 +/- 380.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00877  |\n",
      "|    n_updates        | 2014999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8596     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24720    |\n",
      "|    total_timesteps  | 8161311  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 2015327  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8600     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24731    |\n",
      "|    total_timesteps  | 8165768  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 2016441  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8170000, episode_reward=0.40 +/- 4.63\n",
      "Episode length: 1108.40 +/- 385.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 2017499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.8      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8604     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24752    |\n",
      "|    total_timesteps  | 8171268  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 2017816  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.93     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8608     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24763    |\n",
      "|    total_timesteps  | 8176118  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 2019029  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8180000, episode_reward=5.00 +/- 5.93\n",
      "Episode length: 1033.40 +/- 534.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 5        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 2019999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.75     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8612     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24786    |\n",
      "|    total_timesteps  | 8182462  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00512  |\n",
      "|    n_updates        | 2020615  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.95     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8616     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24799    |\n",
      "|    total_timesteps  | 8187738  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 2021934  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8190000, episode_reward=6.60 +/- 6.09\n",
      "Episode length: 1026.00 +/- 320.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00255  |\n",
      "|    n_updates        | 2022499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.12     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8620     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24821    |\n",
      "|    total_timesteps  | 8193772  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 2023442  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8624     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24833    |\n",
      "|    total_timesteps  | 8198798  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00425  |\n",
      "|    n_updates        | 2024699  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=8200000, episode_reward=2.00 +/- 6.54\n",
      "Episode length: 1040.60 +/- 363.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00633  |\n",
      "|    n_updates        | 2024999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.19     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8628     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24855    |\n",
      "|    total_timesteps  | 8204723  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.004    |\n",
      "|    n_updates        | 2026180  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.12     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8632     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24866    |\n",
      "|    total_timesteps  | 8209541  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0378   |\n",
      "|    n_updates        | 2027385  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8210000, episode_reward=1.20 +/- 5.31\n",
      "Episode length: 1184.40 +/- 343.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00311  |\n",
      "|    n_updates        | 2027499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.52     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8636     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24887    |\n",
      "|    total_timesteps  | 8214449  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00819  |\n",
      "|    n_updates        | 2028612  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8640     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24899    |\n",
      "|    total_timesteps  | 8219890  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 2029972  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8220000, episode_reward=1.60 +/- 5.54\n",
      "Episode length: 1282.40 +/- 197.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 2029999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8644     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24922    |\n",
      "|    total_timesteps  | 8225238  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 2031309  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.75     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8648     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24932    |\n",
      "|    total_timesteps  | 8229583  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 2032395  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8230000, episode_reward=4.20 +/- 8.95\n",
      "Episode length: 1074.00 +/- 86.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 2032499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.81     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8652     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24952    |\n",
      "|    total_timesteps  | 8234714  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 2033678  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8240000, episode_reward=0.80 +/- 8.54\n",
      "Episode length: 1031.60 +/- 291.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00538  |\n",
      "|    n_updates        | 2034999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.93     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8656     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 24975    |\n",
      "|    total_timesteps  | 8241252  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 2035312  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.6      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8660     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 24987    |\n",
      "|    total_timesteps  | 8246311  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0321   |\n",
      "|    n_updates        | 2036577  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8250000, episode_reward=4.60 +/- 4.32\n",
      "Episode length: 992.00 +/- 448.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 992      |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00385  |\n",
      "|    n_updates        | 2037499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.65     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8664     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25008    |\n",
      "|    total_timesteps  | 8252092  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00942  |\n",
      "|    n_updates        | 2038022  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8668     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 25019    |\n",
      "|    total_timesteps  | 8256351  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00947  |\n",
      "|    n_updates        | 2039087  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8260000, episode_reward=4.80 +/- 3.06\n",
      "Episode length: 1316.40 +/- 174.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00764  |\n",
      "|    n_updates        | 2039999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.04     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8672     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25039    |\n",
      "|    total_timesteps  | 8260853  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 2040213  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.98     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8676     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25050    |\n",
      "|    total_timesteps  | 8265781  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 2041445  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8270000, episode_reward=6.60 +/- 3.93\n",
      "Episode length: 1039.20 +/- 228.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00949  |\n",
      "|    n_updates        | 2042499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.02     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8680     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25070    |\n",
      "|    total_timesteps  | 8271052  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 2042762  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8684     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25082    |\n",
      "|    total_timesteps  | 8276004  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00821  |\n",
      "|    n_updates        | 2044000  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8280000, episode_reward=-4.40 +/- 3.72\n",
      "Episode length: 1229.80 +/- 193.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -4.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00729  |\n",
      "|    n_updates        | 2044999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8688     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25103    |\n",
      "|    total_timesteps  | 8281159  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 2045289  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.01     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8692     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25115    |\n",
      "|    total_timesteps  | 8286333  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 2046583  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8290000, episode_reward=2.40 +/- 3.61\n",
      "Episode length: 1003.80 +/- 452.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 2047499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8696     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25137    |\n",
      "|    total_timesteps  | 8292450  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 2048112  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.87     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8700     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25148    |\n",
      "|    total_timesteps  | 8297300  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00614  |\n",
      "|    n_updates        | 2049324  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8300000, episode_reward=2.00 +/- 5.48\n",
      "Episode length: 1356.20 +/- 96.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.36e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00413  |\n",
      "|    n_updates        | 2049999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8704     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25171    |\n",
      "|    total_timesteps  | 8302555  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00285  |\n",
      "|    n_updates        | 2050638  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.86     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8708     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25181    |\n",
      "|    total_timesteps  | 8306984  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00404  |\n",
      "|    n_updates        | 2051745  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=8310000, episode_reward=2.00 +/- 7.24\n",
      "Episode length: 1054.00 +/- 398.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0281   |\n",
      "|    n_updates        | 2052499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8712     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25201    |\n",
      "|    total_timesteps  | 8312483  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 2053120  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8716     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25213    |\n",
      "|    total_timesteps  | 8317346  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00856  |\n",
      "|    n_updates        | 2054336  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8320000, episode_reward=12.20 +/- 2.04\n",
      "Episode length: 1015.80 +/- 56.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 12.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 2054999  |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8720     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25232    |\n",
      "|    total_timesteps  | 8322271  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00516  |\n",
      "|    n_updates        | 2055567  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8724     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25244    |\n",
      "|    total_timesteps  | 8327412  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00519  |\n",
      "|    n_updates        | 2056852  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8330000, episode_reward=4.00 +/- 4.90\n",
      "Episode length: 1222.60 +/- 114.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00881  |\n",
      "|    n_updates        | 2057499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8728     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25265    |\n",
      "|    total_timesteps  | 8332907  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 2058226  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8732     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25278    |\n",
      "|    total_timesteps  | 8338419  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00703  |\n",
      "|    n_updates        | 2059604  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8340000, episode_reward=6.20 +/- 6.94\n",
      "Episode length: 1023.80 +/- 258.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 6.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00386  |\n",
      "|    n_updates        | 2059999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8736     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25298    |\n",
      "|    total_timesteps  | 8343638  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00499  |\n",
      "|    n_updates        | 2060909  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8740     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25310    |\n",
      "|    total_timesteps  | 8348782  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 2062195  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8350000, episode_reward=6.60 +/- 6.09\n",
      "Episode length: 1177.40 +/- 205.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 2062499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8744     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25331    |\n",
      "|    total_timesteps  | 8354146  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00571  |\n",
      "|    n_updates        | 2063536  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8748     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25343    |\n",
      "|    total_timesteps  | 8359073  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 2064768  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8360000, episode_reward=4.60 +/- 4.27\n",
      "Episode length: 1066.00 +/- 311.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0059   |\n",
      "|    n_updates        | 2064999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8752     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25365    |\n",
      "|    total_timesteps  | 8365236  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00545  |\n",
      "|    n_updates        | 2066308  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8370000, episode_reward=6.80 +/- 2.40\n",
      "Episode length: 1116.00 +/- 222.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 6.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 2067499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8756     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25387    |\n",
      "|    total_timesteps  | 8371174  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 2067793  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.82     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8760     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25399    |\n",
      "|    total_timesteps  | 8376056  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 2069013  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8380000, episode_reward=4.80 +/- 5.88\n",
      "Episode length: 1031.60 +/- 509.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 2069999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8764     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25419    |\n",
      "|    total_timesteps  | 8381353  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00924  |\n",
      "|    n_updates        | 2070338  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.46     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8768     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25432    |\n",
      "|    total_timesteps  | 8386755  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 2071688  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8390000, episode_reward=2.60 +/- 4.76\n",
      "Episode length: 933.00 +/- 472.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 933      |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0375   |\n",
      "|    n_updates        | 2072499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.36     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8772     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25452    |\n",
      "|    total_timesteps  | 8392233  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00496  |\n",
      "|    n_updates        | 2073058  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.52     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8776     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25464    |\n",
      "|    total_timesteps  | 8397396  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00746  |\n",
      "|    n_updates        | 2074348  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8400000, episode_reward=3.40 +/- 4.03\n",
      "Episode length: 1289.00 +/- 235.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.29e+03 |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0081   |\n",
      "|    n_updates        | 2074999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.7      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8780     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25486    |\n",
      "|    total_timesteps  | 8402673  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 2075668  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.63     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8784     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25495    |\n",
      "|    total_timesteps  | 8406833  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00617  |\n",
      "|    n_updates        | 2076708  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8410000, episode_reward=6.60 +/- 4.80\n",
      "Episode length: 999.60 +/- 303.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 2077499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.7      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8788     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25516    |\n",
      "|    total_timesteps  | 8412381  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00453  |\n",
      "|    n_updates        | 2078095  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.7      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8792     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25528    |\n",
      "|    total_timesteps  | 8417353  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00683  |\n",
      "|    n_updates        | 2079338  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=8420000, episode_reward=1.20 +/- 4.75\n",
      "Episode length: 1013.20 +/- 516.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00567  |\n",
      "|    n_updates        | 2079999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.89     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8796     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25550    |\n",
      "|    total_timesteps  | 8423637  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00741  |\n",
      "|    n_updates        | 2080909  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.93     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8800     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25563    |\n",
      "|    total_timesteps  | 8428959  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00696  |\n",
      "|    n_updates        | 2082239  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8430000, episode_reward=4.40 +/- 6.12\n",
      "Episode length: 1262.60 +/- 133.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 2082499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8804     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25583    |\n",
      "|    total_timesteps  | 8433699  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 2083424  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8808     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25594    |\n",
      "|    total_timesteps  | 8438309  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 2084577  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8440000, episode_reward=-0.60 +/- 7.94\n",
      "Episode length: 1085.80 +/- 203.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | -0.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00891  |\n",
      "|    n_updates        | 2084999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8812     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25615    |\n",
      "|    total_timesteps  | 8443684  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 2085920  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.81     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8816     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25626    |\n",
      "|    total_timesteps  | 8448312  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0238   |\n",
      "|    n_updates        | 2087077  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8450000, episode_reward=2.40 +/- 7.81\n",
      "Episode length: 1183.40 +/- 323.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00853  |\n",
      "|    n_updates        | 2087499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8820     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25648    |\n",
      "|    total_timesteps  | 8454094  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00495  |\n",
      "|    n_updates        | 2088523  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8824     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25659    |\n",
      "|    total_timesteps  | 8458701  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0569   |\n",
      "|    n_updates        | 2089675  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8460000, episode_reward=4.80 +/- 4.17\n",
      "Episode length: 1378.60 +/- 186.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.38e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00848  |\n",
      "|    n_updates        | 2089999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8828     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25681    |\n",
      "|    total_timesteps  | 8463704  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 2090925  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8832     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25692    |\n",
      "|    total_timesteps  | 8468478  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00845  |\n",
      "|    n_updates        | 2092119  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8470000, episode_reward=2.40 +/- 7.36\n",
      "Episode length: 1140.00 +/- 205.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.005    |\n",
      "|    n_updates        | 2092499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.25     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8836     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25714    |\n",
      "|    total_timesteps  | 8474069  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 2093517  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8840     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25725    |\n",
      "|    total_timesteps  | 8478770  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00444  |\n",
      "|    n_updates        | 2094692  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8480000, episode_reward=3.80 +/- 3.71\n",
      "Episode length: 1298.80 +/- 121.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.3e+03  |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0079   |\n",
      "|    n_updates        | 2094999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8844     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25748    |\n",
      "|    total_timesteps  | 8484674  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00718  |\n",
      "|    n_updates        | 2096168  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8490000, episode_reward=1.00 +/- 6.23\n",
      "Episode length: 967.60 +/- 428.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 968      |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 2097499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8848     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25771    |\n",
      "|    total_timesteps  | 8491348  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00601  |\n",
      "|    n_updates        | 2097836  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8852     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25783    |\n",
      "|    total_timesteps  | 8496492  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 2099122  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8500000, episode_reward=-2.00 +/- 8.56\n",
      "Episode length: 1056.80 +/- 378.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 2099999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8856     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25805    |\n",
      "|    total_timesteps  | 8502430  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 2100607  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.04     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8860     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25816    |\n",
      "|    total_timesteps  | 8507096  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 2101773  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8510000, episode_reward=5.00 +/- 2.37\n",
      "Episode length: 1088.80 +/- 461.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 5        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 2102499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8864     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25837    |\n",
      "|    total_timesteps  | 8512659  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 2103164  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8868     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25848    |\n",
      "|    total_timesteps  | 8517512  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 2104377  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8520000, episode_reward=2.60 +/- 4.54\n",
      "Episode length: 1305.40 +/- 92.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00811  |\n",
      "|    n_updates        | 2104999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.96     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8872     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25869    |\n",
      "|    total_timesteps  | 8522490  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00756  |\n",
      "|    n_updates        | 2105622  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.02     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8876     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25879    |\n",
      "|    total_timesteps  | 8526874  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00753  |\n",
      "|    n_updates        | 2106718  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=8530000, episode_reward=3.00 +/- 8.56\n",
      "Episode length: 1085.60 +/- 169.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00614  |\n",
      "|    n_updates        | 2107499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.8      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8880     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25901    |\n",
      "|    total_timesteps  | 8532561  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00441  |\n",
      "|    n_updates        | 2108140  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8884     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25911    |\n",
      "|    total_timesteps  | 8536838  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 2109209  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8540000, episode_reward=-1.40 +/- 4.59\n",
      "Episode length: 984.00 +/- 432.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 984      |\n",
      "|    mean_reward      | -1.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 2109999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8888     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25932    |\n",
      "|    total_timesteps  | 8542561  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 2110640  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8892     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25943    |\n",
      "|    total_timesteps  | 8547294  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00683  |\n",
      "|    n_updates        | 2111823  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8550000, episode_reward=3.60 +/- 4.54\n",
      "Episode length: 1041.60 +/- 414.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00664  |\n",
      "|    n_updates        | 2112499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8896     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25966    |\n",
      "|    total_timesteps  | 8553790  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 2113447  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.31     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8900     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 25979    |\n",
      "|    total_timesteps  | 8559161  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00664  |\n",
      "|    n_updates        | 2114790  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8560000, episode_reward=-2.20 +/- 5.60\n",
      "Episode length: 1094.60 +/- 358.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0061   |\n",
      "|    n_updates        | 2114999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8904     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26001    |\n",
      "|    total_timesteps  | 8565320  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00228  |\n",
      "|    n_updates        | 2116329  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8570000, episode_reward=-2.60 +/- 10.17\n",
      "Episode length: 1073.40 +/- 359.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -2.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00423  |\n",
      "|    n_updates        | 2117499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.41     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8908     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26023    |\n",
      "|    total_timesteps  | 8571000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 2117749  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8912     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26034    |\n",
      "|    total_timesteps  | 8575918  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00411  |\n",
      "|    n_updates        | 2118979  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8580000, episode_reward=6.20 +/- 5.98\n",
      "Episode length: 1133.40 +/- 165.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | 6.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.046    |\n",
      "|    n_updates        | 2119999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.03     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8916     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26056    |\n",
      "|    total_timesteps  | 8581426  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 2120356  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8920     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26069    |\n",
      "|    total_timesteps  | 8586751  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 2121687  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8590000, episode_reward=3.80 +/- 5.91\n",
      "Episode length: 1143.60 +/- 262.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 2122499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.17     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8924     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26092    |\n",
      "|    total_timesteps  | 8592861  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00509  |\n",
      "|    n_updates        | 2123215  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8928     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26104    |\n",
      "|    total_timesteps  | 8597619  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00244  |\n",
      "|    n_updates        | 2124404  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8600000, episode_reward=8.60 +/- 5.31\n",
      "Episode length: 930.80 +/- 435.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 931      |\n",
      "|    mean_reward      | 8.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 2124999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.35     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8932     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26125    |\n",
      "|    total_timesteps  | 8603667  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 2125916  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8936     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26136    |\n",
      "|    total_timesteps  | 8608336  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0208   |\n",
      "|    n_updates        | 2127083  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8610000, episode_reward=2.80 +/- 5.11\n",
      "Episode length: 1227.80 +/- 146.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 2127499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 2.09     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8940     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26158    |\n",
      "|    total_timesteps  | 8613664  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 2128415  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 2.01     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8944     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26170    |\n",
      "|    total_timesteps  | 8618708  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 2129676  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8620000, episode_reward=7.20 +/- 5.15\n",
      "Episode length: 1242.00 +/- 190.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 7.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00239  |\n",
      "|    n_updates        | 2129999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.1      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8948     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26191    |\n",
      "|    total_timesteps  | 8623831  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 2130957  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8952     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26202    |\n",
      "|    total_timesteps  | 8628424  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 2132105  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8630000, episode_reward=3.80 +/- 4.45\n",
      "Episode length: 1294.80 +/- 257.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.29e+03 |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00957  |\n",
      "|    n_updates        | 2132499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8956     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26225    |\n",
      "|    total_timesteps  | 8634126  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00807  |\n",
      "|    n_updates        | 2133531  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8960     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26237    |\n",
      "|    total_timesteps  | 8639375  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00795  |\n",
      "|    n_updates        | 2134843  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=8640000, episode_reward=4.00 +/- 7.40\n",
      "Episode length: 1109.00 +/- 246.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 2134999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.16     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8964     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26259    |\n",
      "|    total_timesteps  | 8645079  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 2136269  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8650000, episode_reward=2.40 +/- 4.41\n",
      "Episode length: 1053.40 +/- 488.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 2137499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8968     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26280    |\n",
      "|    total_timesteps  | 8650980  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 2137744  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 2.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8972     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26292    |\n",
      "|    total_timesteps  | 8655723  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 2138930  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8660000, episode_reward=-2.20 +/- 5.15\n",
      "Episode length: 983.00 +/- 499.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 983      |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 2139999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 2.6      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8976     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26315    |\n",
      "|    total_timesteps  | 8662563  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 2140640  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 2.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8980     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26328    |\n",
      "|    total_timesteps  | 8668353  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00866  |\n",
      "|    n_updates        | 2142088  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8670000, episode_reward=-3.40 +/- 2.06\n",
      "Episode length: 1308.80 +/- 160.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | -3.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00437  |\n",
      "|    n_updates        | 2142499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 3.05     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8984     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26351    |\n",
      "|    total_timesteps  | 8673892  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 2143472  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 3.16     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8988     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26362    |\n",
      "|    total_timesteps  | 8678588  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0095   |\n",
      "|    n_updates        | 2144646  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8680000, episode_reward=1.40 +/- 3.83\n",
      "Episode length: 1472.60 +/- 158.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.47e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00798  |\n",
      "|    n_updates        | 2144999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 2.99     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8992     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26385    |\n",
      "|    total_timesteps  | 8683324  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00963  |\n",
      "|    n_updates        | 2145830  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.12     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8996     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26396    |\n",
      "|    total_timesteps  | 8688180  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0082   |\n",
      "|    n_updates        | 2147044  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8690000, episode_reward=10.80 +/- 4.02\n",
      "Episode length: 1006.00 +/- 214.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 10.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 2147499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9000     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26417    |\n",
      "|    total_timesteps  | 8693859  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00637  |\n",
      "|    n_updates        | 2148464  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.6      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9004     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26428    |\n",
      "|    total_timesteps  | 8698611  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00547  |\n",
      "|    n_updates        | 2149652  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8700000, episode_reward=4.00 +/- 4.86\n",
      "Episode length: 1218.20 +/- 144.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00507  |\n",
      "|    n_updates        | 2149999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.51     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9008     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26450    |\n",
      "|    total_timesteps  | 8704042  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00832  |\n",
      "|    n_updates        | 2151010  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9012     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26461    |\n",
      "|    total_timesteps  | 8708832  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00846  |\n",
      "|    n_updates        | 2152207  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8710000, episode_reward=1.20 +/- 8.03\n",
      "Episode length: 1026.80 +/- 444.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 2152499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9016     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26483    |\n",
      "|    total_timesteps  | 8715001  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00932  |\n",
      "|    n_updates        | 2153750  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.43     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9020     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26495    |\n",
      "|    total_timesteps  | 8719936  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 2154983  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8720000, episode_reward=1.80 +/- 6.73\n",
      "Episode length: 1217.60 +/- 153.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0307   |\n",
      "|    n_updates        | 2154999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9024     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26515    |\n",
      "|    total_timesteps  | 8724738  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00649  |\n",
      "|    n_updates        | 2156184  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9028     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26527    |\n",
      "|    total_timesteps  | 8729903  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 2157475  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8730000, episode_reward=7.80 +/- 6.05\n",
      "Episode length: 1180.60 +/- 154.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 7.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 2157499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.43     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9032     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26549    |\n",
      "|    total_timesteps  | 8735250  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00924  |\n",
      "|    n_updates        | 2158812  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9036     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 26559    |\n",
      "|    total_timesteps  | 8739649  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00726  |\n",
      "|    n_updates        | 2159912  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8740000, episode_reward=2.00 +/- 6.60\n",
      "Episode length: 1212.60 +/- 178.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 2159999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9040     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26581    |\n",
      "|    total_timesteps  | 8745194  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00859  |\n",
      "|    n_updates        | 2161298  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8750000, episode_reward=4.00 +/- 8.49\n",
      "Episode length: 1079.60 +/- 233.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0429   |\n",
      "|    n_updates        | 2162499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9044     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26603    |\n",
      "|    total_timesteps  | 8751063  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 2162765  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.04     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9048     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26614    |\n",
      "|    total_timesteps  | 8755921  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 2163980  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8760000, episode_reward=1.60 +/- 7.94\n",
      "Episode length: 1180.40 +/- 299.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 2164999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.82     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9052     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26636    |\n",
      "|    total_timesteps  | 8761229  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 2165307  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9056     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26648    |\n",
      "|    total_timesteps  | 8766460  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 2166614  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8770000, episode_reward=3.80 +/- 3.82\n",
      "Episode length: 1096.40 +/- 447.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 2167499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9060     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26670    |\n",
      "|    total_timesteps  | 8772531  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 2168132  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.84     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9064     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26682    |\n",
      "|    total_timesteps  | 8777510  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 2169377  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8780000, episode_reward=6.20 +/- 6.05\n",
      "Episode length: 1079.20 +/- 426.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 6.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 2169999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9068     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26704    |\n",
      "|    total_timesteps  | 8783756  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00421  |\n",
      "|    n_updates        | 2170938  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.48     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9072     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26719    |\n",
      "|    total_timesteps  | 8789817  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 2172454  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8790000, episode_reward=6.20 +/- 5.27\n",
      "Episode length: 1240.20 +/- 174.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 6.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 2172499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.42     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9076     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26741    |\n",
      "|    total_timesteps  | 8795387  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 2173846  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8800000, episode_reward=3.60 +/- 5.85\n",
      "Episode length: 1033.20 +/- 400.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 2174999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.67     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9080     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26762    |\n",
      "|    total_timesteps  | 8801211  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 2175302  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.43     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9084     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26775    |\n",
      "|    total_timesteps  | 8806594  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0264   |\n",
      "|    n_updates        | 2176648  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=8810000, episode_reward=7.20 +/- 5.00\n",
      "Episode length: 1007.40 +/- 336.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 7.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 2177499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9088     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26796    |\n",
      "|    total_timesteps  | 8812425  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0345   |\n",
      "|    n_updates        | 2178106  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9092     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26807    |\n",
      "|    total_timesteps  | 8817294  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 2179323  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8820000, episode_reward=3.20 +/- 4.35\n",
      "Episode length: 975.60 +/- 483.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 976      |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 2179999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 3.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9096     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26830    |\n",
      "|    total_timesteps  | 8824091  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00761  |\n",
      "|    n_updates        | 2181022  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9100     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26840    |\n",
      "|    total_timesteps  | 8828354  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00699  |\n",
      "|    n_updates        | 2182088  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8830000, episode_reward=1.00 +/- 4.77\n",
      "Episode length: 1164.20 +/- 132.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 2182499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9104     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26862    |\n",
      "|    total_timesteps  | 8833786  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 2183446  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9108     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26874    |\n",
      "|    total_timesteps  | 8838740  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 2184684  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8840000, episode_reward=2.60 +/- 5.28\n",
      "Episode length: 1071.60 +/- 468.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 2184999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 3.43     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9112     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26895    |\n",
      "|    total_timesteps  | 8844453  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00749  |\n",
      "|    n_updates        | 2186113  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9116     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26907    |\n",
      "|    total_timesteps  | 8849692  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00802  |\n",
      "|    n_updates        | 2187422  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8850000, episode_reward=4.00 +/- 4.60\n",
      "Episode length: 1280.80 +/- 149.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00704  |\n",
      "|    n_updates        | 2187499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.7      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9120     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26929    |\n",
      "|    total_timesteps  | 8854827  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 2188706  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9124     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26940    |\n",
      "|    total_timesteps  | 8859580  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00544  |\n",
      "|    n_updates        | 2189894  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8860000, episode_reward=3.60 +/- 3.38\n",
      "Episode length: 1162.40 +/- 186.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 2189999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9128     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26962    |\n",
      "|    total_timesteps  | 8865102  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00644  |\n",
      "|    n_updates        | 2191275  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.25     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9132     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26972    |\n",
      "|    total_timesteps  | 8869396  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 2192348  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8870000, episode_reward=6.00 +/- 4.98\n",
      "Episode length: 1047.40 +/- 365.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | 6        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 2192499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 4.27     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9136     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 26993    |\n",
      "|    total_timesteps  | 8874917  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00989  |\n",
      "|    n_updates        | 2193729  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.4      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9140     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27004    |\n",
      "|    total_timesteps  | 8879681  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00857  |\n",
      "|    n_updates        | 2194920  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8880000, episode_reward=2.60 +/- 5.57\n",
      "Episode length: 1230.00 +/- 321.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 2194999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9144     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27025    |\n",
      "|    total_timesteps  | 8884819  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 2196204  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8890000, episode_reward=1.20 +/- 6.14\n",
      "Episode length: 1079.40 +/- 503.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00099  |\n",
      "|    n_updates        | 2197499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 4.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9148     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27049    |\n",
      "|    total_timesteps  | 8891423  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00957  |\n",
      "|    n_updates        | 2197855  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 4.8      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9152     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27059    |\n",
      "|    total_timesteps  | 8895749  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 2198937  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8900000, episode_reward=0.80 +/- 6.31\n",
      "Episode length: 1131.40 +/- 330.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0373   |\n",
      "|    n_updates        | 2199999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 4.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9156     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27080    |\n",
      "|    total_timesteps  | 8901228  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 2200306  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9160     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27091    |\n",
      "|    total_timesteps  | 8905862  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00372  |\n",
      "|    n_updates        | 2201465  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8910000, episode_reward=7.60 +/- 6.25\n",
      "Episode length: 1147.40 +/- 332.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 7.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 2202499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.57     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9164     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27113    |\n",
      "|    total_timesteps  | 8911265  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00512  |\n",
      "|    n_updates        | 2202816  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.46     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9168     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27124    |\n",
      "|    total_timesteps  | 8916029  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 2204007  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=8920000, episode_reward=2.20 +/- 4.31\n",
      "Episode length: 1363.20 +/- 97.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.36e+03 |\n",
      "|    mean_reward      | 2.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00992  |\n",
      "|    n_updates        | 2204999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.43     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9172     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27147    |\n",
      "|    total_timesteps  | 8921630  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 2205407  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9176     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27158    |\n",
      "|    total_timesteps  | 8926466  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00809  |\n",
      "|    n_updates        | 2206616  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8930000, episode_reward=2.80 +/- 5.64\n",
      "Episode length: 1084.60 +/- 558.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 2207499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.29     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9180     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27181    |\n",
      "|    total_timesteps  | 8932584  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 2208145  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9184     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27191    |\n",
      "|    total_timesteps  | 8937098  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0389   |\n",
      "|    n_updates        | 2209274  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8940000, episode_reward=4.80 +/- 1.94\n",
      "Episode length: 1173.80 +/- 379.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 2209999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 4.69     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9188     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27213    |\n",
      "|    total_timesteps  | 8942819  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 2210704  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.42     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9192     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27225    |\n",
      "|    total_timesteps  | 8947987  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 2211996  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8950000, episode_reward=6.20 +/- 3.76\n",
      "Episode length: 1050.60 +/- 281.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | 6.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00979  |\n",
      "|    n_updates        | 2212499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 4.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9196     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27246    |\n",
      "|    total_timesteps  | 8953247  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00872  |\n",
      "|    n_updates        | 2213311  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.05     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9200     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27259    |\n",
      "|    total_timesteps  | 8958921  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 2214730  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8960000, episode_reward=5.40 +/- 1.85\n",
      "Episode length: 1170.20 +/- 408.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 5.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 2214999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9204     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27282    |\n",
      "|    total_timesteps  | 8965103  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 2216275  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9208     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27294    |\n",
      "|    total_timesteps  | 8969916  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00525  |\n",
      "|    n_updates        | 2217478  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8970000, episode_reward=4.80 +/- 6.37\n",
      "Episode length: 1275.00 +/- 232.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 4.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00427  |\n",
      "|    n_updates        | 2217499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9212     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27316    |\n",
      "|    total_timesteps  | 8975486  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 2218871  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8980000, episode_reward=3.60 +/- 3.83\n",
      "Episode length: 1157.00 +/- 330.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 2219999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9216     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27338    |\n",
      "|    total_timesteps  | 8981226  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 2220306  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9220     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27351    |\n",
      "|    total_timesteps  | 8986681  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 2221670  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8990000, episode_reward=2.00 +/- 3.58\n",
      "Episode length: 1162.00 +/- 513.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00441  |\n",
      "|    n_updates        | 2222499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.17     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9224     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27374    |\n",
      "|    total_timesteps  | 8992581  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 2223145  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.16     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9228     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27385    |\n",
      "|    total_timesteps  | 8997558  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00386  |\n",
      "|    n_updates        | 2224389  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9000000, episode_reward=2.80 +/- 1.33\n",
      "Episode length: 1151.20 +/- 425.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00687  |\n",
      "|    n_updates        | 2224999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.94     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9232     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27408    |\n",
      "|    total_timesteps  | 9003594  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00739  |\n",
      "|    n_updates        | 2225898  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9236     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27419    |\n",
      "|    total_timesteps  | 9008369  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 2227092  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9010000, episode_reward=6.80 +/- 3.19\n",
      "Episode length: 1227.40 +/- 431.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | 6.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 2227499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9240     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27440    |\n",
      "|    total_timesteps  | 9013748  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 2228436  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9244     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27452    |\n",
      "|    total_timesteps  | 9018674  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00348  |\n",
      "|    n_updates        | 2229668  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9020000, episode_reward=5.80 +/- 7.57\n",
      "Episode length: 1186.60 +/- 195.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 5.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00849  |\n",
      "|    n_updates        | 2229999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.65     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9248     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27473    |\n",
      "|    total_timesteps  | 9023997  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 2230999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9252     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27484    |\n",
      "|    total_timesteps  | 9028777  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0043   |\n",
      "|    n_updates        | 2232194  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=9030000, episode_reward=7.80 +/- 3.43\n",
      "Episode length: 1027.00 +/- 454.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 7.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0063   |\n",
      "|    n_updates        | 2232499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9256     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27506    |\n",
      "|    total_timesteps  | 9034703  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 2233675  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4        |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9260     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27516    |\n",
      "|    total_timesteps  | 9039373  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00826  |\n",
      "|    n_updates        | 2234843  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9040000, episode_reward=6.00 +/- 4.73\n",
      "Episode length: 1172.40 +/- 319.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 6        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00662  |\n",
      "|    n_updates        | 2234999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.11     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9264     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27538    |\n",
      "|    total_timesteps  | 9044972  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 2236242  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9268     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27549    |\n",
      "|    total_timesteps  | 9049567  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00557  |\n",
      "|    n_updates        | 2237391  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9050000, episode_reward=2.60 +/- 7.63\n",
      "Episode length: 1196.80 +/- 298.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 2237499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.46     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9272     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27571    |\n",
      "|    total_timesteps  | 9055108  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.005    |\n",
      "|    n_updates        | 2238776  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.15     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9276     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27581    |\n",
      "|    total_timesteps  | 9059399  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 2239849  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9060000, episode_reward=1.00 +/- 5.29\n",
      "Episode length: 1324.40 +/- 258.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 2239999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.31     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9280     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27604    |\n",
      "|    total_timesteps  | 9065118  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 2241279  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9070000, episode_reward=3.00 +/- 8.00\n",
      "Episode length: 960.20 +/- 480.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 960      |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 2242499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9284     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27625    |\n",
      "|    total_timesteps  | 9071006  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00971  |\n",
      "|    n_updates        | 2242751  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9288     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27637    |\n",
      "|    total_timesteps  | 9076174  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00456  |\n",
      "|    n_updates        | 2244043  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9080000, episode_reward=7.20 +/- 4.31\n",
      "Episode length: 1215.00 +/- 354.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 7.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00744  |\n",
      "|    n_updates        | 2244999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9292     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27657    |\n",
      "|    total_timesteps  | 9080919  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 2245229  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9296     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27670    |\n",
      "|    total_timesteps  | 9086383  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 2246595  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9090000, episode_reward=-0.40 +/- 6.53\n",
      "Episode length: 1088.40 +/- 509.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | -0.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00565  |\n",
      "|    n_updates        | 2247499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9300     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27693    |\n",
      "|    total_timesteps  | 9092767  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00439  |\n",
      "|    n_updates        | 2248191  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9304     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27704    |\n",
      "|    total_timesteps  | 9097874  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0262   |\n",
      "|    n_updates        | 2249468  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9100000, episode_reward=1.20 +/- 7.68\n",
      "Episode length: 1110.00 +/- 373.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 2249999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9308     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27727    |\n",
      "|    total_timesteps  | 9103930  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 2250982  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9312     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27739    |\n",
      "|    total_timesteps  | 9109323  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 2252330  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9110000, episode_reward=2.00 +/- 5.18\n",
      "Episode length: 1020.00 +/- 396.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 2252499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9316     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27760    |\n",
      "|    total_timesteps  | 9114671  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00645  |\n",
      "|    n_updates        | 2253667  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9320     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27771    |\n",
      "|    total_timesteps  | 9119440  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00768  |\n",
      "|    n_updates        | 2254859  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9120000, episode_reward=0.60 +/- 2.87\n",
      "Episode length: 1197.40 +/- 363.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 0.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00464  |\n",
      "|    n_updates        | 2254999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9324     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27794    |\n",
      "|    total_timesteps  | 9125341  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 2256335  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9130000, episode_reward=3.40 +/- 5.75\n",
      "Episode length: 1202.20 +/- 658.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 2257499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.81     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9328     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27816    |\n",
      "|    total_timesteps  | 9131002  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0468   |\n",
      "|    n_updates        | 2257750  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9332     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27828    |\n",
      "|    total_timesteps  | 9136191  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0327   |\n",
      "|    n_updates        | 2259047  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9140000, episode_reward=4.20 +/- 6.31\n",
      "Episode length: 1030.60 +/- 357.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00777  |\n",
      "|    n_updates        | 2259999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.74     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9336     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27850    |\n",
      "|    total_timesteps  | 9142409  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0043   |\n",
      "|    n_updates        | 2260602  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9340     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27862    |\n",
      "|    total_timesteps  | 9147398  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 2261849  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9150000, episode_reward=6.60 +/- 6.47\n",
      "Episode length: 1048.00 +/- 233.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00724  |\n",
      "|    n_updates        | 2262499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9344     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27881    |\n",
      "|    total_timesteps  | 9152227  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 2263056  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9348     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27895    |\n",
      "|    total_timesteps  | 9157963  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0315   |\n",
      "|    n_updates        | 2264490  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9160000, episode_reward=2.80 +/- 6.46\n",
      "Episode length: 1083.00 +/- 369.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00981  |\n",
      "|    n_updates        | 2264999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 4.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9352     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27916    |\n",
      "|    total_timesteps  | 9163708  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0062   |\n",
      "|    n_updates        | 2265926  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9356     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27927    |\n",
      "|    total_timesteps  | 9168482  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 2267120  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9170000, episode_reward=6.20 +/- 2.86\n",
      "Episode length: 1264.20 +/- 257.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 6.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00685  |\n",
      "|    n_updates        | 2267499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 4.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9360     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27949    |\n",
      "|    total_timesteps  | 9174051  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00659  |\n",
      "|    n_updates        | 2268512  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.11     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9364     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27959    |\n",
      "|    total_timesteps  | 9178230  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0073   |\n",
      "|    n_updates        | 2269557  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9180000, episode_reward=3.20 +/- 2.14\n",
      "Episode length: 1098.60 +/- 415.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0242   |\n",
      "|    n_updates        | 2269999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.28     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9368     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27978    |\n",
      "|    total_timesteps  | 9183005  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 2270751  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.16     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9372     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 27991    |\n",
      "|    total_timesteps  | 9188292  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00756  |\n",
      "|    n_updates        | 2272072  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9190000, episode_reward=5.60 +/- 3.88\n",
      "Episode length: 1202.20 +/- 219.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00935  |\n",
      "|    n_updates        | 2272499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 4.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9376     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28013    |\n",
      "|    total_timesteps  | 9193927  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 2273481  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9380     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28025    |\n",
      "|    total_timesteps  | 9198907  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 2274726  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9200000, episode_reward=5.60 +/- 5.68\n",
      "Episode length: 1095.40 +/- 225.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 2274999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.3      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9384     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28046    |\n",
      "|    total_timesteps  | 9204420  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0079   |\n",
      "|    n_updates        | 2276104  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.05     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9388     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28058    |\n",
      "|    total_timesteps  | 9209670  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 2277417  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9210000, episode_reward=7.20 +/- 3.54\n",
      "Episode length: 1238.80 +/- 283.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 7.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00544  |\n",
      "|    n_updates        | 2277499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.67     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9392     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28080    |\n",
      "|    total_timesteps  | 9215283  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00711  |\n",
      "|    n_updates        | 2278820  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9220000, episode_reward=4.20 +/- 6.18\n",
      "Episode length: 1011.80 +/- 522.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 2279999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.94     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9396     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28102    |\n",
      "|    total_timesteps  | 9221148  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 2280286  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.03     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9400     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28113    |\n",
      "|    total_timesteps  | 9226084  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00768  |\n",
      "|    n_updates        | 2281520  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9230000, episode_reward=-1.80 +/- 4.45\n",
      "Episode length: 1263.80 +/- 87.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | -1.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00678  |\n",
      "|    n_updates        | 2282499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.95     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9404     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28136    |\n",
      "|    total_timesteps  | 9231610  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 2282902  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9408     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28147    |\n",
      "|    total_timesteps  | 9236460  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00783  |\n",
      "|    n_updates        | 2284114  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9240000, episode_reward=3.40 +/- 7.06\n",
      "Episode length: 952.60 +/- 397.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 953      |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00763  |\n",
      "|    n_updates        | 2284999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9412     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28168    |\n",
      "|    total_timesteps  | 9242470  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 2285617  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.52     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9416     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28179    |\n",
      "|    total_timesteps  | 9247042  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 2286760  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9250000, episode_reward=4.60 +/- 3.88\n",
      "Episode length: 1228.40 +/- 134.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0254   |\n",
      "|    n_updates        | 2287499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.63     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9420     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28201    |\n",
      "|    total_timesteps  | 9252555  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 2288138  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.69     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9424     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28211    |\n",
      "|    total_timesteps  | 9257213  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00773  |\n",
      "|    n_updates        | 2289303  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9260000, episode_reward=9.20 +/- 2.40\n",
      "Episode length: 1202.80 +/- 125.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | 9.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 2289999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9428     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28232    |\n",
      "|    total_timesteps  | 9262437  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 2290609  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9432     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28243    |\n",
      "|    total_timesteps  | 9267096  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00513  |\n",
      "|    n_updates        | 2291773  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9270000, episode_reward=2.20 +/- 9.83\n",
      "Episode length: 1075.20 +/- 83.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 2.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0056   |\n",
      "|    n_updates        | 2292499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.09     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9436     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28265    |\n",
      "|    total_timesteps  | 9272840  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 2293209  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.94     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9440     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28276    |\n",
      "|    total_timesteps  | 9277742  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 2294435  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9280000, episode_reward=3.20 +/- 3.60\n",
      "Episode length: 1015.40 +/- 512.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 2294999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9444     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28297    |\n",
      "|    total_timesteps  | 9283494  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 2295873  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.08     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9448     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28309    |\n",
      "|    total_timesteps  | 9288459  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00972  |\n",
      "|    n_updates        | 2297114  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9290000, episode_reward=-2.40 +/- 6.50\n",
      "Episode length: 1184.60 +/- 163.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -2.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00684  |\n",
      "|    n_updates        | 2297499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.82     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9452     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28330    |\n",
      "|    total_timesteps  | 9293855  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 2298463  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.02     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9456     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28342    |\n",
      "|    total_timesteps  | 9298801  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 2299700  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9300000, episode_reward=6.60 +/- 7.79\n",
      "Episode length: 1030.00 +/- 78.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 2299999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9460     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28361    |\n",
      "|    total_timesteps  | 9303552  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 2300887  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9464     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28372    |\n",
      "|    total_timesteps  | 9308447  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 2302111  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9310000, episode_reward=-0.80 +/- 5.42\n",
      "Episode length: 1186.00 +/- 200.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00721  |\n",
      "|    n_updates        | 2302499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.89     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9468     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28392    |\n",
      "|    total_timesteps  | 9313373  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 2303343  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9472     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28404    |\n",
      "|    total_timesteps  | 9318378  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00575  |\n",
      "|    n_updates        | 2304594  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9320000, episode_reward=9.00 +/- 2.28\n",
      "Episode length: 1045.00 +/- 229.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 9        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00772  |\n",
      "|    n_updates        | 2304999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.08     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9476     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28424    |\n",
      "|    total_timesteps  | 9323812  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 2305952  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.22     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9480     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28436    |\n",
      "|    total_timesteps  | 9328704  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00394  |\n",
      "|    n_updates        | 2307175  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9330000, episode_reward=7.60 +/- 5.64\n",
      "Episode length: 1243.60 +/- 233.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | 7.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 2307499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9484     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28457    |\n",
      "|    total_timesteps  | 9333890  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 2308472  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.96     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9488     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28469    |\n",
      "|    total_timesteps  | 9339111  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00319  |\n",
      "|    n_updates        | 2309777  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9340000, episode_reward=3.60 +/- 7.06\n",
      "Episode length: 1003.40 +/- 286.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 2309999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.33     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9492     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28489    |\n",
      "|    total_timesteps  | 9344362  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 2311090  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9496     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28500    |\n",
      "|    total_timesteps  | 9348941  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 2312235  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9350000, episode_reward=8.20 +/- 5.46\n",
      "Episode length: 953.40 +/- 369.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 953      |\n",
      "|    mean_reward      | 8.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 2312499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.44     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9500     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28522    |\n",
      "|    total_timesteps  | 9355088  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00886  |\n",
      "|    n_updates        | 2313771  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9360000, episode_reward=3.20 +/- 9.54\n",
      "Episode length: 924.00 +/- 288.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 924      |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 2314999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9504     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28543    |\n",
      "|    total_timesteps  | 9361255  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00475  |\n",
      "|    n_updates        | 2315313  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.56     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9508     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28555    |\n",
      "|    total_timesteps  | 9366517  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 2316629  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9370000, episode_reward=4.20 +/- 5.88\n",
      "Episode length: 993.80 +/- 424.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 994      |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 2317499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.54     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9512     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28577    |\n",
      "|    total_timesteps  | 9372603  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 2318150  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.55     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9516     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 28589    |\n",
      "|    total_timesteps  | 9377556  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0086   |\n",
      "|    n_updates        | 2319388  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9380000, episode_reward=3.20 +/- 5.27\n",
      "Episode length: 1277.60 +/- 211.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 2319999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.47     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9520     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28610    |\n",
      "|    total_timesteps  | 9382647  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 2320661  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.49     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9524     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28622    |\n",
      "|    total_timesteps  | 9387768  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 2321941  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9390000, episode_reward=-1.60 +/- 8.09\n",
      "Episode length: 952.40 +/- 494.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 952      |\n",
      "|    mean_reward      | -1.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00753  |\n",
      "|    n_updates        | 2322499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9528     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28643    |\n",
      "|    total_timesteps  | 9393738  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 2323434  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.85     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9532     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28654    |\n",
      "|    total_timesteps  | 9398515  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00568  |\n",
      "|    n_updates        | 2324628  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9400000, episode_reward=3.20 +/- 4.07\n",
      "Episode length: 1015.40 +/- 463.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 2324999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.14     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9536     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28676    |\n",
      "|    total_timesteps  | 9404802  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00604  |\n",
      "|    n_updates        | 2326200  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.04     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9540     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28687    |\n",
      "|    total_timesteps  | 9409533  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 2327383  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9410000, episode_reward=4.40 +/- 5.89\n",
      "Episode length: 1207.80 +/- 356.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00951  |\n",
      "|    n_updates        | 2327499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9544     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28708    |\n",
      "|    total_timesteps  | 9414311  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 2328577  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.49     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9548     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28719    |\n",
      "|    total_timesteps  | 9419083  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00778  |\n",
      "|    n_updates        | 2329770  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9420000, episode_reward=0.00 +/- 3.16\n",
      "Episode length: 1218.20 +/- 439.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 0        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 2329999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9552     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28742    |\n",
      "|    total_timesteps  | 9425082  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00381  |\n",
      "|    n_updates        | 2331270  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.53     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9556     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28754    |\n",
      "|    total_timesteps  | 9429847  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00805  |\n",
      "|    n_updates        | 2332461  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9430000, episode_reward=9.00 +/- 3.63\n",
      "Episode length: 1150.40 +/- 163.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | 9        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00641  |\n",
      "|    n_updates        | 2332499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.8      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9560     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28773    |\n",
      "|    total_timesteps  | 9434481  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0304   |\n",
      "|    n_updates        | 2333620  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9440000, episode_reward=-0.80 +/- 8.16\n",
      "Episode length: 1112.40 +/- 479.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -0.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00813  |\n",
      "|    n_updates        | 2334999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.66     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9564     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28797    |\n",
      "|    total_timesteps  | 9441168  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 2335291  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9568     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28807    |\n",
      "|    total_timesteps  | 9445390  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 2336347  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9450000, episode_reward=-2.80 +/- 4.53\n",
      "Episode length: 1068.80 +/- 435.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -2.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 2337499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.28     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9572     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28828    |\n",
      "|    total_timesteps  | 9451014  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 2337753  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.29     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9576     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28841    |\n",
      "|    total_timesteps  | 9456617  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 2339154  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9460000, episode_reward=8.60 +/- 2.42\n",
      "Episode length: 926.20 +/- 293.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 926      |\n",
      "|    mean_reward      | 8.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 2339999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.25     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9580     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28863    |\n",
      "|    total_timesteps  | 9462954  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00278  |\n",
      "|    n_updates        | 2340738  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.67     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9584     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28875    |\n",
      "|    total_timesteps  | 9467611  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 2341902  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9470000, episode_reward=2.60 +/- 5.85\n",
      "Episode length: 1012.80 +/- 335.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | 2.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 2342499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 4.62     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9588     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28897    |\n",
      "|    total_timesteps  | 9473871  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 2343467  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 4.34     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9592     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28909    |\n",
      "|    total_timesteps  | 9479141  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 2344785  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9480000, episode_reward=5.60 +/- 6.18\n",
      "Episode length: 1029.60 +/- 382.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 2344999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 4.2      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9596     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28930    |\n",
      "|    total_timesteps  | 9484839  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 2346209  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 4.08     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9600     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28942    |\n",
      "|    total_timesteps  | 9489732  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 2347432  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9490000, episode_reward=8.80 +/- 3.66\n",
      "Episode length: 1074.60 +/- 201.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 8.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 2347499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.28     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9604     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28961    |\n",
      "|    total_timesteps  | 9494640  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.009    |\n",
      "|    n_updates        | 2348659  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 4.23     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9608     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28973    |\n",
      "|    total_timesteps  | 9499470  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 2349867  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9500000, episode_reward=1.80 +/- 6.97\n",
      "Episode length: 1080.40 +/- 262.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 2349999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.03     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9612     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 28993    |\n",
      "|    total_timesteps  | 9504931  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 2351232  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9616     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29003    |\n",
      "|    total_timesteps  | 9508850  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00541  |\n",
      "|    n_updates        | 2352212  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9510000, episode_reward=3.80 +/- 6.24\n",
      "Episode length: 979.80 +/- 425.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 980      |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0074   |\n",
      "|    n_updates        | 2352499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.68     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9620     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29024    |\n",
      "|    total_timesteps  | 9514655  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 2353663  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.31     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9624     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29036    |\n",
      "|    total_timesteps  | 9519753  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 2354938  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9520000, episode_reward=6.80 +/- 5.95\n",
      "Episode length: 1116.20 +/- 251.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 6.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 2354999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.29     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9628     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29056    |\n",
      "|    total_timesteps  | 9524651  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 2356162  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9632     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29067    |\n",
      "|    total_timesteps  | 9529412  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00842  |\n",
      "|    n_updates        | 2357352  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9530000, episode_reward=0.40 +/- 2.42\n",
      "Episode length: 1193.40 +/- 369.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 2357499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 4.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9636     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29087    |\n",
      "|    total_timesteps  | 9534100  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 2358524  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 4.22     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9640     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29099    |\n",
      "|    total_timesteps  | 9539238  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00337  |\n",
      "|    n_updates        | 2359809  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9540000, episode_reward=-2.20 +/- 8.75\n",
      "Episode length: 936.20 +/- 275.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 936      |\n",
      "|    mean_reward      | -2.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 2359999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.99     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9644     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29118    |\n",
      "|    total_timesteps  | 9544352  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00602  |\n",
      "|    n_updates        | 2361087  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9648     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29129    |\n",
      "|    total_timesteps  | 9549266  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00426  |\n",
      "|    n_updates        | 2362316  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9550000, episode_reward=1.80 +/- 2.64\n",
      "Episode length: 1102.20 +/- 425.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00864  |\n",
      "|    n_updates        | 2362499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9652     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29149    |\n",
      "|    total_timesteps  | 9554046  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 2363511  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 4.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9656     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29160    |\n",
      "|    total_timesteps  | 9558824  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 2364705  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9560000, episode_reward=3.80 +/- 5.11\n",
      "Episode length: 1216.20 +/- 215.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 2364999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 4.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9660     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29180    |\n",
      "|    total_timesteps  | 9563799  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 2365949  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 4.28     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9664     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29192    |\n",
      "|    total_timesteps  | 9568841  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00462  |\n",
      "|    n_updates        | 2367210  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9570000, episode_reward=6.20 +/- 2.93\n",
      "Episode length: 1136.40 +/- 261.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | 6.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 2367499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 4.25     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9668     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29212    |\n",
      "|    total_timesteps  | 9573908  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 2368476  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 4.3      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9672     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29225    |\n",
      "|    total_timesteps  | 9579524  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0285   |\n",
      "|    n_updates        | 2369880  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=9580000, episode_reward=7.00 +/- 4.77\n",
      "Episode length: 1098.00 +/- 255.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | 7        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 2369999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 4.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9676     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29246    |\n",
      "|    total_timesteps  | 9585122  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00344  |\n",
      "|    n_updates        | 2371280  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9590000, episode_reward=0.40 +/- 4.67\n",
      "Episode length: 1069.80 +/- 369.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 0.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 2372499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 4.01     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9680     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29269    |\n",
      "|    total_timesteps  | 9591453  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00311  |\n",
      "|    n_updates        | 2372863  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9684     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29282    |\n",
      "|    total_timesteps  | 9596661  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 2374165  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9600000, episode_reward=0.20 +/- 3.92\n",
      "Episode length: 1186.80 +/- 398.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00949  |\n",
      "|    n_updates        | 2374999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9688     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29304    |\n",
      "|    total_timesteps  | 9602277  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00887  |\n",
      "|    n_updates        | 2375569  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.81     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9692     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29316    |\n",
      "|    total_timesteps  | 9607613  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 2376903  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9610000, episode_reward=3.40 +/- 7.09\n",
      "Episode length: 1225.60 +/- 123.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 2377499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.6      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9696     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29337    |\n",
      "|    total_timesteps  | 9612550  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 2378137  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | 3.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9700     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29347    |\n",
      "|    total_timesteps  | 9616919  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00938  |\n",
      "|    n_updates        | 2379229  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9620000, episode_reward=3.20 +/- 7.65\n",
      "Episode length: 1018.40 +/- 536.70\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00371  |\n",
      "|    n_updates        | 2379999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.24     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9704     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29368    |\n",
      "|    total_timesteps  | 9622442  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00977  |\n",
      "|    n_updates        | 2380610  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.19     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9708     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29380    |\n",
      "|    total_timesteps  | 9627585  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00395  |\n",
      "|    n_updates        | 2381896  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9630000, episode_reward=3.40 +/- 8.09\n",
      "Episode length: 997.40 +/- 536.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 997      |\n",
      "|    mean_reward      | 3.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00691  |\n",
      "|    n_updates        | 2382499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9712     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29402    |\n",
      "|    total_timesteps  | 9633770  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 2383442  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9716     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29411    |\n",
      "|    total_timesteps  | 9637939  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0235   |\n",
      "|    n_updates        | 2384484  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9640000, episode_reward=5.00 +/- 8.12\n",
      "Episode length: 958.40 +/- 346.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 958      |\n",
      "|    mean_reward      | 5        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 2384999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.63     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9720     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29433    |\n",
      "|    total_timesteps  | 9644222  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 2386055  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 2.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9724     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29445    |\n",
      "|    total_timesteps  | 9649118  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 2387279  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9650000, episode_reward=2.40 +/- 5.82\n",
      "Episode length: 948.20 +/- 388.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 948      |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 2387499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9728     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29466    |\n",
      "|    total_timesteps  | 9655196  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00923  |\n",
      "|    n_updates        | 2388798  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.75     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9732     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29477    |\n",
      "|    total_timesteps  | 9659950  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 2389987  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9660000, episode_reward=6.20 +/- 7.83\n",
      "Episode length: 1251.60 +/- 217.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.25e+03 |\n",
      "|    mean_reward      | 6.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 2389999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.69     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9736     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29498    |\n",
      "|    total_timesteps  | 9665086  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 2391271  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.8      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9740     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29509    |\n",
      "|    total_timesteps  | 9669783  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000975 |\n",
      "|    n_updates        | 2392445  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9670000, episode_reward=1.00 +/- 5.73\n",
      "Episode length: 1283.00 +/- 114.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 2392499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9744     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29530    |\n",
      "|    total_timesteps  | 9674855  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 2393713  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.76     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9748     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29542    |\n",
      "|    total_timesteps  | 9679853  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00733  |\n",
      "|    n_updates        | 2394963  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9680000, episode_reward=0.80 +/- 3.60\n",
      "Episode length: 1306.80 +/- 212.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00861  |\n",
      "|    n_updates        | 2394999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.67     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9752     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29564    |\n",
      "|    total_timesteps  | 9684999  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0094   |\n",
      "|    n_updates        | 2396249  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9756     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29575    |\n",
      "|    total_timesteps  | 9689596  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 2397398  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=9690000, episode_reward=6.60 +/- 6.22\n",
      "Episode length: 1021.80 +/- 243.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 2397499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.69     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9760     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29596    |\n",
      "|    total_timesteps  | 9695206  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 2398801  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9764     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29607    |\n",
      "|    total_timesteps  | 9699942  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00407  |\n",
      "|    n_updates        | 2399985  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9700000, episode_reward=4.20 +/- 5.34\n",
      "Episode length: 1223.20 +/- 88.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 2399999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9768     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29628    |\n",
      "|    total_timesteps  | 9705123  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 2401280  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9710000, episode_reward=0.00 +/- 4.34\n",
      "Episode length: 1120.80 +/- 408.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | 0        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 2402499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 2.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9772     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29651    |\n",
      "|    total_timesteps  | 9711293  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 2402823  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9776     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29662    |\n",
      "|    total_timesteps  | 9716206  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00918  |\n",
      "|    n_updates        | 2404051  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9720000, episode_reward=1.80 +/- 7.00\n",
      "Episode length: 960.40 +/- 443.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 960      |\n",
      "|    mean_reward      | 1.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00358  |\n",
      "|    n_updates        | 2404999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 2.87     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9780     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29684    |\n",
      "|    total_timesteps  | 9722094  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0051   |\n",
      "|    n_updates        | 2405523  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.62     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9784     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29695    |\n",
      "|    total_timesteps  | 9726848  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00765  |\n",
      "|    n_updates        | 2406711  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9730000, episode_reward=12.20 +/- 4.83\n",
      "Episode length: 826.60 +/- 372.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 827      |\n",
      "|    mean_reward      | 12.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 2407499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9788     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29714    |\n",
      "|    total_timesteps  | 9732630  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 2408157  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 2.94     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9792     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29726    |\n",
      "|    total_timesteps  | 9737619  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 2409404  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9740000, episode_reward=2.80 +/- 5.19\n",
      "Episode length: 1324.40 +/- 135.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00473  |\n",
      "|    n_updates        | 2409999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.01     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9796     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29746    |\n",
      "|    total_timesteps  | 9742134  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 2410533  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.32     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9800     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29759    |\n",
      "|    total_timesteps  | 9747549  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 2411887  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9750000, episode_reward=0.80 +/- 5.04\n",
      "Episode length: 1347.40 +/- 182.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.35e+03 |\n",
      "|    mean_reward      | 0.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 2412499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.38     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9804     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29782    |\n",
      "|    total_timesteps  | 9753027  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00911  |\n",
      "|    n_updates        | 2413256  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9808     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29792    |\n",
      "|    total_timesteps  | 9757450  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 2414362  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9760000, episode_reward=2.80 +/- 3.31\n",
      "Episode length: 1166.80 +/- 389.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 2.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 2414999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.63     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9812     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29813    |\n",
      "|    total_timesteps  | 9762627  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 2415656  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9816     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29824    |\n",
      "|    total_timesteps  | 9767516  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00878  |\n",
      "|    n_updates        | 2416878  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9770000, episode_reward=6.60 +/- 3.44\n",
      "Episode length: 939.40 +/- 336.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 939      |\n",
      "|    mean_reward      | 6.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00662  |\n",
      "|    n_updates        | 2417499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.77     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9820     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29846    |\n",
      "|    total_timesteps  | 9773719  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00628  |\n",
      "|    n_updates        | 2418429  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.83     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9824     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29859    |\n",
      "|    total_timesteps  | 9779141  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00456  |\n",
      "|    n_updates        | 2419785  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9780000, episode_reward=2.40 +/- 7.66\n",
      "Episode length: 1040.00 +/- 382.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 2419999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.78     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9828     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29881    |\n",
      "|    total_timesteps  | 9785277  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 2421319  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9790000, episode_reward=5.40 +/- 3.93\n",
      "Episode length: 1073.40 +/- 249.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | 5.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00515  |\n",
      "|    n_updates        | 2422499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.59     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9832     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29903    |\n",
      "|    total_timesteps  | 9791362  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00528  |\n",
      "|    n_updates        | 2422840  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.6      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9836     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29916    |\n",
      "|    total_timesteps  | 9796779  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00683  |\n",
      "|    n_updates        | 2424194  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9800000, episode_reward=-0.20 +/- 3.76\n",
      "Episode length: 1160.60 +/- 293.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | -0.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 2424999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.52     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9840     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29938    |\n",
      "|    total_timesteps  | 9802711  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 2425677  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.58     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9844     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29950    |\n",
      "|    total_timesteps  | 9807748  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 2426936  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9810000, episode_reward=4.60 +/- 5.89\n",
      "Episode length: 1131.60 +/- 333.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00986  |\n",
      "|    n_updates        | 2427499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.64     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9848     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29973    |\n",
      "|    total_timesteps  | 9814162  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 2428540  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.7      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9852     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 29985    |\n",
      "|    total_timesteps  | 9819213  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 2429803  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9820000, episode_reward=1.60 +/- 8.78\n",
      "Episode length: 995.60 +/- 311.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 996      |\n",
      "|    mean_reward      | 1.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 2429999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9856     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30006    |\n",
      "|    total_timesteps  | 9825095  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00794  |\n",
      "|    n_updates        | 2431273  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9830000, episode_reward=5.40 +/- 3.61\n",
      "Episode length: 1019.80 +/- 515.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | 5.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 2432499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 3.21     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9860     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30028    |\n",
      "|    total_timesteps  | 9831291  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0269   |\n",
      "|    n_updates        | 2432822  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 3.39     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9864     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30040    |\n",
      "|    total_timesteps  | 9836105  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 2434026  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9840000, episode_reward=7.00 +/- 6.10\n",
      "Episode length: 932.00 +/- 437.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 932      |\n",
      "|    mean_reward      | 7        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 2434999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 3.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9868     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30063    |\n",
      "|    total_timesteps  | 9843012  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00986  |\n",
      "|    n_updates        | 2435752  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 3.37     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9872     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30074    |\n",
      "|    total_timesteps  | 9847811  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 2436952  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9850000, episode_reward=7.00 +/- 2.61\n",
      "Episode length: 1106.00 +/- 208.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | 7        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 2437499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 3.07     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9876     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30095    |\n",
      "|    total_timesteps  | 9853427  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 2438356  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 2.9      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9880     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30106    |\n",
      "|    total_timesteps  | 9857833  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0347   |\n",
      "|    n_updates        | 2439458  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=9860000, episode_reward=2.00 +/- 5.73\n",
      "Episode length: 1075.40 +/- 543.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | 2        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0271   |\n",
      "|    n_updates        | 2439999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 3.17     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9884     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30128    |\n",
      "|    total_timesteps  | 9863982  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00805  |\n",
      "|    n_updates        | 2440995  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 3.18     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9888     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30139    |\n",
      "|    total_timesteps  | 9868831  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 2442207  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9870000, episode_reward=0.00 +/- 7.90\n",
      "Episode length: 1268.20 +/- 185.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | 0        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00798  |\n",
      "|    n_updates        | 2442499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 2.97     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9892     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30160    |\n",
      "|    total_timesteps  | 9873630  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0081   |\n",
      "|    n_updates        | 2443407  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 2.85     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9896     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30173    |\n",
      "|    total_timesteps  | 9879017  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00455  |\n",
      "|    n_updates        | 2444754  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9880000, episode_reward=9.80 +/- 7.57\n",
      "Episode length: 871.80 +/- 371.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 872      |\n",
      "|    mean_reward      | 9.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00641  |\n",
      "|    n_updates        | 2444999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 3.11     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9900     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30191    |\n",
      "|    total_timesteps  | 9884198  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00999  |\n",
      "|    n_updates        | 2446049  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 2.87     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9904     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30204    |\n",
      "|    total_timesteps  | 9889585  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00924  |\n",
      "|    n_updates        | 2447396  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9890000, episode_reward=0.20 +/- 7.96\n",
      "Episode length: 1087.60 +/- 261.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | 0.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 2447499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 3.05     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9908     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30222    |\n",
      "|    total_timesteps  | 9894127  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 2448531  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 3        |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9912     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30233    |\n",
      "|    total_timesteps  | 9898713  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00962  |\n",
      "|    n_updates        | 2449678  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9900000, episode_reward=4.40 +/- 4.13\n",
      "Episode length: 1336.80 +/- 87.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 2449999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 3.08     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9916     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30254    |\n",
      "|    total_timesteps  | 9903289  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0061   |\n",
      "|    n_updates        | 2450822  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.13     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9920     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30267    |\n",
      "|    total_timesteps  | 9908720  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 2452179  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9910000, episode_reward=-0.60 +/- 4.63\n",
      "Episode length: 1116.20 +/- 489.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -0.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 2452499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 3.26     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9924     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30291    |\n",
      "|    total_timesteps  | 9915304  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00432  |\n",
      "|    n_updates        | 2453825  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9920000, episode_reward=4.60 +/- 4.18\n",
      "Episode length: 1062.40 +/- 470.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.06e+03 |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 2454999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | 3.19     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9928     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30313    |\n",
      "|    total_timesteps  | 9921262  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 2455315  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 3.45     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9932     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30324    |\n",
      "|    total_timesteps  | 9925982  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00639  |\n",
      "|    n_updates        | 2456495  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9930000, episode_reward=5.80 +/- 4.79\n",
      "Episode length: 1170.60 +/- 298.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | 5.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 2457499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.69     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9936     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30344    |\n",
      "|    total_timesteps  | 9931038  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 2457759  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.87     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9940     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30356    |\n",
      "|    total_timesteps  | 9935976  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 2458993  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9940000, episode_reward=1.40 +/- 4.67\n",
      "Episode length: 1183.40 +/- 172.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | 1.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.009    |\n",
      "|    n_updates        | 2459999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.91     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9944     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30377    |\n",
      "|    total_timesteps  | 9941165  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00563  |\n",
      "|    n_updates        | 2460291  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.86     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9948     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30388    |\n",
      "|    total_timesteps  | 9946118  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 2461529  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9950000, episode_reward=7.20 +/- 5.31\n",
      "Episode length: 1261.80 +/- 198.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.26e+03 |\n",
      "|    mean_reward      | 7.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00547  |\n",
      "|    n_updates        | 2462499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 3.73     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9952     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30409    |\n",
      "|    total_timesteps  | 9951234  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00389  |\n",
      "|    n_updates        | 2462808  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.87     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9956     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30421    |\n",
      "|    total_timesteps  | 9956023  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00982  |\n",
      "|    n_updates        | 2464005  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9960000, episode_reward=10.60 +/- 1.96\n",
      "Episode length: 1037.40 +/- 133.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 10.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 2464999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 4.06     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9960     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30441    |\n",
      "|    total_timesteps  | 9961403  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00848  |\n",
      "|    n_updates        | 2465350  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.72     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9964     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30452    |\n",
      "|    total_timesteps  | 9966307  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0478   |\n",
      "|    n_updates        | 2466576  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=9970000, episode_reward=5.80 +/- 5.84\n",
      "Episode length: 1036.00 +/- 522.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | 5.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00601  |\n",
      "|    n_updates        | 2467499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 3.7      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9968     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30474    |\n",
      "|    total_timesteps  | 9972213  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00702  |\n",
      "|    n_updates        | 2468053  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.5      |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9972     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30487    |\n",
      "|    total_timesteps  | 9977632  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00556  |\n",
      "|    n_updates        | 2469407  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9980000, episode_reward=8.00 +/- 6.32\n",
      "Episode length: 962.40 +/- 415.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 962      |\n",
      "|    mean_reward      | 8        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00748  |\n",
      "|    n_updates        | 2469999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | 3.71     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9976     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30507    |\n",
      "|    total_timesteps  | 9983475  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 2470868  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 3.88     |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9980     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30520    |\n",
      "|    total_timesteps  | 9989011  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00707  |\n",
      "|    n_updates        | 2472252  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9990000, episode_reward=1.20 +/- 2.71\n",
      "Episode length: 1189.80 +/- 287.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | 1.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00583  |\n",
      "|    n_updates        | 2472499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | 4        |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9984     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 30543    |\n",
      "|    total_timesteps  | 9995032  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 2473757  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000000, episode_reward=5.60 +/- 2.42\n",
      "Episode length: 1026.20 +/- 417.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.03e+03 |\n",
      "|    mean_reward      | 5.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000000 |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00477  |\n",
      "|    n_updates        | 2474999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3f.dqn.dqn.DQN at 0x7f7ca8399040>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pong.learn(total_timesteps=10000000, callback=eval_callback,tb_log_name='Pong_Opt_10x0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models','Opt_Pong_10M')\n",
    "model_pong.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.9, 1.8681541692269403)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model_pong, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

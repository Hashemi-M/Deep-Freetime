{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n",
    "# https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym \n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"Pong-v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-21.0\n",
      "Episode:2 Score:-21.0\n",
      "Episode:3 Score:-20.0\n",
      "Episode:4 Score:-18.0\n",
      "Episode:5 Score:-20.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[134,  85, 232],\n",
       "        [ 85, 167, 244],\n",
       "        [181,  85,   8],\n",
       "        ...,\n",
       "        [ 43, 252,  14],\n",
       "        [ 71,   4,  26],\n",
       "        [106,  96,  21]],\n",
       "\n",
       "       [[  0, 140,  23],\n",
       "        [250, 150,  15],\n",
       "        [ 12, 137, 105],\n",
       "        ...,\n",
       "        [187,  67,   6],\n",
       "        [149,   6, 201],\n",
       "        [149,  28, 190]],\n",
       "\n",
       "       [[  2, 191, 255],\n",
       "        [117, 236,  69],\n",
       "        [219,  83, 149],\n",
       "        ...,\n",
       "        [169,  43, 146],\n",
       "        [184,  91,  10],\n",
       "        [231,  15, 126]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[177,  90, 215],\n",
       "        [176, 188,  46],\n",
       "        [ 37, 142, 204],\n",
       "        ...,\n",
       "        [ 41, 168,  79],\n",
       "        [ 28, 182,  58],\n",
       "        [153,  12, 146]],\n",
       "\n",
       "       [[ 19, 107,  24],\n",
       "        [253, 179,   5],\n",
       "        [235, 215, 240],\n",
       "        ...,\n",
       "        [204, 164, 169],\n",
       "        [ 60, 187, 174],\n",
       "        [ 71, 145, 149]],\n",
       "\n",
       "       [[154, 146, 124],\n",
       "        [175,  48, 169],\n",
       "        [ 19,  43,  27],\n",
       "        ...,\n",
       "        [ 38,  37, 115],\n",
       "        [224, 121, 194],\n",
       "        [100, 137, 188]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train an RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "model = DQN('CnnPolicy',env, verbose = 1,buffer_size = 10000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4910     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 2758     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 9785     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.2e+03  |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 2865     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 14448    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.2e+03  |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 19267    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f3fc15cd460>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN_path = os.path.join('Training', 'Saved Models', 'DQN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(DQN_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(DQN_path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-21.0, 0.0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info {'lives': 0, 'episode_frame_number': 3056, 'frame_number': 93574}\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done: \n",
    "        print('info', info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Viewing Logs in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training','Logs')\n",
    "training_log_path = os.path.join(log_path, 'DQN_Pong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-14 23:37:06.171732: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-08-14 23:37:07.060327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 23:37:07.148370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 23:37:07.148495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.9.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Adding a callback to the training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models')\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=20, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=stop_callback, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=save_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = DQN('CnnPolicy', env, verbose = 1, buffer_size = 10000, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/DQN_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:345: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f3f5c607280> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f3f5cee9b20>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.18e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4734     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.17e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 2735     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 9397     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1017.80 +/- 5.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1481     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 15001    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1687     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 19572    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1020.60 +/- 7.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1408     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 25032    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1537     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 29595    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1022.80 +/- 7.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1378     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 34842    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1475     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 39455    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1018.00 +/- 4.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1360     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 44733    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1436     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 49331    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1010.60 +/- 6.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1100     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 54571    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 1142     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 985      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 59484    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 2370     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1156.00 +/- 70.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.16e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000223 |\n",
      "|    n_updates        | 2499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 65504    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00768  |\n",
      "|    n_updates        | 3875     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1127.40 +/- 88.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000432 |\n",
      "|    n_updates        | 4999     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 732      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 71331    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000934 |\n",
      "|    n_updates        | 5332     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 700      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 76357    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000347 |\n",
      "|    n_updates        | 6589     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1014.80 +/- 7.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.01e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000594 |\n",
      "|    n_updates        | 7499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -21.6    |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 648      |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 82477    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 8119     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -21.5    |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 631      |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 87429    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 9357     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1024.60 +/- 8.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.02e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000724 |\n",
      "|    n_updates        | 9999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -21.5    |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 600      |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 92162    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 10540    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 97069    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000492 |\n",
      "|    n_updates        | 11767    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1037.00 +/- 33.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.04e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 12499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 102796   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000349 |\n",
      "|    n_updates        | 13198    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 556      |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 107523   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 14380    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1343.80 +/- 196.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 110000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000685 |\n",
      "|    n_updates        | 14999    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 531      |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 112222   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000771 |\n",
      "|    n_updates        | 15555    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 527      |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 117316   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 16828    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1197.40 +/- 73.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 120000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 17499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 509      |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 122331   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000378 |\n",
      "|    n_updates        | 18082    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.27e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 506      |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 127255   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 19313    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-20.20 +/- 1.17\n",
      "Episode length: 1266.60 +/- 64.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 130000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 19999    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 490      |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 132521   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 20630    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 488      |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 137968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0006   |\n",
      "|    n_updates        | 21991    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1178.40 +/- 74.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 140000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000641 |\n",
      "|    n_updates        | 22499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 475      |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 144114   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 23528    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 474      |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 149216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000772 |\n",
      "|    n_updates        | 24803    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1230.40 +/- 77.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 150000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000732 |\n",
      "|    n_updates        | 24999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+03  |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 463      |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 155178   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000939 |\n",
      "|    n_updates        | 26294    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-20.60 +/- 0.80\n",
      "Episode length: 1448.00 +/- 127.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.45e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 160000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000689 |\n",
      "|    n_updates        | 27499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 453      |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 161215   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00479  |\n",
      "|    n_updates        | 27803    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.31e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 451      |\n",
      "|    time_elapsed     | 367      |\n",
      "|    total_timesteps  | 166196   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000624 |\n",
      "|    n_updates        | 29048    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-19.80 +/- 0.75\n",
      "Episode length: 1407.40 +/- 146.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.41e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 170000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000694 |\n",
      "|    n_updates        | 29999    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 390      |\n",
      "|    total_timesteps  | 172556   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000803 |\n",
      "|    n_updates        | 30638    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 441      |\n",
      "|    time_elapsed     | 402      |\n",
      "|    total_timesteps  | 177690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00067  |\n",
      "|    n_updates        | 31922    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-19.80 +/- 0.40\n",
      "Episode length: 1387.80 +/- 29.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.39e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 180000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 32499    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.781    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 425      |\n",
      "|    total_timesteps  | 184631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000815 |\n",
      "|    n_updates        | 33657    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 437      |\n",
      "|    total_timesteps  | 189949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000951 |\n",
      "|    n_updates        | 34987    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-20.20 +/- 0.75\n",
      "Episode length: 1198.80 +/- 227.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 190000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000566 |\n",
      "|    n_updates        | 34999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.768    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 455      |\n",
      "|    total_timesteps  | 195153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 36288    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1325.40 +/- 176.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.33e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 37499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.761    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 421      |\n",
      "|    time_elapsed     | 476      |\n",
      "|    total_timesteps  | 201193   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000531 |\n",
      "|    n_updates        | 37798    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 421      |\n",
      "|    time_elapsed     | 490      |\n",
      "|    total_timesteps  | 206889   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00334  |\n",
      "|    n_updates        | 39222    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1089.80 +/- 70.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.751    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 210000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 39999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | -21.2    |\n",
      "|    exploration_rate | 0.747    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 511      |\n",
      "|    total_timesteps  | 212859   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000554 |\n",
      "|    n_updates        | 40714    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 523      |\n",
      "|    total_timesteps  | 217913   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000951 |\n",
      "|    n_updates        | 41978    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-19.40 +/- 1.36\n",
      "Episode length: 1668.20 +/- 272.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.67e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.739    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 220000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000749 |\n",
      "|    n_updates        | 42499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.36e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 546      |\n",
      "|    total_timesteps  | 223826   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 43456    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.728    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 561      |\n",
      "|    total_timesteps  | 229462   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000571 |\n",
      "|    n_updates        | 44865    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-19.60 +/- 1.02\n",
      "Episode length: 1495.00 +/- 242.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.5e+03  |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 230000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 44999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 403      |\n",
      "|    time_elapsed     | 582      |\n",
      "|    total_timesteps  | 235481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000586 |\n",
      "|    n_updates        | 46370    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-18.00 +/- 0.89\n",
      "Episode length: 1779.60 +/- 95.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.78e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 240000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00925  |\n",
      "|    n_updates        | 47499    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.714    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 397      |\n",
      "|    time_elapsed     | 606      |\n",
      "|    total_timesteps  | 241243   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 47810    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.39e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.708    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 397      |\n",
      "|    time_elapsed     | 619      |\n",
      "|    total_timesteps  | 246202   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000255 |\n",
      "|    n_updates        | 49050    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-20.00 +/- 1.55\n",
      "Episode length: 1345.60 +/- 222.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.35e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.703    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 250000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000475 |\n",
      "|    n_updates        | 49999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.41e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.699    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 643      |\n",
      "|    total_timesteps  | 253154   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 50788    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.42e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.693    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 657      |\n",
      "|    total_timesteps  | 258831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00421  |\n",
      "|    n_updates        | 52207    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-18.80 +/- 1.17\n",
      "Episode length: 1584.60 +/- 80.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.58e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.691    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 260000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 52499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.42e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 680      |\n",
      "|    total_timesteps  | 264751   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 53687    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-18.40 +/- 1.36\n",
      "Episode length: 1620.80 +/- 196.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.62e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.679    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 270000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 54999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.44e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 705      |\n",
      "|    total_timesteps  | 271254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00384  |\n",
      "|    n_updates        | 55313    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.44e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 719      |\n",
      "|    total_timesteps  | 276847   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 56711    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-18.00 +/- 1.67\n",
      "Episode length: 1767.00 +/- 274.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.77e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 280000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 57499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.46e+03 |\n",
      "|    ep_rew_mean      | -21.5    |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 746      |\n",
      "|    total_timesteps  | 283846   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 58461    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.45e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 761      |\n",
      "|    total_timesteps  | 289455   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 59863    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-17.80 +/- 1.60\n",
      "Episode length: 1931.40 +/- 204.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.93e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 290000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 59999    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.47e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 785      |\n",
      "|    total_timesteps  | 295763   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 61440    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-18.60 +/- 1.36\n",
      "Episode length: 1692.00 +/- 249.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.69e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.644    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 300000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 62499    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.48e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 811      |\n",
      "|    total_timesteps  | 303105   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00436  |\n",
      "|    n_updates        | 63276    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.48e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.633    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 825      |\n",
      "|    total_timesteps  | 308772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 64692    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-19.60 +/- 0.49\n",
      "Episode length: 1763.40 +/- 166.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.76e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.632    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 310000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 64999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.5e+03  |\n",
      "|    ep_rew_mean      | -21.5    |\n",
      "|    exploration_rate | 0.625    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 851      |\n",
      "|    total_timesteps  | 315771   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 66442    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-17.20 +/- 0.75\n",
      "Episode length: 2214.60 +/- 197.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 320000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 67499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.51e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 879      |\n",
      "|    total_timesteps  | 323277   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00368  |\n",
      "|    n_updates        | 68319    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.52e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 895      |\n",
      "|    total_timesteps  | 329257   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 69814    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1463.40 +/- 238.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.46e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 330000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 69999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.52e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.601    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 920      |\n",
      "|    total_timesteps  | 336213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 71553    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-18.20 +/- 0.75\n",
      "Episode length: 1760.40 +/- 321.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.76e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.596    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 340000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 72499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.53e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 947      |\n",
      "|    total_timesteps  | 343296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 73323    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-19.80 +/- 0.75\n",
      "Episode length: 1383.20 +/- 181.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.38e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.584    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 350000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 74999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.56e+03 |\n",
      "|    ep_rew_mean      | -21.5    |\n",
      "|    exploration_rate | 0.583    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 975      |\n",
      "|    total_timesteps  | 351397   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 75349    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.57e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.575    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 992      |\n",
      "|    total_timesteps  | 357894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 76973    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-19.80 +/- 0.40\n",
      "Episode length: 1739.00 +/- 200.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.74e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 360000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00683  |\n",
      "|    n_updates        | 77499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.57e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.567    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 1018     |\n",
      "|    total_timesteps  | 364323   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 78580    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=370000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1272.60 +/- 148.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.561    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 370000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000862 |\n",
      "|    n_updates        | 79999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.559    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 1042     |\n",
      "|    total_timesteps  | 371128   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 80281    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.59e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.553    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 1058     |\n",
      "|    total_timesteps  | 376765   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 81691    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=-18.60 +/- 1.20\n",
      "Episode length: 1706.60 +/- 247.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.71e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.549    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 380000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00289  |\n",
      "|    n_updates        | 82499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.59e+03 |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 1082     |\n",
      "|    total_timesteps  | 382937   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000945 |\n",
      "|    n_updates        | 83234    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.6e+03  |\n",
      "|    ep_rew_mean      | -21.3    |\n",
      "|    exploration_rate | 0.538    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 1099     |\n",
      "|    total_timesteps  | 388972   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 84742    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=-19.60 +/- 1.02\n",
      "Episode length: 1384.60 +/- 141.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.38e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.537    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 390000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 84999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.6e+03  |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.53     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 1124     |\n",
      "|    total_timesteps  | 395448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00436  |\n",
      "|    n_updates        | 86361    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-19.20 +/- 1.47\n",
      "Episode length: 1503.80 +/- 235.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.5e+03  |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 400000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 87499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.6e+03  |\n",
      "|    ep_rew_mean      | -21.5    |\n",
      "|    exploration_rate | 0.523    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 1147     |\n",
      "|    total_timesteps  | 401304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00648  |\n",
      "|    n_updates        | 87825    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | -21.5    |\n",
      "|    exploration_rate | 0.517    |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 1163     |\n",
      "|    total_timesteps  | 407041   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00314  |\n",
      "|    n_updates        | 89260    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=-18.00 +/- 1.90\n",
      "Episode length: 1721.80 +/- 281.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.72e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 410000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 89999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.6e+03  |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.509    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 1189     |\n",
      "|    total_timesteps  | 413187   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00613  |\n",
      "|    n_updates        | 90796    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.501    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 1207     |\n",
      "|    total_timesteps  | 419826   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00342  |\n",
      "|    n_updates        | 92456    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=-19.00 +/- 0.89\n",
      "Episode length: 1577.20 +/- 150.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.58e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.501    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 420000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 92499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.62e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.493    |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 1235     |\n",
      "|    total_timesteps  | 427119   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 94279    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=430000, episode_reward=-19.00 +/- 1.79\n",
      "Episode length: 1665.60 +/- 408.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.67e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.489    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 430000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00313  |\n",
      "|    n_updates        | 94999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.64e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.484    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 1265     |\n",
      "|    total_timesteps  | 434861   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0055   |\n",
      "|    n_updates        | 96215    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-18.60 +/- 1.36\n",
      "Episode length: 1613.60 +/- 169.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.61e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 440000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 97499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 1291     |\n",
      "|    total_timesteps  | 441509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 97877    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 1311     |\n",
      "|    total_timesteps  | 448395   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00517  |\n",
      "|    n_updates        | 99598    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-19.40 +/- 0.80\n",
      "Episode length: 1536.00 +/- 81.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.54e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.466    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 450000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 99999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 1338     |\n",
      "|    total_timesteps  | 455571   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 101392   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=-20.80 +/- 0.40\n",
      "Episode length: 1442.60 +/- 143.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.44e+03 |\n",
      "|    mean_reward      | -20.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.454    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 460000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00294  |\n",
      "|    n_updates        | 102499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.452    |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 1362     |\n",
      "|    total_timesteps  | 461551   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 102887   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 1382     |\n",
      "|    total_timesteps  | 468515   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00357  |\n",
      "|    n_updates        | 104628   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=-19.80 +/- 0.98\n",
      "Episode length: 1702.40 +/- 258.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.7e+03  |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 470000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000916 |\n",
      "|    n_updates        | 104999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.436    |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 337      |\n",
      "|    time_elapsed     | 1408     |\n",
      "|    total_timesteps  | 474902   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 106225   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-20.20 +/- 0.98\n",
      "Episode length: 1311.80 +/- 320.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 480000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 107499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.429    |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 1432     |\n",
      "|    total_timesteps  | 481104   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 107775   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.63e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 1448     |\n",
      "|    total_timesteps  | 486608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 109151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=-20.20 +/- 0.75\n",
      "Episode length: 1193.40 +/- 65.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.19e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.418    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 490000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000772 |\n",
      "|    n_updates        | 109999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.63e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 1470     |\n",
      "|    total_timesteps  | 492488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 110621   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.409    |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 1484     |\n",
      "|    total_timesteps  | 497484   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00718  |\n",
      "|    n_updates        | 111870   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=-19.80 +/- 1.17\n",
      "Episode length: 1487.60 +/- 186.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.49e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 112499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.401    |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 1508     |\n",
      "|    total_timesteps  | 504061   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00969  |\n",
      "|    n_updates        | 113515   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.395    |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 1522     |\n",
      "|    total_timesteps  | 509121   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 114780   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=-19.80 +/- 1.17\n",
      "Episode length: 1278.60 +/- 195.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.394    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 510000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 114999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 1546     |\n",
      "|    total_timesteps  | 515439   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00626  |\n",
      "|    n_updates        | 116359   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-20.20 +/- 0.40\n",
      "Episode length: 1139.20 +/- 61.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 520000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00212  |\n",
      "|    n_updates        | 117499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.57e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 1567     |\n",
      "|    total_timesteps  | 521399   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00314  |\n",
      "|    n_updates        | 117849   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.56e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.375    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 1582     |\n",
      "|    total_timesteps  | 526700   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000994 |\n",
      "|    n_updates        | 119174   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=-19.60 +/- 1.02\n",
      "Episode length: 1827.40 +/- 146.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.83e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.371    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 530000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 119999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.56e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.367    |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 1608     |\n",
      "|    total_timesteps  | 532988   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0047   |\n",
      "|    n_updates        | 120746   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.56e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.36     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 331      |\n",
      "|    time_elapsed     | 1624     |\n",
      "|    total_timesteps  | 538583   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000877 |\n",
      "|    n_updates        | 122145   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=-20.00 +/- 1.10\n",
      "Episode length: 1170.60 +/- 106.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.359    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 540000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 122499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.55e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 1645     |\n",
      "|    total_timesteps  | 544359   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 123589   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.54e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.348    |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 1659     |\n",
      "|    total_timesteps  | 549223   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00344  |\n",
      "|    n_updates        | 124805   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=550000, episode_reward=-20.40 +/- 0.80\n",
      "Episode length: 1246.80 +/- 187.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.25e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 550000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00636  |\n",
      "|    n_updates        | 124999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.54e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.341    |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 1681     |\n",
      "|    total_timesteps  | 554995   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000916 |\n",
      "|    n_updates        | 126248   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-18.60 +/- 0.49\n",
      "Episode length: 1646.20 +/- 153.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.65e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 560000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00298  |\n",
      "|    n_updates        | 127499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.54e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.334    |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 1706     |\n",
      "|    total_timesteps  | 561178   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00617  |\n",
      "|    n_updates        | 127794   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.55e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.325    |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 1726     |\n",
      "|    total_timesteps  | 568131   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 129532   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=-19.40 +/- 1.20\n",
      "Episode length: 1526.80 +/- 124.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.53e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.323    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 570000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00538  |\n",
      "|    n_updates        | 129999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.55e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.318    |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 1750     |\n",
      "|    total_timesteps  | 574513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00227  |\n",
      "|    n_updates        | 131128   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=-19.20 +/- 1.33\n",
      "Episode length: 1949.60 +/- 261.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.95e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 580000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 132499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.55e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.309    |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 326      |\n",
      "|    time_elapsed     | 1779     |\n",
      "|    total_timesteps  | 581643   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 132910   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.54e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 1799     |\n",
      "|    total_timesteps  | 588462   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 134615   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=-18.60 +/- 0.49\n",
      "Episode length: 1979.60 +/- 168.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.98e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 590000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 134999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.54e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 325      |\n",
      "|    time_elapsed     | 1828     |\n",
      "|    total_timesteps  | 595582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 136395   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=-17.20 +/- 1.17\n",
      "Episode length: 2536.80 +/- 203.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.54e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 600000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00827  |\n",
      "|    n_updates        | 137499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.56e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.282    |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 324      |\n",
      "|    time_elapsed     | 1864     |\n",
      "|    total_timesteps  | 604346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00439  |\n",
      "|    n_updates        | 138586   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=-18.40 +/- 0.49\n",
      "Episode length: 2132.20 +/- 264.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.13e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 610000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 139999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.57e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.273    |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 322      |\n",
      "|    time_elapsed     | 1896     |\n",
      "|    total_timesteps  | 612253   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.002    |\n",
      "|    n_updates        | 140563   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.264    |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 323      |\n",
      "|    time_elapsed     | 1918     |\n",
      "|    total_timesteps  | 619615   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 142403   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=-17.80 +/- 1.17\n",
      "Episode length: 2204.60 +/- 435.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.2e+03  |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.264    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 620000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 142499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 321      |\n",
      "|    time_elapsed     | 1948     |\n",
      "|    total_timesteps  | 626949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 144237   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=-19.60 +/- 0.49\n",
      "Episode length: 1872.80 +/- 226.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.87e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.252    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 630000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00606  |\n",
      "|    n_updates        | 144999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.245    |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 320      |\n",
      "|    time_elapsed     | 1981     |\n",
      "|    total_timesteps  | 635448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 146361   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-19.80 +/- 1.94\n",
      "Episode length: 1332.20 +/- 325.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.33e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 640000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 147499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.62e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.236    |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 319      |\n",
      "|    time_elapsed     | 2010     |\n",
      "|    total_timesteps  | 643313   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00827  |\n",
      "|    n_updates        | 148328   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.63e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.228    |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 320      |\n",
      "|    time_elapsed     | 2029     |\n",
      "|    total_timesteps  | 649871   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 149967   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=-20.00 +/- 0.63\n",
      "Episode length: 1363.40 +/- 84.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.36e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.228    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 650000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00376  |\n",
      "|    n_updates        | 149999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.63e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 319      |\n",
      "|    time_elapsed     | 2052     |\n",
      "|    total_timesteps  | 655738   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 151434   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=-17.20 +/- 1.72\n",
      "Episode length: 2501.40 +/- 452.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.5e+03  |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.216    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 660000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00314  |\n",
      "|    n_updates        | 152499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.212    |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 317      |\n",
      "|    time_elapsed     | 2087     |\n",
      "|    total_timesteps  | 663708   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 153426   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=-18.40 +/- 1.85\n",
      "Episode length: 2274.40 +/- 390.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.204    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 670000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00285  |\n",
      "|    n_updates        | 154999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.202    |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 316      |\n",
      "|    time_elapsed     | 2122     |\n",
      "|    total_timesteps  | 672153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00593  |\n",
      "|    n_updates        | 155538   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=-19.80 +/- 0.98\n",
      "Episode length: 1931.20 +/- 318.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.93e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.193    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 680000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 157499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.19     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 315      |\n",
      "|    time_elapsed     | 2159     |\n",
      "|    total_timesteps  | 681814   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00175  |\n",
      "|    n_updates        | 157953   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 312      |\n",
      "|    time_elapsed     | 2204     |\n",
      "|    total_timesteps  | 689930   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00321  |\n",
      "|    n_updates        | 159982   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=-17.60 +/- 1.36\n",
      "Episode length: 2092.20 +/- 293.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.09e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 690000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00505  |\n",
      "|    n_updates        | 159999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.171    |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 309      |\n",
      "|    time_elapsed     | 2253     |\n",
      "|    total_timesteps  | 698279   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00239  |\n",
      "|    n_updates        | 162069   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=-15.40 +/- 1.50\n",
      "Episode length: 2213.40 +/- 196.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.169    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 700000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0034   |\n",
      "|    n_updates        | 162499   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 308      |\n",
      "|    time_elapsed     | 2282     |\n",
      "|    total_timesteps  | 704258   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00468  |\n",
      "|    n_updates        | 163564   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.157    |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 308      |\n",
      "|    time_elapsed     | 2300     |\n",
      "|    total_timesteps  | 709987   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 164996   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=-19.80 +/- 1.17\n",
      "Episode length: 1348.60 +/- 160.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.35e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.157    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 710000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00595  |\n",
      "|    n_updates        | 164999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.149    |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 308      |\n",
      "|    time_elapsed     | 2327     |\n",
      "|    total_timesteps  | 716750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 166687   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=-15.80 +/- 0.75\n",
      "Episode length: 2067.40 +/- 164.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.07e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 720000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 167499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.138    |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 306      |\n",
      "|    time_elapsed     | 2364     |\n",
      "|    total_timesteps  | 725851   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 168962   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=-18.20 +/- 2.40\n",
      "Episode length: 1753.20 +/- 300.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.75e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.133    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 730000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00446  |\n",
      "|    n_updates        | 169999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.85e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.128    |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 306      |\n",
      "|    time_elapsed     | 2398     |\n",
      "|    total_timesteps  | 734049   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00362  |\n",
      "|    n_updates        | 171012   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=-16.20 +/- 2.23\n",
      "Episode length: 2097.20 +/- 172.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.1e+03  |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.121    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 740000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 172499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.87e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.119    |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 305      |\n",
      "|    time_elapsed     | 2432     |\n",
      "|    total_timesteps  | 741939   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 172984   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=-18.40 +/- 1.02\n",
      "Episode length: 1850.40 +/- 143.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.85e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.109    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 750000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00406  |\n",
      "|    n_updates        | 174999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.91e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.107    |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 304      |\n",
      "|    time_elapsed     | 2471     |\n",
      "|    total_timesteps  | 751798   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 175449   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.0977   |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 304      |\n",
      "|    time_elapsed     | 2496     |\n",
      "|    total_timesteps  | 759810   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 177452   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=-17.20 +/- 1.17\n",
      "Episode length: 2275.20 +/- 139.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.28e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0975   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 760000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00449  |\n",
      "|    n_updates        | 177499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.0877   |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 303      |\n",
      "|    time_elapsed     | 2532     |\n",
      "|    total_timesteps  | 768218   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 179554   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=-16.60 +/- 1.36\n",
      "Episode length: 2045.80 +/- 131.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.05e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 770000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 179999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.0754   |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 302      |\n",
      "|    time_elapsed     | 2575     |\n",
      "|    total_timesteps  | 778596   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 182148   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=-17.60 +/- 1.02\n",
      "Episode length: 2231.60 +/- 152.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.23e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0738   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 780000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 182499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.0631   |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 301      |\n",
      "|    time_elapsed     | 2618     |\n",
      "|    total_timesteps  | 788951   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 184737   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=-16.60 +/- 1.02\n",
      "Episode length: 2124.60 +/- 210.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.12e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0619   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 790000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00553  |\n",
      "|    n_updates        | 184999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.0518   |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 300      |\n",
      "|    time_elapsed     | 2656     |\n",
      "|    total_timesteps  | 798524   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00255  |\n",
      "|    n_updates        | 187130   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=-16.20 +/- 2.14\n",
      "Episode length: 2253.40 +/- 166.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.25e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 800000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0021   |\n",
      "|    n_updates        | 187499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 299      |\n",
      "|    time_elapsed     | 2698     |\n",
      "|    total_timesteps  | 809310   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00541  |\n",
      "|    n_updates        | 189827   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=-17.40 +/- 1.02\n",
      "Episode length: 2225.00 +/- 285.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.22e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 810000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 189999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 299      |\n",
      "|    time_elapsed     | 2735     |\n",
      "|    total_timesteps  | 818362   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 192090   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=-17.00 +/- 1.79\n",
      "Episode length: 2220.80 +/- 168.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.22e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 820000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000847 |\n",
      "|    n_updates        | 192499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 298      |\n",
      "|    time_elapsed     | 2775     |\n",
      "|    total_timesteps  | 828344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00422  |\n",
      "|    n_updates        | 194585   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=-14.80 +/- 1.17\n",
      "Episode length: 2013.00 +/- 140.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.01e+03 |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 830000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 194999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 297      |\n",
      "|    time_elapsed     | 2809     |\n",
      "|    total_timesteps  | 836729   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 196682   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=-16.40 +/- 1.62\n",
      "Episode length: 2198.60 +/- 168.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.2e+03  |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 840000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 197499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 297      |\n",
      "|    time_elapsed     | 2846     |\n",
      "|    total_timesteps  | 845857   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00471  |\n",
      "|    n_updates        | 198964   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=-16.60 +/- 2.06\n",
      "Episode length: 1891.00 +/- 107.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.89e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 850000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 199999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 296      |\n",
      "|    time_elapsed     | 2880     |\n",
      "|    total_timesteps  | 854195   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0309   |\n",
      "|    n_updates        | 201048   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=-17.40 +/- 0.80\n",
      "Episode length: 2175.80 +/- 138.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.18e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 860000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 202499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 295      |\n",
      "|    time_elapsed     | 2918     |\n",
      "|    total_timesteps  | 863845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00658  |\n",
      "|    n_updates        | 203461   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=-17.20 +/- 1.17\n",
      "Episode length: 2127.40 +/- 205.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.13e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 870000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00435  |\n",
      "|    n_updates        | 204999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 295      |\n",
      "|    time_elapsed     | 2951     |\n",
      "|    total_timesteps  | 871826   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00206  |\n",
      "|    n_updates        | 205456   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=-15.40 +/- 1.50\n",
      "Episode length: 2270.00 +/- 239.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 880000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 207499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 294      |\n",
      "|    time_elapsed     | 2991     |\n",
      "|    total_timesteps  | 881614   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 207903   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 295      |\n",
      "|    time_elapsed     | 3016     |\n",
      "|    total_timesteps  | 889932   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00481  |\n",
      "|    n_updates        | 209982   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=-17.00 +/- 1.90\n",
      "Episode length: 2015.40 +/- 169.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.02e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 890000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00529  |\n",
      "|    n_updates        | 209999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 294      |\n",
      "|    time_elapsed     | 3050     |\n",
      "|    total_timesteps  | 898280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 212069   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=-16.40 +/- 2.15\n",
      "Episode length: 2046.00 +/- 376.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.05e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 900000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00689  |\n",
      "|    n_updates        | 212499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 293      |\n",
      "|    time_elapsed     | 3085     |\n",
      "|    total_timesteps  | 906996   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 214248   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=910000, episode_reward=-18.00 +/- 0.00\n",
      "Episode length: 1631.00 +/- 113.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.63e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 910000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 214999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 293      |\n",
      "|    time_elapsed     | 3116     |\n",
      "|    total_timesteps  | 914886   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 216221   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=-16.60 +/- 1.85\n",
      "Episode length: 2025.20 +/- 232.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.03e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 920000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 217499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 293      |\n",
      "|    time_elapsed     | 3151     |\n",
      "|    total_timesteps  | 923509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00281  |\n",
      "|    n_updates        | 218377   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=-16.60 +/- 1.36\n",
      "Episode length: 1920.80 +/- 140.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.92e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 930000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00242  |\n",
      "|    n_updates        | 219999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 292      |\n",
      "|    time_elapsed     | 3183     |\n",
      "|    total_timesteps  | 931632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 220407   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 292      |\n",
      "|    time_elapsed     | 3203     |\n",
      "|    total_timesteps  | 938237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00322  |\n",
      "|    n_updates        | 222059   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=-17.20 +/- 0.75\n",
      "Episode length: 1897.80 +/- 87.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.9e+03  |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 940000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 222499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 292      |\n",
      "|    time_elapsed     | 3240     |\n",
      "|    total_timesteps  | 947625   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00789  |\n",
      "|    n_updates        | 224406   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=-16.20 +/- 1.94\n",
      "Episode length: 2050.80 +/- 275.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.05e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 950000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 224999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 291      |\n",
      "|    time_elapsed     | 3274     |\n",
      "|    total_timesteps  | 956002   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 226500   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=-17.00 +/- 0.89\n",
      "Episode length: 1794.40 +/- 188.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.79e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 960000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 227499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 291      |\n",
      "|    time_elapsed     | 3304     |\n",
      "|    total_timesteps  | 963322   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 228330   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=-15.80 +/- 2.04\n",
      "Episode length: 2158.00 +/- 170.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.16e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 970000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00893  |\n",
      "|    n_updates        | 229999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 291      |\n",
      "|    time_elapsed     | 3339     |\n",
      "|    total_timesteps  | 971869   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00221  |\n",
      "|    n_updates        | 230467   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=-15.20 +/- 2.93\n",
      "Episode length: 2294.20 +/- 424.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.29e+03 |\n",
      "|    mean_reward      | -15.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 980000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 232499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 290      |\n",
      "|    time_elapsed     | 3381     |\n",
      "|    total_timesteps  | 982618   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 233154   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=-17.80 +/- 2.40\n",
      "Episode length: 1844.60 +/- 247.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.84e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 990000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00503  |\n",
      "|    n_updates        | 234999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 290      |\n",
      "|    time_elapsed     | 3417     |\n",
      "|    total_timesteps  | 991975   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00405  |\n",
      "|    n_updates        | 235493   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 290      |\n",
      "|    time_elapsed     | 3441     |\n",
      "|    total_timesteps  | 999857   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 237464   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=-14.00 +/- 2.53\n",
      "Episode length: 2391.80 +/- 293.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.39e+03 |\n",
      "|    mean_reward      | -14      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00254  |\n",
      "|    n_updates        | 237499   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 289      |\n",
      "|    time_elapsed     | 3480     |\n",
      "|    total_timesteps  | 1009153  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00373  |\n",
      "|    n_updates        | 239788   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=-15.60 +/- 1.50\n",
      "Episode length: 2218.20 +/- 187.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.22e+03 |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 239999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=-16.80 +/- 0.40\n",
      "Episode length: 2333.20 +/- 212.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.33e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00619  |\n",
      "|    n_updates        | 242499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 288      |\n",
      "|    time_elapsed     | 3538     |\n",
      "|    total_timesteps  | 1021953  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00327  |\n",
      "|    n_updates        | 242988   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1030000, episode_reward=-16.20 +/- 1.47\n",
      "Episode length: 2428.40 +/- 207.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.43e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 244999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 288      |\n",
      "|    time_elapsed     | 3581     |\n",
      "|    total_timesteps  | 1032708  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 245676   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=-16.80 +/- 1.17\n",
      "Episode length: 2117.40 +/- 181.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.12e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 247499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 287      |\n",
      "|    time_elapsed     | 3616     |\n",
      "|    total_timesteps  | 1041463  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 247865   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 288      |\n",
      "|    time_elapsed     | 3641     |\n",
      "|    total_timesteps  | 1049823  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 249955   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=-14.80 +/- 2.32\n",
      "Episode length: 2317.00 +/- 269.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.32e+03 |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00207  |\n",
      "|    n_updates        | 249999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 287      |\n",
      "|    time_elapsed     | 3677     |\n",
      "|    total_timesteps  | 1058513  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 252128   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1060000, episode_reward=-16.20 +/- 1.72\n",
      "Episode length: 2141.80 +/- 86.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 252499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 287      |\n",
      "|    time_elapsed     | 3715     |\n",
      "|    total_timesteps  | 1067931  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 254482   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1070000, episode_reward=-19.40 +/- 1.36\n",
      "Episode length: 1548.20 +/- 369.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.55e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 254999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 287      |\n",
      "|    time_elapsed     | 3743     |\n",
      "|    total_timesteps  | 1074804  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 256200   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=-18.20 +/- 1.47\n",
      "Episode length: 2045.40 +/- 58.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.05e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 257499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 286      |\n",
      "|    time_elapsed     | 3774     |\n",
      "|    total_timesteps  | 1082185  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00292  |\n",
      "|    n_updates        | 258046   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1090000, episode_reward=-18.20 +/- 1.17\n",
      "Episode length: 1592.00 +/- 187.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.59e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 259999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 286      |\n",
      "|    time_elapsed     | 3810     |\n",
      "|    total_timesteps  | 1091994  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 260498   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 286      |\n",
      "|    time_elapsed     | 3831     |\n",
      "|    total_timesteps  | 1098772  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 262192   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=-14.40 +/- 2.24\n",
      "Episode length: 2379.80 +/- 216.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.38e+03 |\n",
      "|    mean_reward      | -14.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 262499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 286      |\n",
      "|    time_elapsed     | 3871     |\n",
      "|    total_timesteps  | 1108805  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00432  |\n",
      "|    n_updates        | 264701   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=-13.40 +/- 3.77\n",
      "Episode length: 2782.60 +/- 327.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.78e+03 |\n",
      "|    mean_reward      | -13.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 264999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 285      |\n",
      "|    time_elapsed     | 3912     |\n",
      "|    total_timesteps  | 1118309  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 267077   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=-16.40 +/- 1.20\n",
      "Episode length: 1957.40 +/- 155.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.96e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 267499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 285      |\n",
      "|    time_elapsed     | 3952     |\n",
      "|    total_timesteps  | 1128632  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 269657   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1130000, episode_reward=-17.80 +/- 1.60\n",
      "Episode length: 1859.00 +/- 118.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.86e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00738  |\n",
      "|    n_updates        | 269999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 285      |\n",
      "|    time_elapsed     | 3986     |\n",
      "|    total_timesteps  | 1137493  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00629  |\n",
      "|    n_updates        | 271873   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1140000, episode_reward=-18.00 +/- 0.63\n",
      "Episode length: 1728.00 +/- 196.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.73e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 272499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 285      |\n",
      "|    time_elapsed     | 4018     |\n",
      "|    total_timesteps  | 1145478  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 273869   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1051.40 +/- 16.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.05e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 274999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 284      |\n",
      "|    time_elapsed     | 4042     |\n",
      "|    total_timesteps  | 1152117  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 275529   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 285      |\n",
      "|    time_elapsed     | 4061     |\n",
      "|    total_timesteps  | 1158480  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00536  |\n",
      "|    n_updates        | 277119   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=-18.80 +/- 0.40\n",
      "Episode length: 1677.80 +/- 134.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.68e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 277499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 285      |\n",
      "|    time_elapsed     | 4095     |\n",
      "|    total_timesteps  | 1167333  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 279333   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1170000, episode_reward=-18.00 +/- 1.10\n",
      "Episode length: 1727.40 +/- 84.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.73e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 279999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 284      |\n",
      "|    time_elapsed     | 4126     |\n",
      "|    total_timesteps  | 1174978  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00702  |\n",
      "|    n_updates        | 281244   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=-17.20 +/- 1.17\n",
      "Episode length: 1932.40 +/- 186.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.93e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00233  |\n",
      "|    n_updates        | 282499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 284      |\n",
      "|    time_elapsed     | 4161     |\n",
      "|    total_timesteps  | 1183938  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0021   |\n",
      "|    n_updates        | 283484   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 284      |\n",
      "|    time_elapsed     | 4178     |\n",
      "|    total_timesteps  | 1189352  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 284837   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1190000, episode_reward=-18.80 +/- 0.98\n",
      "Episode length: 1724.00 +/- 158.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.72e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 284999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 284      |\n",
      "|    time_elapsed     | 4210     |\n",
      "|    total_timesteps  | 1197730  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 286932   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=-17.20 +/- 0.75\n",
      "Episode length: 1823.60 +/- 188.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.82e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00358  |\n",
      "|    n_updates        | 287499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 284      |\n",
      "|    time_elapsed     | 4252     |\n",
      "|    total_timesteps  | 1208895  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00607  |\n",
      "|    n_updates        | 289723   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1210000, episode_reward=-19.20 +/- 1.33\n",
      "Episode length: 1360.80 +/- 180.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.36e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00943  |\n",
      "|    n_updates        | 289999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 284      |\n",
      "|    time_elapsed     | 4278     |\n",
      "|    total_timesteps  | 1215560  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 291389   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=-18.80 +/- 2.14\n",
      "Episode length: 1635.20 +/- 458.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.64e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00217  |\n",
      "|    n_updates        | 292499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 283      |\n",
      "|    time_elapsed     | 4309     |\n",
      "|    total_timesteps  | 1223527  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00382  |\n",
      "|    n_updates        | 293381   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=-16.60 +/- 2.42\n",
      "Episode length: 2179.40 +/- 287.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.18e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 294999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 283      |\n",
      "|    time_elapsed     | 4344     |\n",
      "|    total_timesteps  | 1231955  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00357  |\n",
      "|    n_updates        | 295488   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 283      |\n",
      "|    time_elapsed     | 4368     |\n",
      "|    total_timesteps  | 1239936  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00331  |\n",
      "|    n_updates        | 297483   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=-17.40 +/- 1.85\n",
      "Episode length: 2212.20 +/- 421.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 297499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 283      |\n",
      "|    time_elapsed     | 4402     |\n",
      "|    total_timesteps  | 1247886  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00278  |\n",
      "|    n_updates        | 299471   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=-15.80 +/- 2.32\n",
      "Episode length: 2320.60 +/- 432.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.32e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0052   |\n",
      "|    n_updates        | 299999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 283      |\n",
      "|    time_elapsed     | 4435     |\n",
      "|    total_timesteps  | 1255731  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 301432   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=-17.40 +/- 0.49\n",
      "Episode length: 2228.20 +/- 194.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.23e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 302499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 282      |\n",
      "|    time_elapsed     | 4469     |\n",
      "|    total_timesteps  | 1263696  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 303423   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1270000, episode_reward=-15.80 +/- 2.93\n",
      "Episode length: 2312.00 +/- 391.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.31e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 304999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 282      |\n",
      "|    time_elapsed     | 4509     |\n",
      "|    total_timesteps  | 1273688  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 305921   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1280000, episode_reward=-19.00 +/- 0.89\n",
      "Episode length: 2190.80 +/- 347.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.19e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000818 |\n",
      "|    n_updates        | 307499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 282      |\n",
      "|    time_elapsed     | 4544     |\n",
      "|    total_timesteps  | 1282049  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 308012   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 282      |\n",
      "|    time_elapsed     | 4565     |\n",
      "|    total_timesteps  | 1289167  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000629 |\n",
      "|    n_updates        | 309791   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1290000, episode_reward=-18.20 +/- 1.60\n",
      "Episode length: 1581.40 +/- 217.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.58e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 309999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 282      |\n",
      "|    time_elapsed     | 4595     |\n",
      "|    total_timesteps  | 1296642  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00354  |\n",
      "|    n_updates        | 311660   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=-17.40 +/- 1.36\n",
      "Episode length: 1711.80 +/- 268.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.71e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 312499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 282      |\n",
      "|    time_elapsed     | 4628     |\n",
      "|    total_timesteps  | 1305245  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 313811   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1310000, episode_reward=-18.20 +/- 1.60\n",
      "Episode length: 1660.40 +/- 211.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.66e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 314999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 281      |\n",
      "|    time_elapsed     | 4661     |\n",
      "|    total_timesteps  | 1313841  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 315960   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1320000, episode_reward=-17.00 +/- 1.26\n",
      "Episode length: 1866.60 +/- 139.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.87e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00234  |\n",
      "|    n_updates        | 317499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 281      |\n",
      "|    time_elapsed     | 4693     |\n",
      "|    total_timesteps  | 1321734  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00739  |\n",
      "|    n_updates        | 317933   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=-16.60 +/- 1.02\n",
      "Episode length: 2122.40 +/- 105.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.12e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00818  |\n",
      "|    n_updates        | 319999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 281      |\n",
      "|    time_elapsed     | 4733     |\n",
      "|    total_timesteps  | 1332085  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00395  |\n",
      "|    n_updates        | 320521   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=-15.60 +/- 2.42\n",
      "Episode length: 2047.40 +/- 351.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.05e+03 |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00233  |\n",
      "|    n_updates        | 322499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 281      |\n",
      "|    time_elapsed     | 4771     |\n",
      "|    total_timesteps  | 1341619  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 322904   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 281      |\n",
      "|    time_elapsed     | 4791     |\n",
      "|    total_timesteps  | 1348234  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 324558   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1350000, episode_reward=-17.60 +/- 1.50\n",
      "Episode length: 1698.60 +/- 202.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.7e+03  |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 324999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 281      |\n",
      "|    time_elapsed     | 4819     |\n",
      "|    total_timesteps  | 1355048  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 326261   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=-17.20 +/- 1.47\n",
      "Episode length: 1972.00 +/- 151.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.97e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 327499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 280      |\n",
      "|    time_elapsed     | 4853     |\n",
      "|    total_timesteps  | 1363491  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 328372   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1370000, episode_reward=-16.20 +/- 1.47\n",
      "Episode length: 2154.40 +/- 89.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.15e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00352  |\n",
      "|    n_updates        | 329999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 280      |\n",
      "|    time_elapsed     | 4889     |\n",
      "|    total_timesteps  | 1372339  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 330584   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=-15.40 +/- 1.50\n",
      "Episode length: 2244.80 +/- 236.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.24e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 332499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 280      |\n",
      "|    time_elapsed     | 4927     |\n",
      "|    total_timesteps  | 1382064  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00513  |\n",
      "|    n_updates        | 333015   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 280      |\n",
      "|    time_elapsed     | 4949     |\n",
      "|    total_timesteps  | 1389444  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00694  |\n",
      "|    n_updates        | 334860   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=-18.00 +/- 2.10\n",
      "Episode length: 1782.40 +/- 177.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.78e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00799  |\n",
      "|    n_updates        | 334999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 280      |\n",
      "|    time_elapsed     | 4983     |\n",
      "|    total_timesteps  | 1398162  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00455  |\n",
      "|    n_updates        | 337040   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=-17.40 +/- 1.36\n",
      "Episode length: 1885.40 +/- 140.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.89e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 337499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 280      |\n",
      "|    time_elapsed     | 5013     |\n",
      "|    total_timesteps  | 1405478  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00624  |\n",
      "|    n_updates        | 338869   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1410000, episode_reward=-16.20 +/- 1.72\n",
      "Episode length: 1997.80 +/- 153.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2e+03    |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 339999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 280      |\n",
      "|    time_elapsed     | 5047     |\n",
      "|    total_timesteps  | 1413741  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00284  |\n",
      "|    n_updates        | 340935   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=-16.80 +/- 2.14\n",
      "Episode length: 2087.80 +/- 242.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.09e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00509  |\n",
      "|    n_updates        | 342499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 279      |\n",
      "|    time_elapsed     | 5088     |\n",
      "|    total_timesteps  | 1424364  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00395  |\n",
      "|    n_updates        | 343590   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1430000, episode_reward=-16.60 +/- 1.36\n",
      "Episode length: 1889.60 +/- 187.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.89e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00793  |\n",
      "|    n_updates        | 344999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 279      |\n",
      "|    time_elapsed     | 5118     |\n",
      "|    total_timesteps  | 1431830  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 345457   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 279      |\n",
      "|    time_elapsed     | 5141     |\n",
      "|    total_timesteps  | 1439349  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 347337   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=-18.20 +/- 0.40\n",
      "Episode length: 1612.40 +/- 83.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.61e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00453  |\n",
      "|    n_updates        | 347499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 279      |\n",
      "|    time_elapsed     | 5172     |\n",
      "|    total_timesteps  | 1447274  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 349318   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1450000, episode_reward=-18.00 +/- 1.10\n",
      "Episode length: 1928.20 +/- 233.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.93e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00219  |\n",
      "|    n_updates        | 349999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 279      |\n",
      "|    time_elapsed     | 5207     |\n",
      "|    total_timesteps  | 1456176  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00376  |\n",
      "|    n_updates        | 351543   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=-19.00 +/- 1.41\n",
      "Episode length: 1953.00 +/- 229.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.95e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00175  |\n",
      "|    n_updates        | 352499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 279      |\n",
      "|    time_elapsed     | 5239     |\n",
      "|    total_timesteps  | 1464153  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00345  |\n",
      "|    n_updates        | 353538   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=-17.80 +/- 1.17\n",
      "Episode length: 2306.40 +/- 231.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.31e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00571  |\n",
      "|    n_updates        | 354999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 279      |\n",
      "|    time_elapsed     | 5281     |\n",
      "|    total_timesteps  | 1474472  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00315  |\n",
      "|    n_updates        | 356117   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=-15.20 +/- 1.72\n",
      "Episode length: 2277.40 +/- 247.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.28e+03 |\n",
      "|    mean_reward      | -15.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 357499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 279      |\n",
      "|    time_elapsed     | 5322     |\n",
      "|    total_timesteps  | 1485106  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 358776   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=-16.80 +/- 3.12\n",
      "Episode length: 2029.80 +/- 394.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.03e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 359999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 278      |\n",
      "|    time_elapsed     | 5357     |\n",
      "|    total_timesteps  | 1493594  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 360898   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1500000, episode_reward=-14.20 +/- 2.32\n",
      "Episode length: 2278.80 +/- 294.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.28e+03 |\n",
      "|    mean_reward      | -14.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 362499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 278      |\n",
      "|    time_elapsed     | 5397     |\n",
      "|    total_timesteps  | 1503745  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 363436   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=-18.40 +/- 1.36\n",
      "Episode length: 2240.80 +/- 62.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.24e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 364999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 278      |\n",
      "|    time_elapsed     | 5438     |\n",
      "|    total_timesteps  | 1514127  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 366031   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=-17.40 +/- 1.85\n",
      "Episode length: 1816.60 +/- 246.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.82e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 367499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 278      |\n",
      "|    time_elapsed     | 5469     |\n",
      "|    total_timesteps  | 1521945  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 367986   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 278      |\n",
      "|    time_elapsed     | 5493     |\n",
      "|    total_timesteps  | 1529986  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00323  |\n",
      "|    n_updates        | 369996   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=-17.40 +/- 1.96\n",
      "Episode length: 1864.80 +/- 238.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.86e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00441  |\n",
      "|    n_updates        | 369999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 278      |\n",
      "|    time_elapsed     | 5527     |\n",
      "|    total_timesteps  | 1538381  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 372095   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=-15.80 +/- 2.32\n",
      "Episode length: 2211.00 +/- 128.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00278  |\n",
      "|    n_updates        | 372499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 278      |\n",
      "|    time_elapsed     | 5565     |\n",
      "|    total_timesteps  | 1547999  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.004    |\n",
      "|    n_updates        | 374499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1550000, episode_reward=-17.80 +/- 1.17\n",
      "Episode length: 2007.40 +/- 190.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.01e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 374999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 278      |\n",
      "|    time_elapsed     | 5604     |\n",
      "|    total_timesteps  | 1557988  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00342  |\n",
      "|    n_updates        | 376996   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=-20.20 +/- 0.98\n",
      "Episode length: 1296.40 +/- 227.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.3e+03  |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00282  |\n",
      "|    n_updates        | 377499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5635     |\n",
      "|    total_timesteps  | 1566419  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00335  |\n",
      "|    n_updates        | 379104   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=-19.20 +/- 0.75\n",
      "Episode length: 1447.20 +/- 104.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.45e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 379999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5664     |\n",
      "|    total_timesteps  | 1573976  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 380993   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=-17.00 +/- 2.61\n",
      "Episode length: 2125.00 +/- 234.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.12e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00336  |\n",
      "|    n_updates        | 382499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5703     |\n",
      "|    total_timesteps  | 1583926  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 383481   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1590000, episode_reward=-15.80 +/- 2.04\n",
      "Episode length: 2109.40 +/- 221.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.11e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00932  |\n",
      "|    n_updates        | 384999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5737     |\n",
      "|    total_timesteps  | 1592139  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 385534   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5757     |\n",
      "|    total_timesteps  | 1598935  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0045   |\n",
      "|    n_updates        | 387233   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=-18.80 +/- 0.40\n",
      "Episode length: 1649.20 +/- 228.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.65e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 387499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5786     |\n",
      "|    total_timesteps  | 1606080  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 389019   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=-18.40 +/- 1.36\n",
      "Episode length: 1626.40 +/- 186.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.63e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 389999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5814     |\n",
      "|    total_timesteps  | 1613251  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00537  |\n",
      "|    n_updates        | 390812   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=-16.60 +/- 1.02\n",
      "Episode length: 2116.40 +/- 102.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.12e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 392499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5855     |\n",
      "|    total_timesteps  | 1623809  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 393452   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=-18.00 +/- 1.41\n",
      "Episode length: 1685.40 +/- 146.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.69e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 394999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5891     |\n",
      "|    total_timesteps  | 1633325  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 395831   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5911     |\n",
      "|    total_timesteps  | 1639751  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00366  |\n",
      "|    n_updates        | 397437   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=-20.60 +/- 0.80\n",
      "Episode length: 1123.60 +/- 89.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0068   |\n",
      "|    n_updates        | 397499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5935     |\n",
      "|    total_timesteps  | 1646266  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 399066   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=-15.00 +/- 1.79\n",
      "Episode length: 2292.20 +/- 167.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.29e+03 |\n",
      "|    mean_reward      | -15      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 399999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 5976     |\n",
      "|    total_timesteps  | 1656492  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 401622   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1660000, episode_reward=-15.40 +/- 2.58\n",
      "Episode length: 2232.20 +/- 316.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.23e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 402499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6015     |\n",
      "|    total_timesteps  | 1666334  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 404083   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1670000, episode_reward=-17.00 +/- 1.26\n",
      "Episode length: 2143.00 +/- 170.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 404999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6053     |\n",
      "|    total_timesteps  | 1675709  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 406427   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1680000, episode_reward=-17.00 +/- 0.63\n",
      "Episode length: 1978.00 +/- 118.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.98e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00459  |\n",
      "|    n_updates        | 407499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6094     |\n",
      "|    total_timesteps  | 1686613  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00532  |\n",
      "|    n_updates        | 409153   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1690000, episode_reward=-17.60 +/- 1.02\n",
      "Episode length: 2128.80 +/- 213.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.13e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00358  |\n",
      "|    n_updates        | 409999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6129     |\n",
      "|    total_timesteps  | 1695164  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 411290   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=-19.40 +/- 1.36\n",
      "Episode length: 1542.60 +/- 193.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.54e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00362  |\n",
      "|    n_updates        | 412499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6161     |\n",
      "|    total_timesteps  | 1703339  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00349  |\n",
      "|    n_updates        | 413334   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1710000, episode_reward=-18.20 +/- 2.14\n",
      "Episode length: 2306.00 +/- 290.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.31e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 414999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6198     |\n",
      "|    total_timesteps  | 1712336  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00432  |\n",
      "|    n_updates        | 415583   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1720000, episode_reward=-18.40 +/- 2.15\n",
      "Episode length: 2374.60 +/- 156.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.37e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 417499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6237     |\n",
      "|    total_timesteps  | 1721825  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 417956   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6261     |\n",
      "|    total_timesteps  | 1729702  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 419925   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1730000, episode_reward=-18.00 +/- 1.10\n",
      "Episode length: 2134.60 +/- 136.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.13e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 419999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6293     |\n",
      "|    total_timesteps  | 1737432  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00758  |\n",
      "|    n_updates        | 421857   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1740000, episode_reward=-18.80 +/- 0.75\n",
      "Episode length: 1652.40 +/- 237.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.65e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 422499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6327     |\n",
      "|    total_timesteps  | 1746278  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00333  |\n",
      "|    n_updates        | 424069   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1750000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1168.40 +/- 111.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 424999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6352     |\n",
      "|    total_timesteps  | 1753079  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00254  |\n",
      "|    n_updates        | 425769   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1760000, episode_reward=-17.20 +/- 0.98\n",
      "Episode length: 2030.00 +/- 192.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.03e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 427499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6388     |\n",
      "|    total_timesteps  | 1761989  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 427997   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 6411     |\n",
      "|    total_timesteps  | 1769485  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 429871   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1770000, episode_reward=-17.20 +/- 1.17\n",
      "Episode length: 1988.80 +/- 84.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.99e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 429999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6442     |\n",
      "|    total_timesteps  | 1777048  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00339  |\n",
      "|    n_updates        | 431761   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1780000, episode_reward=-19.40 +/- 1.02\n",
      "Episode length: 1484.20 +/- 132.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.48e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00362  |\n",
      "|    n_updates        | 432499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6471     |\n",
      "|    total_timesteps  | 1784596  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00726  |\n",
      "|    n_updates        | 433648   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1790000, episode_reward=-20.20 +/- 0.75\n",
      "Episode length: 1236.40 +/- 16.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0088   |\n",
      "|    n_updates        | 434999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6498     |\n",
      "|    total_timesteps  | 1791629  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 435407   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6520     |\n",
      "|    total_timesteps  | 1799066  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 437266   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=-17.20 +/- 1.47\n",
      "Episode length: 1899.60 +/- 245.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.9e+03  |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 437499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6553     |\n",
      "|    total_timesteps  | 1807131  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00495  |\n",
      "|    n_updates        | 439282   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1810000, episode_reward=-15.80 +/- 2.71\n",
      "Episode length: 2068.60 +/- 324.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.07e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00278  |\n",
      "|    n_updates        | 439999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6583     |\n",
      "|    total_timesteps  | 1814323  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 441080   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1820000, episode_reward=-20.20 +/- 0.40\n",
      "Episode length: 1233.60 +/- 111.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 442499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6610     |\n",
      "|    total_timesteps  | 1821689  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00219  |\n",
      "|    n_updates        | 442922   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6634     |\n",
      "|    total_timesteps  | 1829638  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 444909   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1830000, episode_reward=-17.20 +/- 1.72\n",
      "Episode length: 2003.80 +/- 264.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2e+03    |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 444999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6667     |\n",
      "|    total_timesteps  | 1837593  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00676  |\n",
      "|    n_updates        | 446898   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=-16.40 +/- 1.85\n",
      "Episode length: 2027.20 +/- 151.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.03e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 447499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6700     |\n",
      "|    total_timesteps  | 1845836  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 448958   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1850000, episode_reward=-16.80 +/- 0.40\n",
      "Episode length: 1962.00 +/- 156.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.96e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000968 |\n",
      "|    n_updates        | 449999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6732     |\n",
      "|    total_timesteps  | 1853402  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00332  |\n",
      "|    n_updates        | 450850   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1860000, episode_reward=-16.20 +/- 1.60\n",
      "Episode length: 2148.60 +/- 134.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.15e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0081   |\n",
      "|    n_updates        | 452499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6766     |\n",
      "|    total_timesteps  | 1861820  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00629  |\n",
      "|    n_updates        | 452954   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6790     |\n",
      "|    total_timesteps  | 1869678  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00281  |\n",
      "|    n_updates        | 454919   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1870000, episode_reward=-17.00 +/- 1.67\n",
      "Episode length: 1953.00 +/- 172.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.95e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00352  |\n",
      "|    n_updates        | 454999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6814     |\n",
      "|    total_timesteps  | 1874837  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 456209   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1880000, episode_reward=-17.80 +/- 0.98\n",
      "Episode length: 1563.00 +/- 93.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.56e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 457499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6847     |\n",
      "|    total_timesteps  | 1883575  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00644  |\n",
      "|    n_updates        | 458393   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1890000, episode_reward=-16.80 +/- 2.48\n",
      "Episode length: 1921.60 +/- 267.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.92e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0029   |\n",
      "|    n_updates        | 459999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 6878     |\n",
      "|    total_timesteps  | 1891128  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00865  |\n",
      "|    n_updates        | 460281   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 6892     |\n",
      "|    total_timesteps  | 1895744  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 461435   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1900000, episode_reward=-17.00 +/- 1.55\n",
      "Episode length: 2043.40 +/- 203.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.04e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00402  |\n",
      "|    n_updates        | 462499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 6926     |\n",
      "|    total_timesteps  | 1903999  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 463499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1910000, episode_reward=-16.40 +/- 1.96\n",
      "Episode length: 2183.20 +/- 172.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.18e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 464999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 6964     |\n",
      "|    total_timesteps  | 1913398  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 465849   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=-18.00 +/- 1.79\n",
      "Episode length: 2013.20 +/- 280.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.01e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 467499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 6997     |\n",
      "|    total_timesteps  | 1921505  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00612  |\n",
      "|    n_updates        | 467876   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.89e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 7013     |\n",
      "|    total_timesteps  | 1926825  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00268  |\n",
      "|    n_updates        | 469206   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1930000, episode_reward=-18.40 +/- 1.02\n",
      "Episode length: 1867.20 +/- 153.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.87e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00568  |\n",
      "|    n_updates        | 469999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.88e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 7043     |\n",
      "|    total_timesteps  | 1934078  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 471019   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1940000, episode_reward=-17.20 +/- 0.98\n",
      "Episode length: 2307.20 +/- 269.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.31e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00489  |\n",
      "|    n_updates        | 472499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.89e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 7077     |\n",
      "|    total_timesteps  | 1942287  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0045   |\n",
      "|    n_updates        | 473071   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1950000, episode_reward=-16.40 +/- 2.24\n",
      "Episode length: 2013.40 +/- 186.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.01e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 474999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 7114     |\n",
      "|    total_timesteps  | 1951805  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00521  |\n",
      "|    n_updates        | 475451   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 7137     |\n",
      "|    total_timesteps  | 1959416  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 477353   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1960000, episode_reward=-16.40 +/- 0.49\n",
      "Episode length: 1970.40 +/- 25.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.97e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00363  |\n",
      "|    n_updates        | 477499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 7169     |\n",
      "|    total_timesteps  | 1967200  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00317  |\n",
      "|    n_updates        | 479299   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1970000, episode_reward=-18.20 +/- 0.75\n",
      "Episode length: 1936.60 +/- 167.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.94e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00359  |\n",
      "|    n_updates        | 479999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 7205     |\n",
      "|    total_timesteps  | 1976352  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00213  |\n",
      "|    n_updates        | 481587   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1980000, episode_reward=-16.20 +/- 1.17\n",
      "Episode length: 2295.80 +/- 249.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.3e+03  |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 482499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 7243     |\n",
      "|    total_timesteps  | 1985739  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 483934   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1990000, episode_reward=-16.80 +/- 1.33\n",
      "Episode length: 1973.20 +/- 140.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.97e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00414  |\n",
      "|    n_updates        | 484999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 274      |\n",
      "|    time_elapsed     | 7277     |\n",
      "|    total_timesteps  | 1994226  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 486056   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2000000, episode_reward=-14.60 +/- 2.87\n",
      "Episode length: 2468.60 +/- 383.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.47e+03 |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00471  |\n",
      "|    n_updates        | 487499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7314     |\n",
      "|    total_timesteps  | 2002979  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00458  |\n",
      "|    n_updates        | 488244   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2010000, episode_reward=-16.00 +/- 1.41\n",
      "Episode length: 2145.20 +/- 233.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.15e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 489999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7352     |\n",
      "|    total_timesteps  | 2012448  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00468  |\n",
      "|    n_updates        | 490611   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7374     |\n",
      "|    total_timesteps  | 2019785  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 492446   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2020000, episode_reward=-16.60 +/- 0.80\n",
      "Episode length: 2037.60 +/- 240.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.04e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 492499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7411     |\n",
      "|    total_timesteps  | 2029156  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00712  |\n",
      "|    n_updates        | 494788   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2030000, episode_reward=-15.40 +/- 1.85\n",
      "Episode length: 2279.60 +/- 102.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.28e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 494999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7444     |\n",
      "|    total_timesteps  | 2037125  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 496781   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2040000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1097.20 +/- 41.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 497499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7475     |\n",
      "|    total_timesteps  | 2045634  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00352  |\n",
      "|    n_updates        | 498908   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2050000, episode_reward=-16.20 +/- 2.04\n",
      "Episode length: 2222.80 +/- 419.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.22e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00539  |\n",
      "|    n_updates        | 499999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7518     |\n",
      "|    total_timesteps  | 2056660  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00255  |\n",
      "|    n_updates        | 501664   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2060000, episode_reward=-15.40 +/- 2.42\n",
      "Episode length: 2350.60 +/- 349.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.35e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 502499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7555     |\n",
      "|    total_timesteps  | 2065789  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 503947   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2070000, episode_reward=-16.00 +/- 1.67\n",
      "Episode length: 2214.20 +/- 282.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0052   |\n",
      "|    n_updates        | 504999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7591     |\n",
      "|    total_timesteps  | 2074410  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 506102   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2080000, episode_reward=-18.00 +/- 1.10\n",
      "Episode length: 1887.60 +/- 143.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.89e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.002    |\n",
      "|    n_updates        | 507499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7620     |\n",
      "|    total_timesteps  | 2081480  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00357  |\n",
      "|    n_updates        | 507869   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7637     |\n",
      "|    total_timesteps  | 2086971  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 509242   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2090000, episode_reward=-19.40 +/- 1.36\n",
      "Episode length: 1788.60 +/- 126.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.79e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00343  |\n",
      "|    n_updates        | 509999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7675     |\n",
      "|    total_timesteps  | 2097203  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 511800   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2100000, episode_reward=-18.00 +/- 2.00\n",
      "Episode length: 1874.60 +/- 369.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.87e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00282  |\n",
      "|    n_updates        | 512499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7712     |\n",
      "|    total_timesteps  | 2106685  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 514171   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2110000, episode_reward=-18.20 +/- 1.60\n",
      "Episode length: 1655.80 +/- 199.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.66e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00344  |\n",
      "|    n_updates        | 514999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7745     |\n",
      "|    total_timesteps  | 2115309  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00462  |\n",
      "|    n_updates        | 516327   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2120000, episode_reward=-18.40 +/- 1.62\n",
      "Episode length: 1578.20 +/- 239.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.58e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 517499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7772     |\n",
      "|    total_timesteps  | 2121947  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 517986   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7796     |\n",
      "|    total_timesteps  | 2129897  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 519974   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2130000, episode_reward=-18.00 +/- 1.79\n",
      "Episode length: 1816.60 +/- 219.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.82e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 519999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 7826     |\n",
      "|    total_timesteps  | 2137404  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00534  |\n",
      "|    n_updates        | 521850   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2140000, episode_reward=-17.40 +/- 1.36\n",
      "Episode length: 2175.60 +/- 302.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.18e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 522499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 272      |\n",
      "|    time_elapsed     | 7860     |\n",
      "|    total_timesteps  | 2145701  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 523925   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2150000, episode_reward=-19.00 +/- 1.10\n",
      "Episode length: 1992.60 +/- 255.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.99e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00534  |\n",
      "|    n_updates        | 524999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 272      |\n",
      "|    time_elapsed     | 7894     |\n",
      "|    total_timesteps  | 2154128  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 526031   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2160000, episode_reward=-17.80 +/- 1.17\n",
      "Episode length: 2195.80 +/- 233.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.2e+03  |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0057   |\n",
      "|    n_updates        | 527499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 272      |\n",
      "|    time_elapsed     | 7925     |\n",
      "|    total_timesteps  | 2161258  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00336  |\n",
      "|    n_updates        | 527814   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2170000, episode_reward=-13.60 +/- 1.62\n",
      "Episode length: 2633.80 +/- 65.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.63e+03 |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 529999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 272      |\n",
      "|    time_elapsed     | 7971     |\n",
      "|    total_timesteps  | 2172894  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 530723   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2180000, episode_reward=-16.80 +/- 1.47\n",
      "Episode length: 1814.00 +/- 222.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.81e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00493  |\n",
      "|    n_updates        | 532499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 272      |\n",
      "|    time_elapsed     | 8007     |\n",
      "|    total_timesteps  | 2182057  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 533014   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2190000, episode_reward=-15.60 +/- 2.73\n",
      "Episode length: 2152.40 +/- 253.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.15e+03 |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 534999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 272      |\n",
      "|    time_elapsed     | 8048     |\n",
      "|    total_timesteps  | 2192598  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 535649   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 272      |\n",
      "|    time_elapsed     | 8062     |\n",
      "|    total_timesteps  | 2197402  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 536850   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2200000, episode_reward=-17.00 +/- 2.10\n",
      "Episode length: 2282.80 +/- 338.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.28e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00293  |\n",
      "|    n_updates        | 537499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 272      |\n",
      "|    time_elapsed     | 8098     |\n",
      "|    total_timesteps  | 2205897  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00207  |\n",
      "|    n_updates        | 538974   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2210000, episode_reward=-16.20 +/- 2.14\n",
      "Episode length: 2401.00 +/- 422.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.4e+03  |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 539999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 272      |\n",
      "|    time_elapsed     | 8141     |\n",
      "|    total_timesteps  | 2216728  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 541681   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2220000, episode_reward=-17.00 +/- 0.89\n",
      "Episode length: 2584.60 +/- 221.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.58e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 542499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 272      |\n",
      "|    time_elapsed     | 8183     |\n",
      "|    total_timesteps  | 2226943  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 544235   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2230000, episode_reward=-16.40 +/- 1.50\n",
      "Episode length: 2339.40 +/- 317.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.34e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00189  |\n",
      "|    n_updates        | 544999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8217     |\n",
      "|    total_timesteps  | 2234807  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 546201   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2240000, episode_reward=-17.80 +/- 1.60\n",
      "Episode length: 2209.80 +/- 202.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 547499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8253     |\n",
      "|    total_timesteps  | 2243558  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 548389   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2250000, episode_reward=-18.00 +/- 1.10\n",
      "Episode length: 1755.40 +/- 236.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.76e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 549999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8284     |\n",
      "|    total_timesteps  | 2251623  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00213  |\n",
      "|    n_updates        | 550405   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8307     |\n",
      "|    total_timesteps  | 2258982  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00339  |\n",
      "|    n_updates        | 552245   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2260000, episode_reward=-18.80 +/- 1.47\n",
      "Episode length: 2197.00 +/- 383.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.2e+03  |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 552499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8343     |\n",
      "|    total_timesteps  | 2268090  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0032   |\n",
      "|    n_updates        | 554522   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2270000, episode_reward=-19.60 +/- 0.80\n",
      "Episode length: 1982.60 +/- 208.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.98e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 554999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8371     |\n",
      "|    total_timesteps  | 2274489  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0034   |\n",
      "|    n_updates        | 556122   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2280000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1183.20 +/- 61.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00289  |\n",
      "|    n_updates        | 557499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8396     |\n",
      "|    total_timesteps  | 2281058  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00503  |\n",
      "|    n_updates        | 557764   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8409     |\n",
      "|    total_timesteps  | 2285511  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 558877   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2290000, episode_reward=-19.00 +/- 1.10\n",
      "Episode length: 1565.60 +/- 247.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.57e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 559999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8437     |\n",
      "|    total_timesteps  | 2292335  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 560583   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2300000, episode_reward=-17.60 +/- 1.74\n",
      "Episode length: 1922.00 +/- 246.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.92e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 562499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8474     |\n",
      "|    total_timesteps  | 2301916  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00292  |\n",
      "|    n_updates        | 562978   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8490     |\n",
      "|    total_timesteps  | 2307354  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00449  |\n",
      "|    n_updates        | 564338   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2310000, episode_reward=-20.20 +/- 0.75\n",
      "Episode length: 1371.80 +/- 174.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.37e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00347  |\n",
      "|    n_updates        | 564999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1228     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8515     |\n",
      "|    total_timesteps  | 2313670  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 565917   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2320000, episode_reward=-16.80 +/- 1.94\n",
      "Episode length: 1973.60 +/- 133.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.97e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00292  |\n",
      "|    n_updates        | 567499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1232     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8549     |\n",
      "|    total_timesteps  | 2322216  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00396  |\n",
      "|    n_updates        | 568053   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1236     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8572     |\n",
      "|    total_timesteps  | 2329780  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 569944   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2330000, episode_reward=-19.40 +/- 0.80\n",
      "Episode length: 1495.80 +/- 209.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.5e+03  |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000862 |\n",
      "|    n_updates        | 569999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8600     |\n",
      "|    total_timesteps  | 2336849  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 571712   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2340000, episode_reward=-18.60 +/- 1.50\n",
      "Episode length: 1860.20 +/- 347.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.86e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 572499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1244     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8628     |\n",
      "|    total_timesteps  | 2343572  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00636  |\n",
      "|    n_updates        | 573392   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1248     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8646     |\n",
      "|    total_timesteps  | 2349596  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00281  |\n",
      "|    n_updates        | 574898   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2350000, episode_reward=-20.00 +/- 0.63\n",
      "Episode length: 1385.40 +/- 163.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.39e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 574999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1252     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8671     |\n",
      "|    total_timesteps  | 2355606  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 576401   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2360000, episode_reward=-19.60 +/- 0.49\n",
      "Episode length: 1322.60 +/- 143.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00312  |\n",
      "|    n_updates        | 577499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.89e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1256     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8694     |\n",
      "|    total_timesteps  | 2361497  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00477  |\n",
      "|    n_updates        | 577874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.85e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8712     |\n",
      "|    total_timesteps  | 2367478  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00228  |\n",
      "|    n_updates        | 579369   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2370000, episode_reward=-18.00 +/- 1.55\n",
      "Episode length: 1909.20 +/- 178.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.91e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 579999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.83e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1264     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8746     |\n",
      "|    total_timesteps  | 2376064  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 581515   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2380000, episode_reward=-18.80 +/- 1.47\n",
      "Episode length: 1478.00 +/- 132.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.48e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00525  |\n",
      "|    n_updates        | 582499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1268     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8775     |\n",
      "|    total_timesteps  | 2383556  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 583388   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2390000, episode_reward=-17.00 +/- 1.90\n",
      "Episode length: 2126.60 +/- 125.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.13e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 584999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1272     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8809     |\n",
      "|    total_timesteps  | 2391748  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00282  |\n",
      "|    n_updates        | 585436   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1276     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8830     |\n",
      "|    total_timesteps  | 2398694  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 587173   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=-18.20 +/- 0.75\n",
      "Episode length: 1667.20 +/- 187.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.67e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 587499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8862     |\n",
      "|    total_timesteps  | 2406967  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 589241   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2410000, episode_reward=-17.80 +/- 1.17\n",
      "Episode length: 1840.40 +/- 123.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.84e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00238  |\n",
      "|    n_updates        | 589999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1284     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8898     |\n",
      "|    total_timesteps  | 2416211  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00214  |\n",
      "|    n_updates        | 591552   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2420000, episode_reward=-16.80 +/- 1.17\n",
      "Episode length: 2124.60 +/- 108.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.12e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00368  |\n",
      "|    n_updates        | 592499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1288     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8928     |\n",
      "|    total_timesteps  | 2423081  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 593270   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2430000, episode_reward=-19.40 +/- 0.49\n",
      "Episode length: 1867.00 +/- 157.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.87e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 594999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1292     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8961     |\n",
      "|    total_timesteps  | 2431467  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 595366   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1296     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 8978     |\n",
      "|    total_timesteps  | 2437052  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00679  |\n",
      "|    n_updates        | 596762   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2440000, episode_reward=-20.00 +/- 0.00\n",
      "Episode length: 1236.40 +/- 139.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 597499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9004     |\n",
      "|    total_timesteps  | 2443612  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 598402   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.75e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1304     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9021     |\n",
      "|    total_timesteps  | 2449349  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00504  |\n",
      "|    n_updates        | 599837   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2450000, episode_reward=-19.60 +/- 0.49\n",
      "Episode length: 1382.40 +/- 141.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.38e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00348  |\n",
      "|    n_updates        | 599999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1308     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9044     |\n",
      "|    total_timesteps  | 2455154  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 601288   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2460000, episode_reward=-19.80 +/- 1.17\n",
      "Episode length: 1477.60 +/- 171.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.48e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00392  |\n",
      "|    n_updates        | 602499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1312     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9071     |\n",
      "|    total_timesteps  | 2461973  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 602993   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1316     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9094     |\n",
      "|    total_timesteps  | 2469417  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 604854   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2470000, episode_reward=-17.60 +/- 1.02\n",
      "Episode length: 1743.80 +/- 180.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.74e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 604999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.75e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9123     |\n",
      "|    total_timesteps  | 2476653  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 606663   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2480000, episode_reward=-15.80 +/- 2.04\n",
      "Episode length: 2577.40 +/- 333.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.58e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00388  |\n",
      "|    n_updates        | 607499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1324     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9163     |\n",
      "|    total_timesteps  | 2486160  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00663  |\n",
      "|    n_updates        | 609039   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2490000, episode_reward=-19.40 +/- 1.02\n",
      "Episode length: 1769.40 +/- 462.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.77e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 609999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1328     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9200     |\n",
      "|    total_timesteps  | 2495953  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000874 |\n",
      "|    n_updates        | 611488   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2500000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1116.80 +/- 94.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.12e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00221  |\n",
      "|    n_updates        | 612499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1332     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9221     |\n",
      "|    total_timesteps  | 2501320  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00366  |\n",
      "|    n_updates        | 612829   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1336     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9240     |\n",
      "|    total_timesteps  | 2507697  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 614424   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2510000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1234.40 +/- 253.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 614999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9267     |\n",
      "|    total_timesteps  | 2514772  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 616192   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1344     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9283     |\n",
      "|    total_timesteps  | 2519986  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 617496   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2520000, episode_reward=-19.80 +/- 1.94\n",
      "Episode length: 1250.00 +/- 290.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.25e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 617499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1348     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9304     |\n",
      "|    total_timesteps  | 2525361  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00082  |\n",
      "|    n_updates        | 618840   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2530000, episode_reward=-20.20 +/- 0.75\n",
      "Episode length: 1343.00 +/- 121.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 619999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.75e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1352     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9327     |\n",
      "|    total_timesteps  | 2531042  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00213  |\n",
      "|    n_updates        | 620260   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.75e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1356     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9342     |\n",
      "|    total_timesteps  | 2536078  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 621519   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2540000, episode_reward=-19.40 +/- 0.80\n",
      "Episode length: 1345.20 +/- 197.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.35e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 622499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9370     |\n",
      "|    total_timesteps  | 2543162  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 623290   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1364     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9389     |\n",
      "|    total_timesteps  | 2549656  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 624913   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2550000, episode_reward=-20.20 +/- 0.40\n",
      "Episode length: 1112.20 +/- 28.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 624999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.72e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1368     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9412     |\n",
      "|    total_timesteps  | 2555618  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00255  |\n",
      "|    n_updates        | 626404   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2560000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1305.80 +/- 151.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 627499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1372     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9435     |\n",
      "|    total_timesteps  | 2561191  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 627797   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1376     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9450     |\n",
      "|    total_timesteps  | 2566111  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 629027   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2570000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1203.60 +/- 128.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000609 |\n",
      "|    n_updates        | 629999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9474     |\n",
      "|    total_timesteps  | 2572451  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 630612   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1384     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9489     |\n",
      "|    total_timesteps  | 2577417  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 631854   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2580000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1171.20 +/- 67.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00556  |\n",
      "|    n_updates        | 632499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1388     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9516     |\n",
      "|    total_timesteps  | 2584368  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 633591   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1392     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9532     |\n",
      "|    total_timesteps  | 2589706  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 634926   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2590000, episode_reward=-17.40 +/- 2.33\n",
      "Episode length: 1782.20 +/- 213.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.78e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 634999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1396     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9555     |\n",
      "|    total_timesteps  | 2594996  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 636248   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2600000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1148.20 +/- 98.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 637499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9580     |\n",
      "|    total_timesteps  | 2601258  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 637814   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1404     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9597     |\n",
      "|    total_timesteps  | 2606968  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000848 |\n",
      "|    n_updates        | 639241   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2610000, episode_reward=-20.60 +/- 0.80\n",
      "Episode length: 1099.20 +/- 75.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 639999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.57e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1408     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9618     |\n",
      "|    total_timesteps  | 2612164  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000947 |\n",
      "|    n_updates        | 640540   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.55e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1412     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9632     |\n",
      "|    total_timesteps  | 2616892  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 641722   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2620000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1220.40 +/- 103.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 642499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.53e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1416     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9655     |\n",
      "|    total_timesteps  | 2622731  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 643182   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.52e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9674     |\n",
      "|    total_timesteps  | 2628913  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 644728   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2630000, episode_reward=-19.40 +/- 0.80\n",
      "Episode length: 1838.40 +/- 220.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.84e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 644999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.5e+03  |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1424     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9704     |\n",
      "|    total_timesteps  | 2636369  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00408  |\n",
      "|    n_updates        | 646592   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2640000, episode_reward=-18.00 +/- 0.89\n",
      "Episode length: 1995.80 +/- 67.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2e+03    |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 647499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.47e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1428     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9733     |\n",
      "|    total_timesteps  | 2643011  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 648252   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.48e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1432     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9753     |\n",
      "|    total_timesteps  | 2649668  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 649916   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2650000, episode_reward=-19.80 +/- 0.75\n",
      "Episode length: 1316.00 +/- 164.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 649999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.47e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1436     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9775     |\n",
      "|    total_timesteps  | 2655063  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0065   |\n",
      "|    n_updates        | 651265   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2660000, episode_reward=-19.60 +/- 1.02\n",
      "Episode length: 1291.80 +/- 120.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.29e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 652499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.46e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9799     |\n",
      "|    total_timesteps  | 2661058  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 652764   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.47e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1444     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9818     |\n",
      "|    total_timesteps  | 2667398  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00281  |\n",
      "|    n_updates        | 654349   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2670000, episode_reward=-20.80 +/- 0.40\n",
      "Episode length: 1081.20 +/- 49.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | -20.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00785  |\n",
      "|    n_updates        | 654999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.48e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1448     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9841     |\n",
      "|    total_timesteps  | 2673634  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00194  |\n",
      "|    n_updates        | 655908   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.49e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1452     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9860     |\n",
      "|    total_timesteps  | 2679911  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00366  |\n",
      "|    n_updates        | 657477   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2680000, episode_reward=-18.20 +/- 1.47\n",
      "Episode length: 2023.80 +/- 175.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.02e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00422  |\n",
      "|    n_updates        | 657499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.5e+03  |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1456     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9889     |\n",
      "|    total_timesteps  | 2686496  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 659123   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2690000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1205.20 +/- 70.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.21e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000835 |\n",
      "|    n_updates        | 659999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.5e+03  |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9913     |\n",
      "|    total_timesteps  | 2692729  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 660682   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.48e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1464     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9927     |\n",
      "|    total_timesteps  | 2697457  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 661864   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2700000, episode_reward=-20.20 +/- 0.40\n",
      "Episode length: 1137.00 +/- 36.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00311  |\n",
      "|    n_updates        | 662499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.47e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1468     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9947     |\n",
      "|    total_timesteps  | 2702561  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 663140   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.47e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1472     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9965     |\n",
      "|    total_timesteps  | 2708562  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00189  |\n",
      "|    n_updates        | 664640   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2710000, episode_reward=-19.00 +/- 0.63\n",
      "Episode length: 1698.20 +/- 197.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.7e+03  |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 664999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.49e+03 |\n",
      "|    ep_rew_mean      | -21.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1476     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 9993     |\n",
      "|    total_timesteps  | 2715115  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00353  |\n",
      "|    n_updates        | 666278   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2720000, episode_reward=-18.60 +/- 1.62\n",
      "Episode length: 2094.80 +/- 417.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.09e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00969  |\n",
      "|    n_updates        | 667499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.49e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10022    |\n",
      "|    total_timesteps  | 2721646  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 667911   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.5e+03  |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1484     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10040    |\n",
      "|    total_timesteps  | 2727803  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 669450   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2730000, episode_reward=-19.20 +/- 0.40\n",
      "Episode length: 1775.60 +/- 201.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.78e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 669999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.51e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1488     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10070    |\n",
      "|    total_timesteps  | 2735262  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00292  |\n",
      "|    n_updates        | 671315   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2740000, episode_reward=-16.40 +/- 2.87\n",
      "Episode length: 2373.80 +/- 372.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.37e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 672499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.53e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1492     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10102    |\n",
      "|    total_timesteps  | 2742251  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 673062   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2750000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1280.40 +/- 144.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00219  |\n",
      "|    n_updates        | 674999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.57e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1496     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10135    |\n",
      "|    total_timesteps  | 2751616  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 675403   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.57e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10156    |\n",
      "|    total_timesteps  | 2758645  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00504  |\n",
      "|    n_updates        | 677161   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2760000, episode_reward=-19.80 +/- 1.47\n",
      "Episode length: 1490.20 +/- 283.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.49e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00944  |\n",
      "|    n_updates        | 677499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.6e+03  |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1504     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10189    |\n",
      "|    total_timesteps  | 2767428  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 679356   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2770000, episode_reward=-16.80 +/- 1.72\n",
      "Episode length: 2076.40 +/- 155.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.08e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 679999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.64e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1508     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10223    |\n",
      "|    total_timesteps  | 2775731  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 681432   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2780000, episode_reward=-16.60 +/- 1.50\n",
      "Episode length: 2073.20 +/- 262.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.07e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 682499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1512     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10257    |\n",
      "|    total_timesteps  | 2783818  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 683454   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2790000, episode_reward=-17.60 +/- 1.85\n",
      "Episode length: 2171.60 +/- 257.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.17e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 684999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.72e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1516     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10298    |\n",
      "|    total_timesteps  | 2794295  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 686073   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2800000, episode_reward=-17.20 +/- 0.98\n",
      "Episode length: 2260.40 +/- 273.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.26e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 687499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.75e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10338    |\n",
      "|    total_timesteps  | 2804243  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0029   |\n",
      "|    n_updates        | 688560   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2810000, episode_reward=-15.80 +/- 1.72\n",
      "Episode length: 2388.00 +/- 125.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.39e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 689999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1524     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10372    |\n",
      "|    total_timesteps  | 2812143  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00494  |\n",
      "|    n_updates        | 690535   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2820000, episode_reward=-16.40 +/- 0.80\n",
      "Episode length: 2207.20 +/- 133.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 692499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1528     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10410    |\n",
      "|    total_timesteps  | 2821762  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 692940   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1532     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10433    |\n",
      "|    total_timesteps  | 2829339  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00518  |\n",
      "|    n_updates        | 694834   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2830000, episode_reward=-19.40 +/- 1.50\n",
      "Episode length: 1282.00 +/- 217.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 694999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.83e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1536     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10465    |\n",
      "|    total_timesteps  | 2837937  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00982  |\n",
      "|    n_updates        | 696984   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2840000, episode_reward=-16.00 +/- 2.61\n",
      "Episode length: 1967.80 +/- 275.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.97e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 697499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.87e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10504    |\n",
      "|    total_timesteps  | 2848019  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00455  |\n",
      "|    n_updates        | 699504   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2850000, episode_reward=-13.80 +/- 1.17\n",
      "Episode length: 2431.80 +/- 123.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.43e+03 |\n",
      "|    mean_reward      | -13.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00362  |\n",
      "|    n_updates        | 699999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.91e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1544     |\n",
      "|    fps              | 271      |\n",
      "|    time_elapsed     | 10544    |\n",
      "|    total_timesteps  | 2858028  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 702006   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2860000, episode_reward=-17.40 +/- 1.36\n",
      "Episode length: 2137.40 +/- 260.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.002    |\n",
      "|    n_updates        | 702499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1548     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10588    |\n",
      "|    total_timesteps  | 2869546  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00875  |\n",
      "|    n_updates        | 704886   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2870000, episode_reward=-15.00 +/- 1.41\n",
      "Episode length: 2334.80 +/- 166.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.33e+03 |\n",
      "|    mean_reward      | -15      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0021   |\n",
      "|    n_updates        | 704999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1552     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10628    |\n",
      "|    total_timesteps  | 2879388  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00476  |\n",
      "|    n_updates        | 707346   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2880000, episode_reward=-16.00 +/- 2.28\n",
      "Episode length: 2256.40 +/- 280.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.26e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 707499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1556     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10659    |\n",
      "|    total_timesteps  | 2886279  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00298  |\n",
      "|    n_updates        | 709069   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2890000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1099.20 +/- 30.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00223  |\n",
      "|    n_updates        | 709999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10694    |\n",
      "|    total_timesteps  | 2896248  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 711561   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2900000, episode_reward=-15.60 +/- 2.06\n",
      "Episode length: 2199.60 +/- 217.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.2e+03  |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 712499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1564     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10735    |\n",
      "|    total_timesteps  | 2906680  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00359  |\n",
      "|    n_updates        | 714169   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2910000, episode_reward=-17.40 +/- 1.96\n",
      "Episode length: 2070.20 +/- 241.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.07e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00756  |\n",
      "|    n_updates        | 714999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1568     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10771    |\n",
      "|    total_timesteps  | 2915729  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 716432   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2920000, episode_reward=-16.80 +/- 1.83\n",
      "Episode length: 2068.00 +/- 190.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.07e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 717499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1572     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10807    |\n",
      "|    total_timesteps  | 2924826  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 718706   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2930000, episode_reward=-20.20 +/- 1.17\n",
      "Episode length: 1267.20 +/- 209.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 719999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1576     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10838    |\n",
      "|    total_timesteps  | 2933165  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 720791   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2940000, episode_reward=-20.20 +/- 0.75\n",
      "Episode length: 1318.60 +/- 53.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 722499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10871    |\n",
      "|    total_timesteps  | 2942188  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00802  |\n",
      "|    n_updates        | 723046   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2950000, episode_reward=-18.60 +/- 0.49\n",
      "Episode length: 1888.80 +/- 135.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.89e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00394  |\n",
      "|    n_updates        | 724999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1584     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10908    |\n",
      "|    total_timesteps  | 2951931  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000825 |\n",
      "|    n_updates        | 725482   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2960000, episode_reward=-17.00 +/- 1.41\n",
      "Episode length: 2400.60 +/- 89.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.4e+03  |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 727499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.27e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1588     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10949    |\n",
      "|    total_timesteps  | 2962032  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00347  |\n",
      "|    n_updates        | 728007   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2970000, episode_reward=-17.60 +/- 2.06\n",
      "Episode length: 2281.60 +/- 174.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.28e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 729999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.3e+03  |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1592     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 10990    |\n",
      "|    total_timesteps  | 2972327  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 730581   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2980000, episode_reward=-19.60 +/- 0.80\n",
      "Episode length: 1849.00 +/- 167.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.85e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 732499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.3e+03  |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1596     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11027    |\n",
      "|    total_timesteps  | 2982008  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00894  |\n",
      "|    n_updates        | 733001   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.29e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11045    |\n",
      "|    total_timesteps  | 2987821  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 734455   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2990000, episode_reward=-20.20 +/- 1.17\n",
      "Episode length: 1358.40 +/- 197.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.36e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00723  |\n",
      "|    n_updates        | 734999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.27e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1604     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11071    |\n",
      "|    total_timesteps  | 2994404  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00628  |\n",
      "|    n_updates        | 736100   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3000000, episode_reward=-20.00 +/- 0.00\n",
      "Episode length: 1310.20 +/- 165.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00424  |\n",
      "|    n_updates        | 737499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.28e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1608     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11104    |\n",
      "|    total_timesteps  | 3003439  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 738359   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3010000, episode_reward=-18.80 +/- 1.60\n",
      "Episode length: 1665.40 +/- 472.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.67e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 739999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.28e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1612     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11136    |\n",
      "|    total_timesteps  | 3011905  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00214  |\n",
      "|    n_updates        | 740476   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1616     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11158    |\n",
      "|    total_timesteps  | 3019198  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 742299   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3020000, episode_reward=-17.80 +/- 1.94\n",
      "Episode length: 1893.60 +/- 211.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.89e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 742499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11193    |\n",
      "|    total_timesteps  | 3028070  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 744517   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3030000, episode_reward=-20.00 +/- 0.00\n",
      "Episode length: 1231.60 +/- 87.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00529  |\n",
      "|    n_updates        | 744999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1624     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11220    |\n",
      "|    total_timesteps  | 3035278  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00324  |\n",
      "|    n_updates        | 746319   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3040000, episode_reward=-20.20 +/- 0.40\n",
      "Episode length: 1609.20 +/- 328.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.61e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00296  |\n",
      "|    n_updates        | 747499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1628     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11252    |\n",
      "|    total_timesteps  | 3043510  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00468  |\n",
      "|    n_updates        | 748377   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3050000, episode_reward=-17.80 +/- 1.94\n",
      "Episode length: 2236.60 +/- 554.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.24e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00449  |\n",
      "|    n_updates        | 749999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1632     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11286    |\n",
      "|    total_timesteps  | 3051804  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00557  |\n",
      "|    n_updates        | 750450   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1636     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11308    |\n",
      "|    total_timesteps  | 3059058  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 752264   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3060000, episode_reward=-18.60 +/- 1.96\n",
      "Episode length: 1831.20 +/- 590.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.83e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 752499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11340    |\n",
      "|    total_timesteps  | 3066984  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00343  |\n",
      "|    n_updates        | 754245   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3070000, episode_reward=-18.80 +/- 1.60\n",
      "Episode length: 1852.00 +/- 554.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.85e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00353  |\n",
      "|    n_updates        | 754999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1644     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11374    |\n",
      "|    total_timesteps  | 3075813  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 756453   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3080000, episode_reward=-20.20 +/- 0.40\n",
      "Episode length: 2046.40 +/- 686.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.05e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 757499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1648     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11406    |\n",
      "|    total_timesteps  | 3083357  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00493  |\n",
      "|    n_updates        | 758339   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3090000, episode_reward=-17.40 +/- 2.42\n",
      "Episode length: 2077.00 +/- 418.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.08e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00974  |\n",
      "|    n_updates        | 759999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1652     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11439    |\n",
      "|    total_timesteps  | 3091443  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 760360   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1656     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11459    |\n",
      "|    total_timesteps  | 3098119  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 762029   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3100000, episode_reward=-19.80 +/- 0.40\n",
      "Episode length: 1853.80 +/- 364.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.85e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 762499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3110000, episode_reward=-18.40 +/- 1.50\n",
      "Episode length: 1909.60 +/- 397.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.91e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00349  |\n",
      "|    n_updates        | 764999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11518    |\n",
      "|    total_timesteps  | 3112002  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 765500   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3120000, episode_reward=-18.60 +/- 1.62\n",
      "Episode length: 2238.00 +/- 176.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.24e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00336  |\n",
      "|    n_updates        | 767499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1664     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11558    |\n",
      "|    total_timesteps  | 3122281  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 768070   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3130000, episode_reward=-20.00 +/- 0.63\n",
      "Episode length: 1359.20 +/- 199.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.36e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 769999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1668     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11593    |\n",
      "|    total_timesteps  | 3131913  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 770478   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1672     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11614    |\n",
      "|    total_timesteps  | 3138971  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 772242   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3140000, episode_reward=-20.00 +/- 0.89\n",
      "Episode length: 1450.40 +/- 298.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.45e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 772499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1676     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11646    |\n",
      "|    total_timesteps  | 3147546  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 774386   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3150000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1409.00 +/- 122.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.41e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00717  |\n",
      "|    n_updates        | 774999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1680     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11672    |\n",
      "|    total_timesteps  | 3154184  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 776045   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3160000, episode_reward=-18.80 +/- 0.75\n",
      "Episode length: 1843.20 +/- 149.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.84e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 777499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1684     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11705    |\n",
      "|    total_timesteps  | 3162304  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00522  |\n",
      "|    n_updates        | 778075   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1688     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11726    |\n",
      "|    total_timesteps  | 3169193  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00331  |\n",
      "|    n_updates        | 779798   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3170000, episode_reward=-18.20 +/- 1.17\n",
      "Episode length: 2141.40 +/- 204.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 779999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1692     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11757    |\n",
      "|    total_timesteps  | 3176457  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 781614   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3180000, episode_reward=-16.40 +/- 2.42\n",
      "Episode length: 2183.00 +/- 302.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.18e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 782499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1696     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11793    |\n",
      "|    total_timesteps  | 3185194  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 783798   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3190000, episode_reward=-16.80 +/- 2.32\n",
      "Episode length: 2299.80 +/- 339.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.3e+03  |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 784999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -21      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 11822    |\n",
      "|    total_timesteps  | 3191580  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 785394   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1704     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11845    |\n",
      "|    total_timesteps  | 3199278  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 787319   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3200000, episode_reward=-16.80 +/- 2.40\n",
      "Episode length: 1921.20 +/- 350.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.92e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 787499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1708     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11880    |\n",
      "|    total_timesteps  | 3208147  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00367  |\n",
      "|    n_updates        | 789536   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3210000, episode_reward=-19.80 +/- 0.98\n",
      "Episode length: 1204.40 +/- 124.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00845  |\n",
      "|    n_updates        | 789999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1712     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11906    |\n",
      "|    total_timesteps  | 3214952  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 791237   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3220000, episode_reward=-19.60 +/- 1.36\n",
      "Episode length: 1324.60 +/- 214.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 792499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1716     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11939    |\n",
      "|    total_timesteps  | 3223995  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 793498   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3230000, episode_reward=-16.20 +/- 0.75\n",
      "Episode length: 2256.00 +/- 132.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.26e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 794999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1720     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 11973    |\n",
      "|    total_timesteps  | 3232107  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 795526   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1724     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 11994    |\n",
      "|    total_timesteps  | 3239213  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 797303   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3240000, episode_reward=-17.00 +/- 2.28\n",
      "Episode length: 1931.80 +/- 258.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.93e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 797499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1728     |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 12028    |\n",
      "|    total_timesteps  | 3247633  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000834 |\n",
      "|    n_updates        | 799408   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3250000, episode_reward=-17.40 +/- 1.02\n",
      "Episode length: 1834.80 +/- 182.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.83e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 799999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1732     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12058    |\n",
      "|    total_timesteps  | 3254996  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 801248   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3260000, episode_reward=-19.20 +/- 1.17\n",
      "Episode length: 1340.00 +/- 133.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 802499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1736     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12091    |\n",
      "|    total_timesteps  | 3263934  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000923 |\n",
      "|    n_updates        | 803483   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3270000, episode_reward=-16.00 +/- 1.10\n",
      "Episode length: 2289.40 +/- 110.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.29e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 804999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1740     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12133    |\n",
      "|    total_timesteps  | 3274759  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00512  |\n",
      "|    n_updates        | 806189   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3280000, episode_reward=-15.80 +/- 1.94\n",
      "Episode length: 2129.40 +/- 260.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.13e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00845  |\n",
      "|    n_updates        | 807499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1744     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12171    |\n",
      "|    total_timesteps  | 3284225  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 808556   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3290000, episode_reward=-15.00 +/- 2.00\n",
      "Episode length: 2313.40 +/- 257.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.31e+03 |\n",
      "|    mean_reward      | -15      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0021   |\n",
      "|    n_updates        | 809999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1748     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12211    |\n",
      "|    total_timesteps  | 3294068  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 811016   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3300000, episode_reward=-17.00 +/- 1.90\n",
      "Episode length: 2092.60 +/- 422.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.09e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000945 |\n",
      "|    n_updates        | 812499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1752     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12250    |\n",
      "|    total_timesteps  | 3304158  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00293  |\n",
      "|    n_updates        | 813539   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3310000, episode_reward=-16.60 +/- 1.62\n",
      "Episode length: 2138.40 +/- 160.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 814999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1756     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12283    |\n",
      "|    total_timesteps  | 3311876  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00345  |\n",
      "|    n_updates        | 815468   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3320000, episode_reward=-17.40 +/- 2.24\n",
      "Episode length: 2379.00 +/- 263.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.38e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 817499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1760     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12324    |\n",
      "|    total_timesteps  | 3322211  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00175  |\n",
      "|    n_updates        | 818052   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3330000, episode_reward=-15.20 +/- 1.94\n",
      "Episode length: 2391.80 +/- 219.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.39e+03 |\n",
      "|    mean_reward      | -15.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00556  |\n",
      "|    n_updates        | 819999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1764     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12366    |\n",
      "|    total_timesteps  | 3332554  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 820638   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3340000, episode_reward=-15.00 +/- 2.10\n",
      "Episode length: 2658.20 +/- 250.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.66e+03 |\n",
      "|    mean_reward      | -15      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 822499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1768     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12408    |\n",
      "|    total_timesteps  | 3342881  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00212  |\n",
      "|    n_updates        | 823220   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3350000, episode_reward=-16.60 +/- 1.36\n",
      "Episode length: 2566.00 +/- 335.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 824999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1772     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12446    |\n",
      "|    total_timesteps  | 3351764  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 825440   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1776     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12470    |\n",
      "|    total_timesteps  | 3359867  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00504  |\n",
      "|    n_updates        | 827466   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3360000, episode_reward=-17.00 +/- 2.10\n",
      "Episode length: 2398.20 +/- 209.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.4e+03  |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 827499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1780     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12510    |\n",
      "|    total_timesteps  | 3369639  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 829909   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3370000, episode_reward=-15.40 +/- 3.56\n",
      "Episode length: 2427.00 +/- 365.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.43e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 829999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1784     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12549    |\n",
      "|    total_timesteps  | 3379267  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 832316   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3380000, episode_reward=-16.40 +/- 1.74\n",
      "Episode length: 2285.20 +/- 285.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.29e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00644  |\n",
      "|    n_updates        | 832499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1788     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12587    |\n",
      "|    total_timesteps  | 3388626  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 834656   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3390000, episode_reward=-18.40 +/- 1.36\n",
      "Episode length: 2045.80 +/- 127.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.05e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0099   |\n",
      "|    n_updates        | 834999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1792     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12624    |\n",
      "|    total_timesteps  | 3398088  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000926 |\n",
      "|    n_updates        | 837021   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3400000, episode_reward=-17.80 +/- 2.04\n",
      "Episode length: 1873.20 +/- 214.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.87e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00419  |\n",
      "|    n_updates        | 837499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1796     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12657    |\n",
      "|    total_timesteps  | 3406140  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00382  |\n",
      "|    n_updates        | 839034   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3410000, episode_reward=-17.80 +/- 1.60\n",
      "Episode length: 1910.80 +/- 332.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.91e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00234  |\n",
      "|    n_updates        | 839999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -18.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12689    |\n",
      "|    total_timesteps  | 3414130  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 841032   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3420000, episode_reward=-17.60 +/- 1.85\n",
      "Episode length: 1986.80 +/- 167.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.99e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000978 |\n",
      "|    n_updates        | 842499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1804     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12728    |\n",
      "|    total_timesteps  | 3424100  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 843524   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3430000, episode_reward=-17.40 +/- 0.80\n",
      "Episode length: 1989.80 +/- 154.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.99e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000771 |\n",
      "|    n_updates        | 844999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1808     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 12760    |\n",
      "|    total_timesteps  | 3431866  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00521  |\n",
      "|    n_updates        | 845466   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -18.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1812     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12782    |\n",
      "|    total_timesteps  | 3439457  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 847364   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3440000, episode_reward=-17.80 +/- 2.40\n",
      "Episode length: 1831.40 +/- 346.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.83e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 847499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -18.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1816     |\n",
      "|    fps              | 269      |\n",
      "|    time_elapsed     | 12813    |\n",
      "|    total_timesteps  | 3447082  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 849270   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3450000, episode_reward=-17.40 +/- 0.80\n",
      "Episode length: 2268.80 +/- 319.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00357  |\n",
      "|    n_updates        | 849999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | -18.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1820     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 12852    |\n",
      "|    total_timesteps  | 3456519  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00378  |\n",
      "|    n_updates        | 851629   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3460000, episode_reward=-16.60 +/- 0.49\n",
      "Episode length: 2286.60 +/- 176.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.29e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 852499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.28e+03 |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1824     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 12893    |\n",
      "|    total_timesteps  | 3467128  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00227  |\n",
      "|    n_updates        | 854281   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3470000, episode_reward=-15.00 +/- 2.00\n",
      "Episode length: 2529.40 +/- 251.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.53e+03 |\n",
      "|    mean_reward      | -15      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 854999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.29e+03 |\n",
      "|    ep_rew_mean      | -18.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1828     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 12933    |\n",
      "|    total_timesteps  | 3476609  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00649  |\n",
      "|    n_updates        | 856652   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3480000, episode_reward=-20.00 +/- 0.63\n",
      "Episode length: 1245.40 +/- 139.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.25e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 857499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.3e+03  |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1832     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 12963    |\n",
      "|    total_timesteps  | 3484910  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 858727   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3490000, episode_reward=-16.40 +/- 2.06\n",
      "Episode length: 2379.80 +/- 190.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.38e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00292  |\n",
      "|    n_updates        | 859999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.31e+03 |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1836     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13002    |\n",
      "|    total_timesteps  | 3494465  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 861116   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3500000, episode_reward=-14.60 +/- 2.15\n",
      "Episode length: 2141.40 +/- 279.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 862499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.29e+03 |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1840     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13040    |\n",
      "|    total_timesteps  | 3503909  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 863477   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1844     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13057    |\n",
      "|    total_timesteps  | 3509784  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00293  |\n",
      "|    n_updates        | 864945   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3510000, episode_reward=-20.20 +/- 0.75\n",
      "Episode length: 1237.40 +/- 136.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00322  |\n",
      "|    n_updates        | 864999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1848     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13078    |\n",
      "|    total_timesteps  | 3514885  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 866221   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3520000, episode_reward=-19.80 +/- 0.98\n",
      "Episode length: 1275.20 +/- 132.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.28e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00558  |\n",
      "|    n_updates        | 867499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1852     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13105    |\n",
      "|    total_timesteps  | 3521960  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 867989   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1856     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13126    |\n",
      "|    total_timesteps  | 3528851  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000843 |\n",
      "|    n_updates        | 869712   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3530000, episode_reward=-19.40 +/- 0.80\n",
      "Episode length: 1311.80 +/- 125.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00947  |\n",
      "|    n_updates        | 869999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1860     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13155    |\n",
      "|    total_timesteps  | 3536651  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00207  |\n",
      "|    n_updates        | 871662   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3540000, episode_reward=-16.40 +/- 1.50\n",
      "Episode length: 2193.00 +/- 206.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.19e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00836  |\n",
      "|    n_updates        | 872499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1864     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13195    |\n",
      "|    total_timesteps  | 3546675  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00254  |\n",
      "|    n_updates        | 874168   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3550000, episode_reward=-15.80 +/- 3.25\n",
      "Episode length: 2150.80 +/- 385.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.15e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 874999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1868     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13235    |\n",
      "|    total_timesteps  | 3557083  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0097   |\n",
      "|    n_updates        | 876770   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3560000, episode_reward=-16.20 +/- 1.47\n",
      "Episode length: 2309.60 +/- 222.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.31e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00607  |\n",
      "|    n_updates        | 877499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1872     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13271    |\n",
      "|    total_timesteps  | 3565711  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000785 |\n",
      "|    n_updates        | 878927   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3570000, episode_reward=-18.80 +/- 0.98\n",
      "Episode length: 1830.20 +/- 114.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.83e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 879999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1876     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13306    |\n",
      "|    total_timesteps  | 3574804  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 881200   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3580000, episode_reward=-16.60 +/- 1.20\n",
      "Episode length: 2115.20 +/- 76.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.12e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00691  |\n",
      "|    n_updates        | 882499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1880     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13345    |\n",
      "|    total_timesteps  | 3584409  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 883602   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3590000, episode_reward=-19.60 +/- 1.20\n",
      "Episode length: 1315.80 +/- 139.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 884999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1884     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13375    |\n",
      "|    total_timesteps  | 3592660  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00333  |\n",
      "|    n_updates        | 885664   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3600000, episode_reward=-17.20 +/- 1.72\n",
      "Episode length: 2566.00 +/- 555.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00298  |\n",
      "|    n_updates        | 887499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1888     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13417    |\n",
      "|    total_timesteps  | 3602865  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 888216   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3610000, episode_reward=-17.00 +/- 0.89\n",
      "Episode length: 2452.20 +/- 171.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.45e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 889999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1892     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13455    |\n",
      "|    total_timesteps  | 3611853  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00223  |\n",
      "|    n_updates        | 890463   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1896     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13478    |\n",
      "|    total_timesteps  | 3619621  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 892405   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3620000, episode_reward=-18.20 +/- 0.98\n",
      "Episode length: 1817.20 +/- 259.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.82e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 892499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13509    |\n",
      "|    total_timesteps  | 3627311  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00545  |\n",
      "|    n_updates        | 894327   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3630000, episode_reward=-16.80 +/- 3.06\n",
      "Episode length: 1937.40 +/- 428.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.94e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00886  |\n",
      "|    n_updates        | 894999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1904     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13542    |\n",
      "|    total_timesteps  | 3635339  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00682  |\n",
      "|    n_updates        | 896334   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3640000, episode_reward=-17.80 +/- 2.79\n",
      "Episode length: 1815.80 +/- 372.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.82e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00918  |\n",
      "|    n_updates        | 897499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1908     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13576    |\n",
      "|    total_timesteps  | 3644061  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 898515   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3650000, episode_reward=-17.60 +/- 0.49\n",
      "Episode length: 1904.80 +/- 205.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.9e+03  |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 899999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1912     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13610    |\n",
      "|    total_timesteps  | 3652586  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 900646   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1916     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13631    |\n",
      "|    total_timesteps  | 3659688  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00368  |\n",
      "|    n_updates        | 902421   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3660000, episode_reward=-19.00 +/- 1.41\n",
      "Episode length: 1426.80 +/- 258.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.43e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 902499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1920     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13656    |\n",
      "|    total_timesteps  | 3665693  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 903923   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3670000, episode_reward=-18.80 +/- 1.47\n",
      "Episode length: 1646.80 +/- 229.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.65e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00388  |\n",
      "|    n_updates        | 904999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1924     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13685    |\n",
      "|    total_timesteps  | 3672960  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00377  |\n",
      "|    n_updates        | 905739   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1928     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13700    |\n",
      "|    total_timesteps  | 3678022  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 907005   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3680000, episode_reward=-18.40 +/- 2.06\n",
      "Episode length: 1575.20 +/- 286.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.58e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 907499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1932     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13728    |\n",
      "|    total_timesteps  | 3685145  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00599  |\n",
      "|    n_updates        | 908786   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3690000, episode_reward=-17.40 +/- 2.06\n",
      "Episode length: 1747.40 +/- 155.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.75e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 909999   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1936     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13757    |\n",
      "|    total_timesteps  | 3692251  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00239  |\n",
      "|    n_updates        | 910562   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1940     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13776    |\n",
      "|    total_timesteps  | 3698698  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 912174   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3700000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1112.00 +/- 64.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00529  |\n",
      "|    n_updates        | 912499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1944     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13803    |\n",
      "|    total_timesteps  | 3705818  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 913954   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3710000, episode_reward=-19.60 +/- 0.80\n",
      "Episode length: 1727.60 +/- 157.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.73e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00366  |\n",
      "|    n_updates        | 914999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1948     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13831    |\n",
      "|    total_timesteps  | 3712569  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 915642   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1952     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13851    |\n",
      "|    total_timesteps  | 3719322  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000526 |\n",
      "|    n_updates        | 917330   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3720000, episode_reward=-17.80 +/- 1.60\n",
      "Episode length: 1750.80 +/- 174.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.75e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 917499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1956     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13878    |\n",
      "|    total_timesteps  | 3725726  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00206  |\n",
      "|    n_updates        | 918931   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3730000, episode_reward=-17.60 +/- 0.49\n",
      "Episode length: 1698.00 +/- 153.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.7e+03  |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 919999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1960     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13903    |\n",
      "|    total_timesteps  | 3731697  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 920424   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.91e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1964     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13920    |\n",
      "|    total_timesteps  | 3737354  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00451  |\n",
      "|    n_updates        | 921838   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3740000, episode_reward=-19.60 +/- 0.80\n",
      "Episode length: 1355.60 +/- 223.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.36e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00285  |\n",
      "|    n_updates        | 922499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.88e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1968     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13948    |\n",
      "|    total_timesteps  | 3744664  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 923665   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3750000, episode_reward=-18.00 +/- 1.26\n",
      "Episode length: 1891.40 +/- 208.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.89e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00767  |\n",
      "|    n_updates        | 924999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1972     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13977    |\n",
      "|    total_timesteps  | 3751650  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0059   |\n",
      "|    n_updates        | 925412   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.84e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1976     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 13997    |\n",
      "|    total_timesteps  | 3758395  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 927098   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3760000, episode_reward=-18.20 +/- 0.40\n",
      "Episode length: 1881.60 +/- 143.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.88e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00474  |\n",
      "|    n_updates        | 927499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1980     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14029    |\n",
      "|    total_timesteps  | 3766065  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 929016   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3770000, episode_reward=-17.40 +/- 1.74\n",
      "Episode length: 2092.00 +/- 322.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.09e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 929999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1984     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14062    |\n",
      "|    total_timesteps  | 3774069  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00758  |\n",
      "|    n_updates        | 931017   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3780000, episode_reward=-20.00 +/- 0.00\n",
      "Episode length: 1225.80 +/- 95.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 932499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1988     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14089    |\n",
      "|    total_timesteps  | 3781267  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00602  |\n",
      "|    n_updates        | 932816   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1992     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14103    |\n",
      "|    total_timesteps  | 3786081  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00612  |\n",
      "|    n_updates        | 934020   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3790000, episode_reward=-19.00 +/- 1.41\n",
      "Episode length: 2126.40 +/- 111.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.13e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00635  |\n",
      "|    n_updates        | 934999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.75e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1996     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14139    |\n",
      "|    total_timesteps  | 3794794  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 936198   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3800000, episode_reward=-16.00 +/- 2.10\n",
      "Episode length: 2466.60 +/- 230.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.47e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 937499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14181    |\n",
      "|    total_timesteps  | 3805067  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0086   |\n",
      "|    n_updates        | 938766   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3810000, episode_reward=-16.20 +/- 1.83\n",
      "Episode length: 1969.60 +/- 225.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.97e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 939999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2004     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14217    |\n",
      "|    total_timesteps  | 3814398  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000997 |\n",
      "|    n_updates        | 941099   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3820000, episode_reward=-16.60 +/- 0.80\n",
      "Episode length: 2230.00 +/- 83.70\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.23e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00619  |\n",
      "|    n_updates        | 942499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2008     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14259    |\n",
      "|    total_timesteps  | 3825031  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00833  |\n",
      "|    n_updates        | 943757   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3830000, episode_reward=-16.80 +/- 2.04\n",
      "Episode length: 2300.40 +/- 399.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.3e+03  |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 944999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.84e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2012     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14302    |\n",
      "|    total_timesteps  | 3836232  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 946557   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3840000, episode_reward=-19.60 +/- 1.36\n",
      "Episode length: 1556.40 +/- 285.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.56e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00342  |\n",
      "|    n_updates        | 947499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.84e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2016     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14332    |\n",
      "|    total_timesteps  | 3843648  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 948411   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3850000, episode_reward=-18.00 +/- 1.26\n",
      "Episode length: 2100.40 +/- 270.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.1e+03  |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 949999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2020     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14365    |\n",
      "|    total_timesteps  | 3851900  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00789  |\n",
      "|    n_updates        | 950474   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3860000, episode_reward=-18.60 +/- 1.85\n",
      "Episode length: 2347.20 +/- 424.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.35e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000937 |\n",
      "|    n_updates        | 952499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.89e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2024     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14407    |\n",
      "|    total_timesteps  | 3862417  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.004    |\n",
      "|    n_updates        | 953104   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2028     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14429    |\n",
      "|    total_timesteps  | 3869606  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00389  |\n",
      "|    n_updates        | 954901   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3870000, episode_reward=-18.80 +/- 0.75\n",
      "Episode length: 1712.40 +/- 142.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.71e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000665 |\n",
      "|    n_updates        | 954999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.91e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2032     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14457    |\n",
      "|    total_timesteps  | 3876413  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 956603   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3880000, episode_reward=-20.00 +/- 0.63\n",
      "Episode length: 1390.00 +/- 55.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.39e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 957499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2036     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14486    |\n",
      "|    total_timesteps  | 3884167  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 958541   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3890000, episode_reward=-18.20 +/- 0.98\n",
      "Episode length: 2454.60 +/- 249.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.45e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 959999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2040     |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 14528    |\n",
      "|    total_timesteps  | 3894442  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000867 |\n",
      "|    n_updates        | 961110   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3900000, episode_reward=-16.60 +/- 1.02\n",
      "Episode length: 2493.80 +/- 230.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.49e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00242  |\n",
      "|    n_updates        | 962499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2044     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14570    |\n",
      "|    total_timesteps  | 3904725  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 963681   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3910000, episode_reward=-17.80 +/- 0.40\n",
      "Episode length: 2387.20 +/- 379.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.39e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 964999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2048     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14612    |\n",
      "|    total_timesteps  | 3915454  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 966363   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3920000, episode_reward=-17.80 +/- 1.94\n",
      "Episode length: 2226.20 +/- 183.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.23e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00411  |\n",
      "|    n_updates        | 967499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2052     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14646    |\n",
      "|    total_timesteps  | 3923477  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 968369   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3930000, episode_reward=-14.80 +/- 1.83\n",
      "Episode length: 2392.00 +/- 251.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.39e+03 |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00546  |\n",
      "|    n_updates        | 969999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2056     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14681    |\n",
      "|    total_timesteps  | 3931658  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 970414   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3940000, episode_reward=-17.00 +/- 0.89\n",
      "Episode length: 2273.00 +/- 204.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00529  |\n",
      "|    n_updates        | 972499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2060     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14723    |\n",
      "|    total_timesteps  | 3942481  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00462  |\n",
      "|    n_updates        | 973120   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2064     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14744    |\n",
      "|    total_timesteps  | 3949293  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 974823   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3950000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1167.60 +/- 64.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 974999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2068     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14774    |\n",
      "|    total_timesteps  | 3957560  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00098  |\n",
      "|    n_updates        | 976889   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3960000, episode_reward=-18.00 +/- 1.90\n",
      "Episode length: 2226.60 +/- 303.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.23e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00424  |\n",
      "|    n_updates        | 977499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2072     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14809    |\n",
      "|    total_timesteps  | 3966233  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 979058   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3970000, episode_reward=-15.60 +/- 2.15\n",
      "Episode length: 2818.20 +/- 228.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.82e+03 |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 979999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2076     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14841    |\n",
      "|    total_timesteps  | 3972725  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 980681   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2080     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14858    |\n",
      "|    total_timesteps  | 3978523  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00384  |\n",
      "|    n_updates        | 982130   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3980000, episode_reward=-17.80 +/- 2.23\n",
      "Episode length: 1995.00 +/- 429.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2e+03    |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 982499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2084     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14895    |\n",
      "|    total_timesteps  | 3987890  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00507  |\n",
      "|    n_updates        | 984472   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3990000, episode_reward=-20.40 +/- 0.80\n",
      "Episode length: 1308.60 +/- 246.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.31e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000908 |\n",
      "|    n_updates        | 984999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2088     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14922    |\n",
      "|    total_timesteps  | 3994945  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 986236   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4000000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1111.40 +/- 21.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.11e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0072   |\n",
      "|    n_updates        | 987499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2092     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14949    |\n",
      "|    total_timesteps  | 4002260  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00285  |\n",
      "|    n_updates        | 988064   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2096     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 14971    |\n",
      "|    total_timesteps  | 4009612  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 989902   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4010000, episode_reward=-16.80 +/- 1.17\n",
      "Episode length: 2395.20 +/- 194.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.4e+03  |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 989999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15004    |\n",
      "|    total_timesteps  | 4016875  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00455  |\n",
      "|    n_updates        | 991718   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4020000, episode_reward=-18.80 +/- 1.72\n",
      "Episode length: 1979.40 +/- 264.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.98e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0031   |\n",
      "|    n_updates        | 992499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2104     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15041    |\n",
      "|    total_timesteps  | 4026241  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 994060   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4030000, episode_reward=-17.60 +/- 1.36\n",
      "Episode length: 2033.40 +/- 121.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.03e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00755  |\n",
      "|    n_updates        | 994999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2108     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15071    |\n",
      "|    total_timesteps  | 4033479  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00404  |\n",
      "|    n_updates        | 995869   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2112     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15091    |\n",
      "|    total_timesteps  | 4039901  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 997475   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4040000, episode_reward=-20.20 +/- 0.75\n",
      "Episode length: 1652.20 +/- 175.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.65e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00947  |\n",
      "|    n_updates        | 997499   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2116     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15118    |\n",
      "|    total_timesteps  | 4046764  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 999190   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4050000, episode_reward=-15.80 +/- 1.94\n",
      "Episode length: 2142.20 +/- 222.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 999999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2120     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15158    |\n",
      "|    total_timesteps  | 4056811  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 1001702  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4060000, episode_reward=-17.60 +/- 1.85\n",
      "Episode length: 2317.00 +/- 324.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.32e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0284   |\n",
      "|    n_updates        | 1002499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2124     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15193    |\n",
      "|    total_timesteps  | 4065245  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 1003811  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4070000, episode_reward=-20.00 +/- 0.63\n",
      "Episode length: 1951.40 +/- 229.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.95e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 1004999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2128     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15222    |\n",
      "|    total_timesteps  | 4071752  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00892  |\n",
      "|    n_updates        | 1005437  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4080000, episode_reward=-20.00 +/- 0.89\n",
      "Episode length: 1236.80 +/- 119.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.24e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 1007499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2132     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15257    |\n",
      "|    total_timesteps  | 4081748  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00484  |\n",
      "|    n_updates        | 1007936  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2136     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15277    |\n",
      "|    total_timesteps  | 4088262  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 1009565  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4090000, episode_reward=-18.20 +/- 1.60\n",
      "Episode length: 1750.00 +/- 347.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.75e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 1009999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2140     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15315    |\n",
      "|    total_timesteps  | 4098475  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 1012118  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4100000, episode_reward=-17.60 +/- 1.02\n",
      "Episode length: 2379.00 +/- 134.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.38e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00406  |\n",
      "|    n_updates        | 1012499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2144     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15355    |\n",
      "|    total_timesteps  | 4108512  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00352  |\n",
      "|    n_updates        | 1014627  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4110000, episode_reward=-17.40 +/- 1.74\n",
      "Episode length: 1942.40 +/- 321.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.94e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 1014999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2148     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15390    |\n",
      "|    total_timesteps  | 4117321  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00585  |\n",
      "|    n_updates        | 1016830  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4120000, episode_reward=-17.40 +/- 1.36\n",
      "Episode length: 2515.00 +/- 268.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.52e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 1017499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2152     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15426    |\n",
      "|    total_timesteps  | 4125691  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 1018922  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4130000, episode_reward=-16.20 +/- 2.32\n",
      "Episode length: 2730.00 +/- 473.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.73e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 1019999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2156     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15467    |\n",
      "|    total_timesteps  | 4135502  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 1021375  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4140000, episode_reward=-17.40 +/- 1.20\n",
      "Episode length: 2097.20 +/- 278.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.1e+03  |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 1022499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2160     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15502    |\n",
      "|    total_timesteps  | 4144168  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00486  |\n",
      "|    n_updates        | 1023541  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4150000, episode_reward=-16.20 +/- 1.72\n",
      "Episode length: 2370.20 +/- 154.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.37e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0091   |\n",
      "|    n_updates        | 1024999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2164     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15545    |\n",
      "|    total_timesteps  | 4154829  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00381  |\n",
      "|    n_updates        | 1026207  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4160000, episode_reward=-17.20 +/- 0.98\n",
      "Episode length: 2209.60 +/- 145.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00829  |\n",
      "|    n_updates        | 1027499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2168     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15584    |\n",
      "|    total_timesteps  | 4164612  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0092   |\n",
      "|    n_updates        | 1028652  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4170000, episode_reward=-16.20 +/- 2.79\n",
      "Episode length: 2590.60 +/- 260.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.59e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 1029999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2172     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15629    |\n",
      "|    total_timesteps  | 4175904  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 1031475  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4180000, episode_reward=-16.80 +/- 2.56\n",
      "Episode length: 2232.40 +/- 397.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.23e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 1032499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2176     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15669    |\n",
      "|    total_timesteps  | 4186113  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00312  |\n",
      "|    n_updates        | 1034028  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4190000, episode_reward=-17.80 +/- 1.33\n",
      "Episode length: 1961.20 +/- 326.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.96e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00775  |\n",
      "|    n_updates        | 1034999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2180     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15707    |\n",
      "|    total_timesteps  | 4195953  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00551  |\n",
      "|    n_updates        | 1036488  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4200000, episode_reward=-20.00 +/- 0.00\n",
      "Episode length: 1323.40 +/- 143.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 1037499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2184     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15728    |\n",
      "|    total_timesteps  | 4201094  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 1037773  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2188     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15747    |\n",
      "|    total_timesteps  | 4207308  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 1039326  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4210000, episode_reward=-17.20 +/- 1.60\n",
      "Episode length: 2210.40 +/- 234.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 1039999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2192     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15777    |\n",
      "|    total_timesteps  | 4214174  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 1041043  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4220000, episode_reward=-19.80 +/- 0.40\n",
      "Episode length: 1513.40 +/- 213.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.51e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00392  |\n",
      "|    n_updates        | 1042499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2196     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15806    |\n",
      "|    total_timesteps  | 4221491  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 1042872  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15826    |\n",
      "|    total_timesteps  | 4228194  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00321  |\n",
      "|    n_updates        | 1044548  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4230000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1100.40 +/- 32.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 1044999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2204     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15848    |\n",
      "|    total_timesteps  | 4233995  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00693  |\n",
      "|    n_updates        | 1045998  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4240000, episode_reward=-19.20 +/- 0.98\n",
      "Episode length: 1437.40 +/- 84.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.44e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000563 |\n",
      "|    n_updates        | 1047499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2208     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15878    |\n",
      "|    total_timesteps  | 4241712  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00734  |\n",
      "|    n_updates        | 1047927  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2212     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15902    |\n",
      "|    total_timesteps  | 4249721  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 1049930  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4250000, episode_reward=-15.00 +/- 1.10\n",
      "Episode length: 2422.40 +/- 192.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.42e+03 |\n",
      "|    mean_reward      | -15      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 1049999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2216     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15935    |\n",
      "|    total_timesteps  | 4257421  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 1051855  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4260000, episode_reward=-15.60 +/- 2.58\n",
      "Episode length: 2535.00 +/- 429.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.54e+03 |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 1052499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2220     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 15973    |\n",
      "|    total_timesteps  | 4266317  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 1054079  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4270000, episode_reward=-17.00 +/- 1.10\n",
      "Episode length: 1728.40 +/- 252.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.73e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000791 |\n",
      "|    n_updates        | 1054999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2224     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 16009    |\n",
      "|    total_timesteps  | 4275906  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 1056476  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4280000, episode_reward=-17.60 +/- 1.02\n",
      "Episode length: 1786.80 +/- 116.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.79e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 1057499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2228     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 16042    |\n",
      "|    total_timesteps  | 4284142  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00378  |\n",
      "|    n_updates        | 1058535  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4290000, episode_reward=-18.40 +/- 1.36\n",
      "Episode length: 1548.00 +/- 196.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.55e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00751  |\n",
      "|    n_updates        | 1059999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2232     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 16073    |\n",
      "|    total_timesteps  | 4292247  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0049   |\n",
      "|    n_updates        | 1060561  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4300000, episode_reward=-17.00 +/- 0.63\n",
      "Episode length: 1938.60 +/- 136.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.94e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00478  |\n",
      "|    n_updates        | 1062499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2236     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 16110    |\n",
      "|    total_timesteps  | 4301654  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00356  |\n",
      "|    n_updates        | 1062913  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2240     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 16132    |\n",
      "|    total_timesteps  | 4308887  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1064721  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4310000, episode_reward=-17.20 +/- 1.17\n",
      "Episode length: 2168.40 +/- 101.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.17e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 1064999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2244     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 16170    |\n",
      "|    total_timesteps  | 4318415  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 1067103  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4320000, episode_reward=-18.00 +/- 2.00\n",
      "Episode length: 2207.60 +/- 177.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00384  |\n",
      "|    n_updates        | 1067499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2248     |\n",
      "|    fps              | 267      |\n",
      "|    time_elapsed     | 16210    |\n",
      "|    total_timesteps  | 4328685  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0042   |\n",
      "|    n_updates        | 1069671  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4330000, episode_reward=-17.60 +/- 0.80\n",
      "Episode length: 2316.60 +/- 113.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.32e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00234  |\n",
      "|    n_updates        | 1069999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2252     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16242    |\n",
      "|    total_timesteps  | 4335996  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00067  |\n",
      "|    n_updates        | 1071498  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4340000, episode_reward=-17.20 +/- 1.60\n",
      "Episode length: 1761.40 +/- 271.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.76e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00925  |\n",
      "|    n_updates        | 1072499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2256     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16281    |\n",
      "|    total_timesteps  | 4346429  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00368  |\n",
      "|    n_updates        | 1074107  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4350000, episode_reward=-17.40 +/- 1.96\n",
      "Episode length: 2257.40 +/- 266.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.26e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00464  |\n",
      "|    n_updates        | 1074999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2260     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16319    |\n",
      "|    total_timesteps  | 4355973  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00478  |\n",
      "|    n_updates        | 1076493  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4360000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1720.80 +/- 117.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.72e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 1077499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2264     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16348    |\n",
      "|    total_timesteps  | 4363212  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00339  |\n",
      "|    n_updates        | 1078302  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4370000, episode_reward=-19.00 +/- 1.90\n",
      "Episode length: 1889.00 +/- 319.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.89e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 1079999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2268     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16381    |\n",
      "|    total_timesteps  | 4371359  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 1080339  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2272     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16404    |\n",
      "|    total_timesteps  | 4378821  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 1082205  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4380000, episode_reward=-18.20 +/- 0.98\n",
      "Episode length: 2080.20 +/- 112.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.08e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 1082499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2276     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16437    |\n",
      "|    total_timesteps  | 4387006  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.001    |\n",
      "|    n_updates        | 1084251  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4390000, episode_reward=-19.00 +/- 0.63\n",
      "Episode length: 2182.20 +/- 104.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.18e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 1084999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2280     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16474    |\n",
      "|    total_timesteps  | 4396190  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 1086547  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4400000, episode_reward=-17.00 +/- 1.41\n",
      "Episode length: 2341.00 +/- 245.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.34e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00931  |\n",
      "|    n_updates        | 1087499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2284     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16507    |\n",
      "|    total_timesteps  | 4403574  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000689 |\n",
      "|    n_updates        | 1088393  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4410000, episode_reward=-16.60 +/- 2.58\n",
      "Episode length: 2185.20 +/- 332.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.19e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1089999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2288     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16549    |\n",
      "|    total_timesteps  | 4414294  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 1091073  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4420000, episode_reward=-17.20 +/- 1.94\n",
      "Episode length: 2080.80 +/- 258.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.08e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00244  |\n",
      "|    n_updates        | 1092499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2292     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16587    |\n",
      "|    total_timesteps  | 4423974  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000979 |\n",
      "|    n_updates        | 1093493  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4430000, episode_reward=-17.40 +/- 1.85\n",
      "Episode length: 1742.40 +/- 236.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.74e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 1094999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2296     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16618    |\n",
      "|    total_timesteps  | 4432101  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 1095525  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16639    |\n",
      "|    total_timesteps  | 4439020  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 1097254  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4440000, episode_reward=-18.00 +/- 1.10\n",
      "Episode length: 1604.40 +/- 107.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.6e+03  |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 1097499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2304     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16673    |\n",
      "|    total_timesteps  | 4447771  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 1099442  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4450000, episode_reward=-18.60 +/- 0.49\n",
      "Episode length: 1696.40 +/- 220.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.7e+03  |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 1099999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2308     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16704    |\n",
      "|    total_timesteps  | 4455794  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 1101448  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4460000, episode_reward=-16.80 +/- 1.47\n",
      "Episode length: 2496.60 +/- 321.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.5e+03  |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00294  |\n",
      "|    n_updates        | 1102499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2312     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16741    |\n",
      "|    total_timesteps  | 4464434  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00317  |\n",
      "|    n_updates        | 1103608  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4470000, episode_reward=-17.80 +/- 1.47\n",
      "Episode length: 2308.60 +/- 160.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.31e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 1104999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2316     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16783    |\n",
      "|    total_timesteps  | 4475184  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 1106295  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4480000, episode_reward=-18.40 +/- 1.02\n",
      "Episode length: 2384.00 +/- 386.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.38e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 1107499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2320     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16821    |\n",
      "|    total_timesteps  | 4484434  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 1108608  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4490000, episode_reward=-17.60 +/- 2.15\n",
      "Episode length: 2088.20 +/- 109.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.09e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00194  |\n",
      "|    n_updates        | 1109999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2324     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16858    |\n",
      "|    total_timesteps  | 4493712  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00989  |\n",
      "|    n_updates        | 1110927  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4500000, episode_reward=-18.20 +/- 1.94\n",
      "Episode length: 2151.80 +/- 260.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.15e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00281  |\n",
      "|    n_updates        | 1112499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2328     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16892    |\n",
      "|    total_timesteps  | 4501809  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 1112952  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4510000, episode_reward=-19.40 +/- 1.85\n",
      "Episode length: 2161.80 +/- 198.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.16e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 1114999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2332     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16932    |\n",
      "|    total_timesteps  | 4512202  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 1115550  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4520000, episode_reward=-18.40 +/- 1.02\n",
      "Episode length: 2377.00 +/- 99.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.38e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 1117499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2336     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 16973    |\n",
      "|    total_timesteps  | 4522538  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 1118134  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4530000, episode_reward=-19.20 +/- 0.75\n",
      "Episode length: 2170.80 +/- 192.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.17e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00586  |\n",
      "|    n_updates        | 1119999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2340     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17011    |\n",
      "|    total_timesteps  | 4532000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 1120499  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4540000, episode_reward=-17.40 +/- 1.36\n",
      "Episode length: 2514.20 +/- 155.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.51e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 1122499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2344     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17052    |\n",
      "|    total_timesteps  | 4541951  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0056   |\n",
      "|    n_updates        | 1122987  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4550000, episode_reward=-19.20 +/- 1.47\n",
      "Episode length: 1969.00 +/- 366.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.97e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 1124999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2348     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17091    |\n",
      "|    total_timesteps  | 4552108  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 1125526  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4560000, episode_reward=-20.00 +/- 0.63\n",
      "Episode length: 1602.40 +/- 196.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.6e+03  |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00495  |\n",
      "|    n_updates        | 1127499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2352     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17128    |\n",
      "|    total_timesteps  | 4562216  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 1128053  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4570000, episode_reward=-17.20 +/- 2.32\n",
      "Episode length: 2371.60 +/- 256.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.37e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 1129999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2356     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17166    |\n",
      "|    total_timesteps  | 4571650  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0029   |\n",
      "|    n_updates        | 1130412  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2360     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17188    |\n",
      "|    total_timesteps  | 4578721  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00473  |\n",
      "|    n_updates        | 1132180  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4580000, episode_reward=-19.20 +/- 0.75\n",
      "Episode length: 2074.20 +/- 125.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.07e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 1132499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2364     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17226    |\n",
      "|    total_timesteps  | 4588385  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 1134596  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4590000, episode_reward=-16.00 +/- 1.10\n",
      "Episode length: 2613.00 +/- 89.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.61e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 1134999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.28e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2368     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17269    |\n",
      "|    total_timesteps  | 4598922  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00254  |\n",
      "|    n_updates        | 1137230  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4600000, episode_reward=-18.20 +/- 1.33\n",
      "Episode length: 1880.40 +/- 134.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.88e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 1137499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.29e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2372     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17303    |\n",
      "|    total_timesteps  | 4607729  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000298 |\n",
      "|    n_updates        | 1139432  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4610000, episode_reward=-16.80 +/- 0.98\n",
      "Episode length: 2050.00 +/- 153.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.05e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00733  |\n",
      "|    n_updates        | 1139999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.29e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2376     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17336    |\n",
      "|    total_timesteps  | 4615578  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00565  |\n",
      "|    n_updates        | 1141394  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4620000, episode_reward=-19.60 +/- 1.36\n",
      "Episode length: 1898.60 +/- 228.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.9e+03  |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00093  |\n",
      "|    n_updates        | 1142499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.28e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2380     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17370    |\n",
      "|    total_timesteps  | 4624262  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 1143565  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4630000, episode_reward=-19.00 +/- 1.79\n",
      "Episode length: 2089.60 +/- 203.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.09e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 1144999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.28e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2384     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17402    |\n",
      "|    total_timesteps  | 4632020  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 1145504  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4640000, episode_reward=-17.60 +/- 1.50\n",
      "Episode length: 2197.40 +/- 66.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.2e+03  |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 1147499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.28e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2388     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17442    |\n",
      "|    total_timesteps  | 4642040  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 1148009  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2392     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17460    |\n",
      "|    total_timesteps  | 4647965  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1149491  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4650000, episode_reward=-17.40 +/- 2.42\n",
      "Episode length: 1715.80 +/- 228.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.72e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 1149999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2396     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17491    |\n",
      "|    total_timesteps  | 4655936  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 1151483  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4660000, episode_reward=-17.60 +/- 0.80\n",
      "Episode length: 2125.80 +/- 105.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.13e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 1152499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17523    |\n",
      "|    total_timesteps  | 4663575  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00654  |\n",
      "|    n_updates        | 1153393  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4670000, episode_reward=-17.60 +/- 1.74\n",
      "Episode length: 1937.00 +/- 210.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.94e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00281  |\n",
      "|    n_updates        | 1154999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2404     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17557    |\n",
      "|    total_timesteps  | 4672012  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 1155502  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2408     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17576    |\n",
      "|    total_timesteps  | 4678356  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 1157088  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4680000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1344.00 +/- 209.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 1157499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2412     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17610    |\n",
      "|    total_timesteps  | 4687849  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 1159462  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4690000, episode_reward=-19.20 +/- 1.17\n",
      "Episode length: 2093.80 +/- 295.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.09e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00428  |\n",
      "|    n_updates        | 1159999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2416     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17639    |\n",
      "|    total_timesteps  | 4694327  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 1161081  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4700000, episode_reward=-18.80 +/- 1.17\n",
      "Episode length: 2071.80 +/- 220.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.07e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00255  |\n",
      "|    n_updates        | 1162499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2420     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17671    |\n",
      "|    total_timesteps  | 4701959  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00532  |\n",
      "|    n_updates        | 1162989  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4710000, episode_reward=-15.60 +/- 2.33\n",
      "Episode length: 2502.40 +/- 258.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.5e+03  |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00375  |\n",
      "|    n_updates        | 1164999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2424     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17710    |\n",
      "|    total_timesteps  | 4711515  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00254  |\n",
      "|    n_updates        | 1165378  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2428     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17733    |\n",
      "|    total_timesteps  | 4719106  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 1167276  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4720000, episode_reward=-18.60 +/- 1.20\n",
      "Episode length: 1604.00 +/- 106.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.6e+03  |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 1167499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2432     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17766    |\n",
      "|    total_timesteps  | 4727633  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 1169408  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4730000, episode_reward=-18.20 +/- 0.98\n",
      "Episode length: 1817.00 +/- 175.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.82e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 1169999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2436     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17794    |\n",
      "|    total_timesteps  | 4734421  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 1171105  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4740000, episode_reward=-18.80 +/- 0.98\n",
      "Episode length: 1695.60 +/- 250.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.7e+03  |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 1172499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2440     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17823    |\n",
      "|    total_timesteps  | 4741569  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 1172892  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2444     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17846    |\n",
      "|    total_timesteps  | 4749279  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1174819  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4750000, episode_reward=-16.80 +/- 1.94\n",
      "Episode length: 2374.20 +/- 301.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.37e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 1174999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2448     |\n",
      "|    fps              | 266      |\n",
      "|    time_elapsed     | 17879    |\n",
      "|    total_timesteps  | 4756813  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 1176703  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4760000, episode_reward=-17.60 +/- 1.74\n",
      "Episode length: 2438.40 +/- 239.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.44e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000928 |\n",
      "|    n_updates        | 1177499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2452     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 17919    |\n",
      "|    total_timesteps  | 4766498  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 1179124  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4770000, episode_reward=-16.60 +/- 1.96\n",
      "Episode length: 2466.60 +/- 105.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.47e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 1179999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2456     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 17959    |\n",
      "|    total_timesteps  | 4776454  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00647  |\n",
      "|    n_updates        | 1181613  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4780000, episode_reward=-16.20 +/- 1.94\n",
      "Episode length: 2474.80 +/- 256.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.47e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 1182499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2460     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18002    |\n",
      "|    total_timesteps  | 4787087  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 1184271  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4790000, episode_reward=-16.60 +/- 3.01\n",
      "Episode length: 1795.60 +/- 368.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.8e+03  |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 1184999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2464     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18036    |\n",
      "|    total_timesteps  | 4795793  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 1186448  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4800000, episode_reward=-16.00 +/- 1.90\n",
      "Episode length: 2352.40 +/- 212.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.35e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 1187499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2468     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18073    |\n",
      "|    total_timesteps  | 4804720  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 1188679  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4810000, episode_reward=-17.00 +/- 1.67\n",
      "Episode length: 2135.40 +/- 247.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 1189999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2472     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18110    |\n",
      "|    total_timesteps  | 4813745  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00212  |\n",
      "|    n_updates        | 1190936  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4820000, episode_reward=-17.20 +/- 0.40\n",
      "Episode length: 1897.60 +/- 131.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.9e+03  |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 1192499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2476     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18151    |\n",
      "|    total_timesteps  | 4824762  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00446  |\n",
      "|    n_updates        | 1193690  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4830000, episode_reward=-18.20 +/- 1.17\n",
      "Episode length: 1704.40 +/- 230.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.7e+03  |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 1194999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2480     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18187    |\n",
      "|    total_timesteps  | 4834420  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 1196104  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4840000, episode_reward=-17.40 +/- 1.20\n",
      "Episode length: 2459.40 +/- 110.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.46e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00491  |\n",
      "|    n_updates        | 1197499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2484     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18224    |\n",
      "|    total_timesteps  | 4843312  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 1198327  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4850000, episode_reward=-15.20 +/- 1.17\n",
      "Episode length: 2274.80 +/- 101.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | -15.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 1199999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2488     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18267    |\n",
      "|    total_timesteps  | 4854275  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 1201068  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4860000, episode_reward=-18.40 +/- 0.80\n",
      "Episode length: 1668.00 +/- 108.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.67e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 1202499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2492     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18308    |\n",
      "|    total_timesteps  | 4865374  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 1203843  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4870000, episode_reward=-17.20 +/- 1.47\n",
      "Episode length: 2317.60 +/- 109.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.32e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00757  |\n",
      "|    n_updates        | 1204999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2496     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18345    |\n",
      "|    total_timesteps  | 4874656  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00468  |\n",
      "|    n_updates        | 1206163  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4880000, episode_reward=-17.40 +/- 1.62\n",
      "Episode length: 2622.60 +/- 289.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.62e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 1207499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18387    |\n",
      "|    total_timesteps  | 4884778  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 1208694  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4890000, episode_reward=-17.60 +/- 1.62\n",
      "Episode length: 2648.00 +/- 369.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.65e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 1209999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2504     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18429    |\n",
      "|    total_timesteps  | 4894834  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 1211208  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4900000, episode_reward=-14.60 +/- 1.96\n",
      "Episode length: 2753.20 +/- 230.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.75e+03 |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 1212499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.3e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2508     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18480    |\n",
      "|    total_timesteps  | 4907968  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1214491  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4910000, episode_reward=-17.60 +/- 1.62\n",
      "Episode length: 2096.60 +/- 161.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.1e+03  |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 1214999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.3e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2512     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18518    |\n",
      "|    total_timesteps  | 4917460  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 1216864  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4920000, episode_reward=-14.60 +/- 1.85\n",
      "Episode length: 2552.20 +/- 268.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.55e+03 |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 1217499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.35e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2516     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18565    |\n",
      "|    total_timesteps  | 4929399  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 1219849  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4930000, episode_reward=-18.00 +/- 1.67\n",
      "Episode length: 1724.00 +/- 190.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.72e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00565  |\n",
      "|    n_updates        | 1219999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.35e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2520     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18596    |\n",
      "|    total_timesteps  | 4937442  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000995 |\n",
      "|    n_updates        | 1221860  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4940000, episode_reward=-16.00 +/- 1.79\n",
      "Episode length: 2487.60 +/- 208.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.49e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 1222499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.38e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2524     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18643    |\n",
      "|    total_timesteps  | 4949609  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 1224902  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4950000, episode_reward=-17.80 +/- 1.17\n",
      "Episode length: 1750.20 +/- 273.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.75e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 1224999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.39e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2528     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18677    |\n",
      "|    total_timesteps  | 4958303  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00721  |\n",
      "|    n_updates        | 1227075  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4960000, episode_reward=-17.20 +/- 1.47\n",
      "Episode length: 2243.20 +/- 290.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.24e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 1227499  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4970000, episode_reward=-15.40 +/- 1.02\n",
      "Episode length: 2410.20 +/- 187.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.41e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00353  |\n",
      "|    n_updates        | 1229999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.45e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2532     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18739    |\n",
      "|    total_timesteps  | 4972342  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 1230585  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4980000, episode_reward=-14.60 +/- 0.80\n",
      "Episode length: 2568.40 +/- 49.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+03 |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 1232499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.48e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2536     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18780    |\n",
      "|    total_timesteps  | 4982433  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 1233108  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4990000, episode_reward=-16.60 +/- 1.36\n",
      "Episode length: 2104.00 +/- 179.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.1e+03  |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 1234999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.51e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2540     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18819    |\n",
      "|    total_timesteps  | 4992458  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 1235614  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5000000, episode_reward=-16.60 +/- 2.15\n",
      "Episode length: 2425.40 +/- 133.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.43e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 1237499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.53e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2544     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18858    |\n",
      "|    total_timesteps  | 5001908  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00947  |\n",
      "|    n_updates        | 1237976  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.51e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2548     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18876    |\n",
      "|    total_timesteps  | 5007943  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 1239485  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5010000, episode_reward=-18.20 +/- 1.72\n",
      "Episode length: 1943.20 +/- 273.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.94e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 1239999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.48e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2552     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18903    |\n",
      "|    total_timesteps  | 5014227  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 1241056  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.43e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2556     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18920    |\n",
      "|    total_timesteps  | 5019726  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00638  |\n",
      "|    n_updates        | 1242431  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5020000, episode_reward=-14.80 +/- 2.71\n",
      "Episode length: 2148.60 +/- 340.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.15e+03 |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00883  |\n",
      "|    n_updates        | 1242499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.39e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2560     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18950    |\n",
      "|    total_timesteps  | 5026523  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1244130  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5030000, episode_reward=-19.20 +/- 1.17\n",
      "Episode length: 1337.20 +/- 228.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.34e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 1244999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2564     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18975    |\n",
      "|    total_timesteps  | 5033100  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 1245774  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.34e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2568     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 18991    |\n",
      "|    total_timesteps  | 5038426  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00524  |\n",
      "|    n_updates        | 1247106  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5040000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1138.80 +/- 32.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.14e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 1247499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.3e+03  |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2572     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19013    |\n",
      "|    total_timesteps  | 5043897  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00333  |\n",
      "|    n_updates        | 1248474  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2576     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19029    |\n",
      "|    total_timesteps  | 5049314  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00627  |\n",
      "|    n_updates        | 1249828  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5050000, episode_reward=-19.60 +/- 1.02\n",
      "Episode length: 1484.80 +/- 110.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.48e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0044   |\n",
      "|    n_updates        | 1249999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2580     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19054    |\n",
      "|    total_timesteps  | 5055411  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 1251352  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5060000, episode_reward=-20.20 +/- 0.75\n",
      "Episode length: 1174.00 +/- 114.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 1252499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2584     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19076    |\n",
      "|    total_timesteps  | 5061062  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00372  |\n",
      "|    n_updates        | 1252765  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2588     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19092    |\n",
      "|    total_timesteps  | 5066453  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 1254113  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5070000, episode_reward=-20.20 +/- 0.40\n",
      "Episode length: 1287.00 +/- 133.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.29e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 1254999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2592     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19116    |\n",
      "|    total_timesteps  | 5072599  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 1255649  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2596     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19133    |\n",
      "|    total_timesteps  | 5078095  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00566  |\n",
      "|    n_updates        | 1257023  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5080000, episode_reward=-20.40 +/- 0.80\n",
      "Episode length: 1180.20 +/- 108.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.18e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00321  |\n",
      "|    n_updates        | 1257499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19157    |\n",
      "|    total_timesteps  | 5084324  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000366 |\n",
      "|    n_updates        | 1258580  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2604     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19173    |\n",
      "|    total_timesteps  | 5089601  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 1259900  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5090000, episode_reward=-19.20 +/- 0.75\n",
      "Episode length: 1413.60 +/- 108.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.41e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 1259999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.88e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2608     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19197    |\n",
      "|    total_timesteps  | 5095514  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00983  |\n",
      "|    n_updates        | 1261378  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5100000, episode_reward=-20.00 +/- 0.63\n",
      "Episode length: 1383.60 +/- 151.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.38e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 1262499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.84e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2612     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19221    |\n",
      "|    total_timesteps  | 5101476  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000898 |\n",
      "|    n_updates        | 1262868  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2616     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19239    |\n",
      "|    total_timesteps  | 5107483  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 1264370  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5110000, episode_reward=-20.00 +/- 0.00\n",
      "Episode length: 1324.60 +/- 80.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.32e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00403  |\n",
      "|    n_updates        | 1264999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2620     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19267    |\n",
      "|    total_timesteps  | 5115123  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00554  |\n",
      "|    n_updates        | 1266280  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5120000, episode_reward=-17.40 +/- 1.02\n",
      "Episode length: 1781.20 +/- 132.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.78e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00293  |\n",
      "|    n_updates        | 1267499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2624     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19300    |\n",
      "|    total_timesteps  | 5123466  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00428  |\n",
      "|    n_updates        | 1268366  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5130000, episode_reward=-16.40 +/- 1.20\n",
      "Episode length: 2036.00 +/- 142.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.04e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 1269999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2628     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19334    |\n",
      "|    total_timesteps  | 5131833  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 1270458  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2632     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19357    |\n",
      "|    total_timesteps  | 5139224  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 1272305  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5140000, episode_reward=-19.40 +/- 0.80\n",
      "Episode length: 1768.80 +/- 94.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.77e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 1272499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2636     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19390    |\n",
      "|    total_timesteps  | 5147923  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 1274480  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5150000, episode_reward=-17.00 +/- 1.67\n",
      "Episode length: 2018.40 +/- 300.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.02e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000735 |\n",
      "|    n_updates        | 1274999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2640     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19430    |\n",
      "|    total_timesteps  | 5158275  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00612  |\n",
      "|    n_updates        | 1277068  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5160000, episode_reward=-18.00 +/- 1.26\n",
      "Episode length: 2098.40 +/- 186.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.1e+03  |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00753  |\n",
      "|    n_updates        | 1277499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2644     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19468    |\n",
      "|    total_timesteps  | 5167836  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00538  |\n",
      "|    n_updates        | 1279458  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5170000, episode_reward=-19.00 +/- 1.10\n",
      "Episode length: 2301.60 +/- 291.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.3e+03  |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00378  |\n",
      "|    n_updates        | 1279999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.7e+03  |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2648     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19510    |\n",
      "|    total_timesteps  | 5178438  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 1282109  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5180000, episode_reward=-17.60 +/- 1.74\n",
      "Episode length: 1933.40 +/- 225.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.93e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00607  |\n",
      "|    n_updates        | 1282499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2652     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19549    |\n",
      "|    total_timesteps  | 5188506  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 1284626  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5190000, episode_reward=-17.40 +/- 2.24\n",
      "Episode length: 2510.00 +/- 144.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.51e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 1284999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2656     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19587    |\n",
      "|    total_timesteps  | 5197652  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 1286912  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5200000, episode_reward=-18.80 +/- 0.98\n",
      "Episode length: 2374.40 +/- 239.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.37e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00801  |\n",
      "|    n_updates        | 1287499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2660     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19621    |\n",
      "|    total_timesteps  | 5205641  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00366  |\n",
      "|    n_updates        | 1288910  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5210000, episode_reward=-17.40 +/- 2.58\n",
      "Episode length: 1864.60 +/- 302.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.86e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00558  |\n",
      "|    n_updates        | 1289999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2664     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19655    |\n",
      "|    total_timesteps  | 5214356  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 1291088  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5220000, episode_reward=-17.00 +/- 2.00\n",
      "Episode length: 2180.60 +/- 363.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.18e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 1292499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2668     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19695    |\n",
      "|    total_timesteps  | 5224497  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 1293624  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5230000, episode_reward=-16.40 +/- 2.58\n",
      "Episode length: 2347.60 +/- 339.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.35e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 1294999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2672     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19733    |\n",
      "|    total_timesteps  | 5233737  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.007    |\n",
      "|    n_updates        | 1295934  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5240000, episode_reward=-18.00 +/- 1.26\n",
      "Episode length: 1916.00 +/- 240.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.92e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 1297499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2676     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19765    |\n",
      "|    total_timesteps  | 5241659  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00431  |\n",
      "|    n_updates        | 1297914  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5250000, episode_reward=-18.00 +/- 2.28\n",
      "Episode length: 2493.00 +/- 242.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.49e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 1299999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2680     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19808    |\n",
      "|    total_timesteps  | 5252386  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 1300596  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5260000, episode_reward=-15.20 +/- 2.56\n",
      "Episode length: 2833.60 +/- 408.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.83e+03 |\n",
      "|    mean_reward      | -15.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00633  |\n",
      "|    n_updates        | 1302499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2684     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19850    |\n",
      "|    total_timesteps  | 5262130  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00843  |\n",
      "|    n_updates        | 1303032  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5270000, episode_reward=-17.60 +/- 1.50\n",
      "Episode length: 2481.20 +/- 307.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.48e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 1304999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2688     |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 19891    |\n",
      "|    total_timesteps  | 5272375  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 1305593  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5280000, episode_reward=-17.60 +/- 1.50\n",
      "Episode length: 2649.40 +/- 355.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.65e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 1307499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2692     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 19930    |\n",
      "|    total_timesteps  | 5281585  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 1307896  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5290000, episode_reward=-17.80 +/- 0.98\n",
      "Episode length: 2432.00 +/- 130.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.43e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 1309999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2696     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 19975    |\n",
      "|    total_timesteps  | 5292950  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 1310737  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5300000, episode_reward=-17.80 +/- 2.14\n",
      "Episode length: 2819.00 +/- 193.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.82e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 1312499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2700     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20022    |\n",
      "|    total_timesteps  | 5304738  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 1313684  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5310000, episode_reward=-17.80 +/- 1.17\n",
      "Episode length: 2495.00 +/- 219.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.5e+03  |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00469  |\n",
      "|    n_updates        | 1314999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2704     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20064    |\n",
      "|    total_timesteps  | 5315050  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 1316262  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5320000, episode_reward=-19.00 +/- 0.63\n",
      "Episode length: 2128.40 +/- 138.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.13e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00217  |\n",
      "|    n_updates        | 1317499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.29e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2708     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20103    |\n",
      "|    total_timesteps  | 5325004  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 1318750  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5330000, episode_reward=-16.60 +/- 1.85\n",
      "Episode length: 2312.60 +/- 149.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.31e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 1319999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.32e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2712     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20140    |\n",
      "|    total_timesteps  | 5333851  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 1320962  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5340000, episode_reward=-16.00 +/- 1.41\n",
      "Episode length: 2354.20 +/- 234.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.35e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00875  |\n",
      "|    n_updates        | 1322499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.34e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2716     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20174    |\n",
      "|    total_timesteps  | 5341974  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 1322993  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5350000, episode_reward=-18.00 +/- 1.79\n",
      "Episode length: 1920.40 +/- 380.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.92e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 1324999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2720     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20212    |\n",
      "|    total_timesteps  | 5351928  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 1325481  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5360000, episode_reward=-15.60 +/- 1.85\n",
      "Episode length: 2462.40 +/- 262.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.46e+03 |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 1327499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.38e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2724     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20253    |\n",
      "|    total_timesteps  | 5361868  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00357  |\n",
      "|    n_updates        | 1327966  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.38e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2728     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20277    |\n",
      "|    total_timesteps  | 5369825  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00474  |\n",
      "|    n_updates        | 1329956  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5370000, episode_reward=-17.60 +/- 1.50\n",
      "Episode length: 2007.40 +/- 231.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.01e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 1329999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.39e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2732     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20311    |\n",
      "|    total_timesteps  | 5378320  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00963  |\n",
      "|    n_updates        | 1332079  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5380000, episode_reward=-20.00 +/- 0.89\n",
      "Episode length: 1508.60 +/- 272.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.51e+03 |\n",
      "|    mean_reward      | -20      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 1332499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.39e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2736     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20342    |\n",
      "|    total_timesteps  | 5386526  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00481  |\n",
      "|    n_updates        | 1334131  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5390000, episode_reward=-19.00 +/- 0.89\n",
      "Episode length: 1607.40 +/- 251.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.61e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000995 |\n",
      "|    n_updates        | 1334999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.36e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2740     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20371    |\n",
      "|    total_timesteps  | 5393927  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00443  |\n",
      "|    n_updates        | 1335981  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5400000, episode_reward=-14.80 +/- 1.47\n",
      "Episode length: 2292.00 +/- 218.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.29e+03 |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 1337499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.35e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2744     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20407    |\n",
      "|    total_timesteps  | 5402572  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00679  |\n",
      "|    n_updates        | 1338142  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.32e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2748     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20429    |\n",
      "|    total_timesteps  | 5409977  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 1339994  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5410000, episode_reward=-15.80 +/- 1.47\n",
      "Episode length: 2744.60 +/- 257.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.74e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 1339999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.31e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2752     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20469    |\n",
      "|    total_timesteps  | 5419237  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00381  |\n",
      "|    n_updates        | 1342309  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5420000, episode_reward=-17.20 +/- 1.60\n",
      "Episode length: 2380.40 +/- 211.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.38e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000995 |\n",
      "|    n_updates        | 1342499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.31e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2756     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20507    |\n",
      "|    total_timesteps  | 5428270  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 1344567  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5430000, episode_reward=-17.00 +/- 1.26\n",
      "Episode length: 2160.80 +/- 105.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.16e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 1344999  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5440000, episode_reward=-16.60 +/- 1.96\n",
      "Episode length: 2541.20 +/- 134.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.54e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00576  |\n",
      "|    n_updates        | 1347499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2760     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20569    |\n",
      "|    total_timesteps  | 5442366  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00636  |\n",
      "|    n_updates        | 1348091  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5450000, episode_reward=-15.20 +/- 0.98\n",
      "Episode length: 2352.40 +/- 78.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.35e+03 |\n",
      "|    mean_reward      | -15.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000947 |\n",
      "|    n_updates        | 1349999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.38e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2764     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20609    |\n",
      "|    total_timesteps  | 5452291  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 1350572  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5460000, episode_reward=-14.20 +/- 3.92\n",
      "Episode length: 2872.80 +/- 631.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.87e+03 |\n",
      "|    mean_reward      | -14.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 1352499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.38e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2768     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20653    |\n",
      "|    total_timesteps  | 5462772  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00175  |\n",
      "|    n_updates        | 1353192  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5470000, episode_reward=-18.40 +/- 0.80\n",
      "Episode length: 2205.20 +/- 295.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 1354999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.39e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2772     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20692    |\n",
      "|    total_timesteps  | 5472797  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000853 |\n",
      "|    n_updates        | 1355699  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5480000, episode_reward=-15.40 +/- 1.36\n",
      "Episode length: 2394.60 +/- 240.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.39e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00708  |\n",
      "|    n_updates        | 1357499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.41e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2776     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20731    |\n",
      "|    total_timesteps  | 5482243  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00613  |\n",
      "|    n_updates        | 1358060  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2780     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20754    |\n",
      "|    total_timesteps  | 5489815  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00742  |\n",
      "|    n_updates        | 1359953  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5490000, episode_reward=-18.20 +/- 1.60\n",
      "Episode length: 1863.80 +/- 336.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.86e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00363  |\n",
      "|    n_updates        | 1359999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2784     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20791    |\n",
      "|    total_timesteps  | 5499582  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00213  |\n",
      "|    n_updates        | 1362395  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5500000, episode_reward=-19.40 +/- 1.02\n",
      "Episode length: 1721.60 +/- 163.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.72e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 1362499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2788     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20828    |\n",
      "|    total_timesteps  | 5509212  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00941  |\n",
      "|    n_updates        | 1364802  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5510000, episode_reward=-16.60 +/- 1.62\n",
      "Episode length: 2924.40 +/- 431.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.92e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 1364999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.38e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2792     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20870    |\n",
      "|    total_timesteps  | 5519116  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 1367278  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5520000, episode_reward=-18.00 +/- 2.28\n",
      "Episode length: 1917.40 +/- 354.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.92e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 1367499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.35e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2796     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20906    |\n",
      "|    total_timesteps  | 5528337  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 1369584  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5530000, episode_reward=-16.40 +/- 1.36\n",
      "Episode length: 2345.60 +/- 49.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.35e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 1369999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.33e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2800     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 20944    |\n",
      "|    total_timesteps  | 5537611  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00415  |\n",
      "|    n_updates        | 1371902  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5540000, episode_reward=-16.20 +/- 1.17\n",
      "Episode length: 2384.60 +/- 33.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.38e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00328  |\n",
      "|    n_updates        | 1372499  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5550000, episode_reward=-17.80 +/- 1.94\n",
      "Episode length: 2095.40 +/- 251.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.1e+03  |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 1374999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2804     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21008    |\n",
      "|    total_timesteps  | 5552418  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 1375604  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5560000, episode_reward=-14.80 +/- 3.97\n",
      "Episode length: 2460.40 +/- 511.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.46e+03 |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 1377499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2808     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21046    |\n",
      "|    total_timesteps  | 5561791  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00739  |\n",
      "|    n_updates        | 1377947  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5570000, episode_reward=-17.60 +/- 1.02\n",
      "Episode length: 2040.60 +/- 147.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.04e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 1379999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.41e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2812     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21093    |\n",
      "|    total_timesteps  | 5574398  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00499  |\n",
      "|    n_updates        | 1381099  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5580000, episode_reward=-18.40 +/- 1.62\n",
      "Episode length: 2150.80 +/- 579.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.15e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 1382499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.43e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2816     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21133    |\n",
      "|    total_timesteps  | 5584538  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00422  |\n",
      "|    n_updates        | 1383634  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5590000, episode_reward=-16.60 +/- 1.85\n",
      "Episode length: 2920.80 +/- 175.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.92e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00399  |\n",
      "|    n_updates        | 1384999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.42e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2820     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21173    |\n",
      "|    total_timesteps  | 5593966  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 1385991  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5600000, episode_reward=-17.80 +/- 1.47\n",
      "Episode length: 1979.20 +/- 212.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.98e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 1387499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.42e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2824     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21211    |\n",
      "|    total_timesteps  | 5603579  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 1388394  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5610000, episode_reward=-17.00 +/- 1.26\n",
      "Episode length: 2468.00 +/- 450.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.47e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00658  |\n",
      "|    n_updates        | 1389999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.42e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2828     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21246    |\n",
      "|    total_timesteps  | 5611644  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00392  |\n",
      "|    n_updates        | 1390410  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5620000, episode_reward=-14.80 +/- 1.47\n",
      "Episode length: 2851.00 +/- 177.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.85e+03 |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 1392499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.44e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2832     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21288    |\n",
      "|    total_timesteps  | 5621945  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00599  |\n",
      "|    n_updates        | 1392986  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5630000, episode_reward=-20.40 +/- 0.80\n",
      "Episode length: 1265.40 +/- 153.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 1394999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.45e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2836     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21324    |\n",
      "|    total_timesteps  | 5631867  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 1395466  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.46e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2840     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21348    |\n",
      "|    total_timesteps  | 5639787  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 1397446  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5640000, episode_reward=-16.40 +/- 2.58\n",
      "Episode length: 2392.40 +/- 254.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.39e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 1397499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.45e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2844     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21383    |\n",
      "|    total_timesteps  | 5647973  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 1399493  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5650000, episode_reward=-18.60 +/- 1.85\n",
      "Episode length: 2142.20 +/- 487.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 1399999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.49e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2848     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21425    |\n",
      "|    total_timesteps  | 5659185  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00214  |\n",
      "|    n_updates        | 1402296  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5660000, episode_reward=-16.00 +/- 2.19\n",
      "Episode length: 2410.80 +/- 536.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.41e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 1402499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.5e+03  |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2852     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21466    |\n",
      "|    total_timesteps  | 5669298  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 1404824  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5670000, episode_reward=-19.00 +/- 1.41\n",
      "Episode length: 1807.20 +/- 156.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.81e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 1404999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.5e+03  |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2856     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21502    |\n",
      "|    total_timesteps  | 5678603  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 1407150  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5680000, episode_reward=-16.80 +/- 0.75\n",
      "Episode length: 2199.60 +/- 104.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.2e+03  |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 1407499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.46e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2860     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21541    |\n",
      "|    total_timesteps  | 5688451  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00228  |\n",
      "|    n_updates        | 1409612  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5690000, episode_reward=-18.00 +/- 0.00\n",
      "Episode length: 2564.20 +/- 137.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.56e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 1409999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.47e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2864     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21584    |\n",
      "|    total_timesteps  | 5699055  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00369  |\n",
      "|    n_updates        | 1412263  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5700000, episode_reward=-17.60 +/- 1.62\n",
      "Episode length: 2122.80 +/- 226.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.12e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 1412499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.45e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2868     |\n",
      "|    fps              | 264      |\n",
      "|    time_elapsed     | 21620    |\n",
      "|    total_timesteps  | 5708196  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 1414548  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5710000, episode_reward=-15.80 +/- 4.53\n",
      "Episode length: 2782.20 +/- 399.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.78e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 1414999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.45e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2872     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21660    |\n",
      "|    total_timesteps  | 5717495  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 1416873  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5720000, episode_reward=-18.00 +/- 0.89\n",
      "Episode length: 2098.80 +/- 115.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.1e+03  |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0038   |\n",
      "|    n_updates        | 1417499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.44e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2876     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21697    |\n",
      "|    total_timesteps  | 5726523  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 1419130  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5730000, episode_reward=-16.20 +/- 2.79\n",
      "Episode length: 2362.60 +/- 307.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.36e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000865 |\n",
      "|    n_updates        | 1419999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.49e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2880     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21743    |\n",
      "|    total_timesteps  | 5738719  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 1422179  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5740000, episode_reward=-17.60 +/- 1.36\n",
      "Episode length: 2551.80 +/- 121.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.55e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00561  |\n",
      "|    n_updates        | 1422499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.5e+03  |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2884     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21786    |\n",
      "|    total_timesteps  | 5749398  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00597  |\n",
      "|    n_updates        | 1424849  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5750000, episode_reward=-19.40 +/- 1.62\n",
      "Episode length: 2217.60 +/- 407.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.22e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00433  |\n",
      "|    n_updates        | 1424999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.5e+03  |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2888     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21825    |\n",
      "|    total_timesteps  | 5759209  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 1427302  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5760000, episode_reward=-17.40 +/- 2.15\n",
      "Episode length: 2048.40 +/- 297.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.05e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 1427499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.49e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2892     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21860    |\n",
      "|    total_timesteps  | 5767968  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 1429491  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5770000, episode_reward=-17.40 +/- 2.73\n",
      "Episode length: 2089.20 +/- 358.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.09e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00369  |\n",
      "|    n_updates        | 1429999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.46e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2896     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21889    |\n",
      "|    total_timesteps  | 5774598  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 1431149  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5780000, episode_reward=-19.80 +/- 0.98\n",
      "Episode length: 1621.00 +/- 217.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.62e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00916  |\n",
      "|    n_updates        | 1432499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.46e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2900     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21923    |\n",
      "|    total_timesteps  | 5783585  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 1433396  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2904     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21940    |\n",
      "|    total_timesteps  | 5789450  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00311  |\n",
      "|    n_updates        | 1434862  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5790000, episode_reward=-16.40 +/- 2.42\n",
      "Episode length: 1872.00 +/- 301.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.87e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 1434999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.33e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2908     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21966    |\n",
      "|    total_timesteps  | 5795246  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 1436311  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5800000, episode_reward=-19.00 +/- 1.10\n",
      "Episode length: 1441.00 +/- 235.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.44e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 1437499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.29e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2912     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 21996    |\n",
      "|    total_timesteps  | 5803352  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 1438337  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5810000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1069.80 +/- 18.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.07e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00972  |\n",
      "|    n_updates        | 1439999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.27e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2916     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22025    |\n",
      "|    total_timesteps  | 5811322  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00238  |\n",
      "|    n_updates        | 1440330  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2920     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22043    |\n",
      "|    total_timesteps  | 5817418  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 1441854  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5820000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1902.40 +/- 167.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.9e+03  |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00845  |\n",
      "|    n_updates        | 1442499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2924     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22077    |\n",
      "|    total_timesteps  | 5825772  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 1443942  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5830000, episode_reward=-18.60 +/- 1.20\n",
      "Episode length: 2186.80 +/- 133.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.19e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 1444999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2928     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22109    |\n",
      "|    total_timesteps  | 5833423  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 1445855  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5840000, episode_reward=-18.20 +/- 1.72\n",
      "Episode length: 1618.40 +/- 327.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.62e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 1447499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2932     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22141    |\n",
      "|    total_timesteps  | 5841808  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 1447951  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2936     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22160    |\n",
      "|    total_timesteps  | 5848085  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 1449521  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5850000, episode_reward=-16.80 +/- 1.33\n",
      "Episode length: 1948.40 +/- 152.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.95e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 1449999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2940     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22196    |\n",
      "|    total_timesteps  | 5857072  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00809  |\n",
      "|    n_updates        | 1451767  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5860000, episode_reward=-17.00 +/- 1.41\n",
      "Episode length: 2017.00 +/- 106.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.02e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00848  |\n",
      "|    n_updates        | 1452499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2944     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22231    |\n",
      "|    total_timesteps  | 5865976  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00608  |\n",
      "|    n_updates        | 1453993  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5870000, episode_reward=-13.60 +/- 5.31\n",
      "Episode length: 2333.00 +/- 518.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.33e+03 |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 1454999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2948     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22266    |\n",
      "|    total_timesteps  | 5874247  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 1456061  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5880000, episode_reward=-18.20 +/- 1.47\n",
      "Episode length: 1731.20 +/- 220.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.73e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 1457499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2952     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22299    |\n",
      "|    total_timesteps  | 5882820  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00228  |\n",
      "|    n_updates        | 1458204  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2956     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22317    |\n",
      "|    total_timesteps  | 5888748  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00709  |\n",
      "|    n_updates        | 1459686  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5890000, episode_reward=-20.60 +/- 0.80\n",
      "Episode length: 1153.60 +/- 68.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 1459999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2960     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22342    |\n",
      "|    total_timesteps  | 5895498  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0052   |\n",
      "|    n_updates        | 1461374  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5900000, episode_reward=-17.40 +/- 3.01\n",
      "Episode length: 1879.00 +/- 419.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.88e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00386  |\n",
      "|    n_updates        | 1462499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2964     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22368    |\n",
      "|    total_timesteps  | 5901414  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 1462853  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2968     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22389    |\n",
      "|    total_timesteps  | 5908269  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00683  |\n",
      "|    n_updates        | 1464567  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5910000, episode_reward=-17.80 +/- 1.94\n",
      "Episode length: 1737.40 +/- 321.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.74e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 1464999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2972     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22422    |\n",
      "|    total_timesteps  | 5916695  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 1466673  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5920000, episode_reward=-19.80 +/- 1.17\n",
      "Episode length: 1596.00 +/- 124.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.6e+03  |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 1467499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2976     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22456    |\n",
      "|    total_timesteps  | 5925663  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0054   |\n",
      "|    n_updates        | 1468915  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5930000, episode_reward=-19.00 +/- 1.26\n",
      "Episode length: 1647.80 +/- 189.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.65e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 1469999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2980     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22485    |\n",
      "|    total_timesteps  | 5933132  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00544  |\n",
      "|    n_updates        | 1470782  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5940000, episode_reward=-18.20 +/- 1.17\n",
      "Episode length: 1651.60 +/- 117.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.65e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 1472499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2984     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22517    |\n",
      "|    total_timesteps  | 5941345  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 1472836  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.88e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2988     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22534    |\n",
      "|    total_timesteps  | 5946932  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 1474232  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5950000, episode_reward=-18.60 +/- 1.62\n",
      "Episode length: 1707.00 +/- 250.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.71e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00503  |\n",
      "|    n_updates        | 1474999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2992     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22562    |\n",
      "|    total_timesteps  | 5953730  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 1475932  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5960000, episode_reward=-18.20 +/- 0.75\n",
      "Episode length: 1980.00 +/- 198.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.98e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 1477499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.87e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2996     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22595    |\n",
      "|    total_timesteps  | 5961865  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00253  |\n",
      "|    n_updates        | 1477966  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3000     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22617    |\n",
      "|    total_timesteps  | 5969302  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00298  |\n",
      "|    n_updates        | 1479825  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5970000, episode_reward=-19.00 +/- 2.10\n",
      "Episode length: 1835.80 +/- 275.97\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.84e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 1479999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.88e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3004     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22650    |\n",
      "|    total_timesteps  | 5977464  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00327  |\n",
      "|    n_updates        | 1481865  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5980000, episode_reward=-17.40 +/- 1.50\n",
      "Episode length: 2328.20 +/- 179.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.33e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 1482499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3008     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22689    |\n",
      "|    total_timesteps  | 5987242  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 1484310  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5990000, episode_reward=-19.20 +/- 0.75\n",
      "Episode length: 2028.00 +/- 279.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.03e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00487  |\n",
      "|    n_updates        | 1484999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.93e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3012     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22725    |\n",
      "|    total_timesteps  | 5996239  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00227  |\n",
      "|    n_updates        | 1486559  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6000000, episode_reward=-18.80 +/- 1.17\n",
      "Episode length: 1927.60 +/- 218.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.93e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 1487499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.93e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3016     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22759    |\n",
      "|    total_timesteps  | 6004779  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0042   |\n",
      "|    n_updates        | 1488694  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6010000, episode_reward=-18.40 +/- 0.80\n",
      "Episode length: 1818.00 +/- 176.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.82e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 1489999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3020     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22793    |\n",
      "|    total_timesteps  | 6013514  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00703  |\n",
      "|    n_updates        | 1490878  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6020000, episode_reward=-19.40 +/- 0.80\n",
      "Episode length: 1705.20 +/- 184.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.71e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00765  |\n",
      "|    n_updates        | 1492499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3024     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22827    |\n",
      "|    total_timesteps  | 6022477  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00482  |\n",
      "|    n_updates        | 1493119  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3028     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22849    |\n",
      "|    total_timesteps  | 6029670  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00926  |\n",
      "|    n_updates        | 1494917  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6030000, episode_reward=-18.40 +/- 1.02\n",
      "Episode length: 1690.00 +/- 138.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.69e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00522  |\n",
      "|    n_updates        | 1494999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3032     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22878    |\n",
      "|    total_timesteps  | 6036794  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 1496698  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6040000, episode_reward=-18.20 +/- 0.75\n",
      "Episode length: 1773.20 +/- 211.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.77e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 1497499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3036     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22913    |\n",
      "|    total_timesteps  | 6045866  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 1498966  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6050000, episode_reward=-17.80 +/- 1.83\n",
      "Episode length: 1933.20 +/- 237.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.93e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 1499999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3040     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22944    |\n",
      "|    total_timesteps  | 6053325  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 1500831  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6060000, episode_reward=-17.60 +/- 1.74\n",
      "Episode length: 2294.80 +/- 223.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.29e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 1502499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3044     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 22980    |\n",
      "|    total_timesteps  | 6062044  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00569  |\n",
      "|    n_updates        | 1503010  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6070000, episode_reward=-19.80 +/- 1.17\n",
      "Episode length: 1508.00 +/- 393.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.51e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00739  |\n",
      "|    n_updates        | 1504999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3048     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23016    |\n",
      "|    total_timesteps  | 6071895  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00585  |\n",
      "|    n_updates        | 1505473  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6080000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1171.60 +/- 68.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 1507499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3052     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23052    |\n",
      "|    total_timesteps  | 6082204  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 1508050  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3056     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23075    |\n",
      "|    total_timesteps  | 6089872  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00228  |\n",
      "|    n_updates        | 1509967  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6090000, episode_reward=-20.20 +/- 0.75\n",
      "Episode length: 1269.40 +/- 171.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.27e+03 |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000884 |\n",
      "|    n_updates        | 1509999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3060     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23103    |\n",
      "|    total_timesteps  | 6097059  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 1511764  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6100000, episode_reward=-19.80 +/- 1.17\n",
      "Episode length: 1736.80 +/- 252.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.74e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 1512499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3064     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23131    |\n",
      "|    total_timesteps  | 6104098  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00406  |\n",
      "|    n_updates        | 1513524  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6110000, episode_reward=-17.40 +/- 0.49\n",
      "Episode length: 2224.60 +/- 139.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.22e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 1514999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3068     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23166    |\n",
      "|    total_timesteps  | 6112362  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00397  |\n",
      "|    n_updates        | 1515590  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6120000, episode_reward=-17.80 +/- 2.14\n",
      "Episode length: 2812.40 +/- 310.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.81e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00427  |\n",
      "|    n_updates        | 1517499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3072     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23209    |\n",
      "|    total_timesteps  | 6122722  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 1518180  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6130000, episode_reward=-18.00 +/- 1.90\n",
      "Episode length: 2950.60 +/- 215.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.95e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000714 |\n",
      "|    n_updates        | 1519999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3076     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23255    |\n",
      "|    total_timesteps  | 6133856  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00367  |\n",
      "|    n_updates        | 1520963  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6140000, episode_reward=-18.60 +/- 1.36\n",
      "Episode length: 1832.40 +/- 402.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.83e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 1522499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3080     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23295    |\n",
      "|    total_timesteps  | 6144522  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 1523630  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6150000, episode_reward=-18.20 +/- 0.75\n",
      "Episode length: 2755.00 +/- 190.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.76e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 1524999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3084     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23340    |\n",
      "|    total_timesteps  | 6155711  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000905 |\n",
      "|    n_updates        | 1526427  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6160000, episode_reward=-17.60 +/- 1.02\n",
      "Episode length: 2324.20 +/- 152.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.32e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 1527499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3088     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23385    |\n",
      "|    total_timesteps  | 6167207  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 1529301  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6170000, episode_reward=-18.40 +/- 1.36\n",
      "Episode length: 1965.00 +/- 289.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.96e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 1529999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3092     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23416    |\n",
      "|    total_timesteps  | 6174841  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00432  |\n",
      "|    n_updates        | 1531210  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6180000, episode_reward=-16.00 +/- 2.00\n",
      "Episode length: 2658.60 +/- 498.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.66e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 1532499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3096     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23455    |\n",
      "|    total_timesteps  | 6183800  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 1533449  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6190000, episode_reward=-19.20 +/- 0.75\n",
      "Episode length: 1564.40 +/- 199.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.56e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00206  |\n",
      "|    n_updates        | 1534999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3100     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23486    |\n",
      "|    total_timesteps  | 6191878  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000757 |\n",
      "|    n_updates        | 1535469  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6200000, episode_reward=-17.80 +/- 0.75\n",
      "Episode length: 2168.00 +/- 351.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.17e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00482  |\n",
      "|    n_updates        | 1537499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3104     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23526    |\n",
      "|    total_timesteps  | 6202127  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 1538031  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3108     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23546    |\n",
      "|    total_timesteps  | 6208670  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00478  |\n",
      "|    n_updates        | 1539667  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6210000, episode_reward=-16.40 +/- 2.42\n",
      "Episode length: 2408.40 +/- 321.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.41e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 1539999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3112     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23584    |\n",
      "|    total_timesteps  | 6218134  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 1542033  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6220000, episode_reward=-17.60 +/- 1.20\n",
      "Episode length: 2139.80 +/- 360.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 1542499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3116     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23619    |\n",
      "|    total_timesteps  | 6226563  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 1544140  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6230000, episode_reward=-19.00 +/- 0.89\n",
      "Episode length: 1582.60 +/- 209.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.58e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00858  |\n",
      "|    n_updates        | 1544999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3120     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23656    |\n",
      "|    total_timesteps  | 6236395  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 1546598  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6240000, episode_reward=-15.60 +/- 1.62\n",
      "Episode length: 2070.00 +/- 135.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.07e+03 |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00242  |\n",
      "|    n_updates        | 1547499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3124     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23690    |\n",
      "|    total_timesteps  | 6244697  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 1548674  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6250000, episode_reward=-18.40 +/- 1.50\n",
      "Episode length: 1698.60 +/- 214.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.7e+03  |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 1549999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3128     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23717    |\n",
      "|    total_timesteps  | 6251426  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00432  |\n",
      "|    n_updates        | 1550356  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3132     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23738    |\n",
      "|    total_timesteps  | 6258250  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 1552062  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6260000, episode_reward=-18.80 +/- 0.75\n",
      "Episode length: 1761.60 +/- 145.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.76e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00482  |\n",
      "|    n_updates        | 1552499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3136     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23765    |\n",
      "|    total_timesteps  | 6264819  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 1553704  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6270000, episode_reward=-17.00 +/- 1.79\n",
      "Episode length: 1895.60 +/- 231.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.9e+03  |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 1554999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3140     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23800    |\n",
      "|    total_timesteps  | 6273574  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 1555893  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6280000, episode_reward=-11.00 +/- 2.76\n",
      "Episode length: 2793.00 +/- 318.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.79e+03 |\n",
      "|    mean_reward      | -11      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00411  |\n",
      "|    n_updates        | 1557499  |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3144     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23840    |\n",
      "|    total_timesteps  | 6282760  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00497  |\n",
      "|    n_updates        | 1558189  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3148     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23859    |\n",
      "|    total_timesteps  | 6289083  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 1559770  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6290000, episode_reward=-17.80 +/- 1.17\n",
      "Episode length: 2491.80 +/- 265.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.49e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 1559999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3152     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23901    |\n",
      "|    total_timesteps  | 6299499  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 1562374  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6300000, episode_reward=-17.00 +/- 2.28\n",
      "Episode length: 2220.80 +/- 213.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.22e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 1562499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3156     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23937    |\n",
      "|    total_timesteps  | 6308256  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 1564563  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6310000, episode_reward=-16.00 +/- 1.26\n",
      "Episode length: 2321.40 +/- 132.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.32e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 1564999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3160     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 23978    |\n",
      "|    total_timesteps  | 6318469  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 1567117  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6320000, episode_reward=-14.20 +/- 1.17\n",
      "Episode length: 2341.60 +/- 213.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.34e+03 |\n",
      "|    mean_reward      | -14.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 1567499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3164     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24020    |\n",
      "|    total_timesteps  | 6329167  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 1569791  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6330000, episode_reward=-18.60 +/- 1.36\n",
      "Episode length: 1918.20 +/- 268.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.92e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000784 |\n",
      "|    n_updates        | 1569999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3168     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24051    |\n",
      "|    total_timesteps  | 6336889  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.002    |\n",
      "|    n_updates        | 1571722  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6340000, episode_reward=-19.60 +/- 0.49\n",
      "Episode length: 1348.60 +/- 157.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.35e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000998 |\n",
      "|    n_updates        | 1572499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3172     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24077    |\n",
      "|    total_timesteps  | 6343473  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000571 |\n",
      "|    n_updates        | 1573368  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6350000, episode_reward=-15.40 +/- 2.15\n",
      "Episode length: 2201.40 +/- 377.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.2e+03  |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 1574999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3176     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24112    |\n",
      "|    total_timesteps  | 6351862  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00638  |\n",
      "|    n_updates        | 1575465  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3180     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24134    |\n",
      "|    total_timesteps  | 6359123  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 1577280  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6360000, episode_reward=-18.00 +/- 0.89\n",
      "Episode length: 1901.80 +/- 149.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.9e+03  |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00784  |\n",
      "|    n_updates        | 1577499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3184     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24171    |\n",
      "|    total_timesteps  | 6368819  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00896  |\n",
      "|    n_updates        | 1579704  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6370000, episode_reward=-19.20 +/- 1.33\n",
      "Episode length: 1653.80 +/- 180.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.65e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00381  |\n",
      "|    n_updates        | 1579999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3188     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24203    |\n",
      "|    total_timesteps  | 6377052  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 1581762  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6380000, episode_reward=-17.40 +/- 1.62\n",
      "Episode length: 2042.80 +/- 181.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.04e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 1582499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3192     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24238    |\n",
      "|    total_timesteps  | 6385586  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 1583896  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6390000, episode_reward=-17.40 +/- 2.73\n",
      "Episode length: 1782.00 +/- 406.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.78e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 1584999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3196     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24271    |\n",
      "|    total_timesteps  | 6394179  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00727  |\n",
      "|    n_updates        | 1586044  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6400000, episode_reward=-18.20 +/- 1.33\n",
      "Episode length: 1922.40 +/- 321.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.92e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 1587499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3200     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24302    |\n",
      "|    total_timesteps  | 6401869  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00956  |\n",
      "|    n_updates        | 1587967  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3204     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24325    |\n",
      "|    total_timesteps  | 6409357  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 1589839  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6410000, episode_reward=-17.00 +/- 1.90\n",
      "Episode length: 2083.80 +/- 185.19\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.08e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0053   |\n",
      "|    n_updates        | 1589999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3208     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24362    |\n",
      "|    total_timesteps  | 6418692  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 1592172  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6420000, episode_reward=-18.40 +/- 1.85\n",
      "Episode length: 2450.60 +/- 346.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.45e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0073   |\n",
      "|    n_updates        | 1592499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3212     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24402    |\n",
      "|    total_timesteps  | 6428508  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 1594626  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6430000, episode_reward=-16.80 +/- 1.72\n",
      "Episode length: 2181.20 +/- 341.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.18e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000905 |\n",
      "|    n_updates        | 1594999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3216     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24441    |\n",
      "|    total_timesteps  | 6438471  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 1597117  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6440000, episode_reward=-17.40 +/- 2.33\n",
      "Episode length: 2030.40 +/- 250.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.03e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00539  |\n",
      "|    n_updates        | 1597499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3220     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24480    |\n",
      "|    total_timesteps  | 6448292  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000694 |\n",
      "|    n_updates        | 1599572  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6450000, episode_reward=-16.20 +/- 1.60\n",
      "Episode length: 2450.00 +/- 143.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.45e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00281  |\n",
      "|    n_updates        | 1599999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3224     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24523    |\n",
      "|    total_timesteps  | 6459228  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00447  |\n",
      "|    n_updates        | 1602306  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6460000, episode_reward=-17.80 +/- 1.72\n",
      "Episode length: 1948.40 +/- 257.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.95e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00572  |\n",
      "|    n_updates        | 1602499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3228     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24560    |\n",
      "|    total_timesteps  | 6468676  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 1604668  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6470000, episode_reward=-16.40 +/- 1.36\n",
      "Episode length: 2142.40 +/- 224.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 1604999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3232     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24599    |\n",
      "|    total_timesteps  | 6478605  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00824  |\n",
      "|    n_updates        | 1607151  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6480000, episode_reward=-15.80 +/- 0.40\n",
      "Episode length: 2389.80 +/- 197.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.39e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 1607499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3236     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24639    |\n",
      "|    total_timesteps  | 6488270  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 1609567  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6490000, episode_reward=-18.60 +/- 1.62\n",
      "Episode length: 2122.00 +/- 209.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.12e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00357  |\n",
      "|    n_updates        | 1609999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3240     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24669    |\n",
      "|    total_timesteps  | 6495395  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00553  |\n",
      "|    n_updates        | 1611348  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6500000, episode_reward=-18.60 +/- 2.06\n",
      "Episode length: 2348.00 +/- 229.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.35e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 1612499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3244     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24701    |\n",
      "|    total_timesteps  | 6502809  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 1613202  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6510000, episode_reward=-18.20 +/- 0.75\n",
      "Episode length: 2188.20 +/- 237.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.19e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 1614999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3248     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24738    |\n",
      "|    total_timesteps  | 6511736  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 1615433  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3252     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24763    |\n",
      "|    total_timesteps  | 6519969  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 1617492  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6520000, episode_reward=-18.40 +/- 1.02\n",
      "Episode length: 2219.00 +/- 206.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.22e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 1617499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3256     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24794    |\n",
      "|    total_timesteps  | 6527189  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0322   |\n",
      "|    n_updates        | 1619297  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6530000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1231.00 +/- 124.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.23e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 1619999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3260     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24822    |\n",
      "|    total_timesteps  | 6534654  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 1621163  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6540000, episode_reward=-17.00 +/- 2.45\n",
      "Episode length: 2343.00 +/- 234.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.34e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 1622499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3264     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24862    |\n",
      "|    total_timesteps  | 6544804  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 1623700  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6550000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1147.40 +/- 53.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 1624999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3268     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24889    |\n",
      "|    total_timesteps  | 6552005  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 1625501  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3272     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24913    |\n",
      "|    total_timesteps  | 6559832  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00293  |\n",
      "|    n_updates        | 1627457  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6560000, episode_reward=-17.60 +/- 1.02\n",
      "Episode length: 1892.40 +/- 238.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.89e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 1627499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3276     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24940    |\n",
      "|    total_timesteps  | 6566421  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00686  |\n",
      "|    n_updates        | 1629105  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6570000, episode_reward=-16.60 +/- 2.24\n",
      "Episode length: 2010.80 +/- 278.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.01e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 1629999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3280     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 24970    |\n",
      "|    total_timesteps  | 6573559  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00427  |\n",
      "|    n_updates        | 1630889  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6580000, episode_reward=-15.40 +/- 1.85\n",
      "Episode length: 2419.60 +/- 211.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.42e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 1632499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3284     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25015    |\n",
      "|    total_timesteps  | 6584830  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00457  |\n",
      "|    n_updates        | 1633707  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6590000, episode_reward=-18.00 +/- 1.10\n",
      "Episode length: 1984.40 +/- 121.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.98e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 1634999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3288     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25051    |\n",
      "|    total_timesteps  | 6594058  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00502  |\n",
      "|    n_updates        | 1636014  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6600000, episode_reward=-16.60 +/- 2.06\n",
      "Episode length: 2283.20 +/- 180.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.28e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00622  |\n",
      "|    n_updates        | 1637499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3292     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25092    |\n",
      "|    total_timesteps  | 6604346  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 1638586  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6610000, episode_reward=-18.60 +/- 1.02\n",
      "Episode length: 1759.00 +/- 177.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.76e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 1639999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3296     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25128    |\n",
      "|    total_timesteps  | 6613950  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 1640987  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6620000, episode_reward=-16.20 +/- 2.04\n",
      "Episode length: 2279.40 +/- 246.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.28e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 1642499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3300     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25170    |\n",
      "|    total_timesteps  | 6624508  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00075  |\n",
      "|    n_updates        | 1643626  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6630000, episode_reward=-18.00 +/- 0.89\n",
      "Episode length: 2680.00 +/- 145.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.68e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 1644999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3304     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25214    |\n",
      "|    total_timesteps  | 6635341  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00569  |\n",
      "|    n_updates        | 1646335  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6640000, episode_reward=-17.60 +/- 0.49\n",
      "Episode length: 2075.80 +/- 128.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.08e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00525  |\n",
      "|    n_updates        | 1647499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3308     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25249    |\n",
      "|    total_timesteps  | 6643985  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 1648496  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6650000, episode_reward=-17.40 +/- 2.42\n",
      "Episode length: 2285.40 +/- 196.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.29e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 1649999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3312     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25283    |\n",
      "|    total_timesteps  | 6651965  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 1650491  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3316     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25304    |\n",
      "|    total_timesteps  | 6659073  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 1652268  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6660000, episode_reward=-17.20 +/- 1.17\n",
      "Episode length: 2029.40 +/- 170.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.03e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 1652499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3320     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25340    |\n",
      "|    total_timesteps  | 6667776  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 1654443  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6670000, episode_reward=-17.20 +/- 1.47\n",
      "Episode length: 2203.80 +/- 97.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.2e+03  |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 1654999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3324     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25374    |\n",
      "|    total_timesteps  | 6676142  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00589  |\n",
      "|    n_updates        | 1656535  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6680000, episode_reward=-17.40 +/- 1.62\n",
      "Episode length: 2083.20 +/- 148.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.08e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0068   |\n",
      "|    n_updates        | 1657499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3328     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25411    |\n",
      "|    total_timesteps  | 6685441  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00419  |\n",
      "|    n_updates        | 1658860  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6690000, episode_reward=-16.60 +/- 1.02\n",
      "Episode length: 2265.40 +/- 108.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00447  |\n",
      "|    n_updates        | 1659999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3332     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25445    |\n",
      "|    total_timesteps  | 6693570  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00689  |\n",
      "|    n_updates        | 1660892  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6700000, episode_reward=-17.00 +/- 1.10\n",
      "Episode length: 2177.40 +/- 221.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.18e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00534  |\n",
      "|    n_updates        | 1662499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3336     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25478    |\n",
      "|    total_timesteps  | 6701262  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 1662815  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3340     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25496    |\n",
      "|    total_timesteps  | 6707183  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 1664295  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6710000, episode_reward=-18.40 +/- 1.85\n",
      "Episode length: 2248.80 +/- 454.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.25e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 1664999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3344     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25532    |\n",
      "|    total_timesteps  | 6715902  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 1666475  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6720000, episode_reward=-18.20 +/- 1.72\n",
      "Episode length: 2322.40 +/- 342.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.32e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00315  |\n",
      "|    n_updates        | 1667499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3348     |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 25565    |\n",
      "|    total_timesteps  | 6723844  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 1668460  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6730000, episode_reward=-17.20 +/- 0.98\n",
      "Episode length: 2289.40 +/- 119.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.29e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 1669999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3352     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25606    |\n",
      "|    total_timesteps  | 6733938  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00466  |\n",
      "|    n_updates        | 1670984  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6740000, episode_reward=-17.60 +/- 1.02\n",
      "Episode length: 2533.20 +/- 289.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.53e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 1672499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3356     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25648    |\n",
      "|    total_timesteps  | 6744236  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 1673558  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6750000, episode_reward=-18.20 +/- 0.98\n",
      "Episode length: 2409.00 +/- 161.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.41e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 1674999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3360     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25686    |\n",
      "|    total_timesteps  | 6753501  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1675875  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6760000, episode_reward=-16.40 +/- 0.49\n",
      "Episode length: 2082.00 +/- 107.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.08e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 1677499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3364     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25720    |\n",
      "|    total_timesteps  | 6761831  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00598  |\n",
      "|    n_updates        | 1677957  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3368     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25741    |\n",
      "|    total_timesteps  | 6768673  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 1679668  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6770000, episode_reward=-16.00 +/- 1.10\n",
      "Episode length: 2132.40 +/- 155.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.13e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 1679999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3372     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25777    |\n",
      "|    total_timesteps  | 6777670  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00728  |\n",
      "|    n_updates        | 1681917  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6780000, episode_reward=-20.40 +/- 1.20\n",
      "Episode length: 1166.00 +/- 95.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.17e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000878 |\n",
      "|    n_updates        | 1682499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3376     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25806    |\n",
      "|    total_timesteps  | 6785691  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 1683922  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6790000, episode_reward=-18.60 +/- 0.80\n",
      "Episode length: 1954.40 +/- 242.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.95e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 1684999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3380     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25832    |\n",
      "|    total_timesteps  | 6791399  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 1685349  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3384     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25850    |\n",
      "|    total_timesteps  | 6797569  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 1686892  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6800000, episode_reward=-20.80 +/- 0.40\n",
      "Episode length: 1205.00 +/- 96.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.2e+03  |\n",
      "|    mean_reward      | -20.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 1687499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3388     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25877    |\n",
      "|    total_timesteps  | 6804682  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 1688670  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6810000, episode_reward=-19.40 +/- 0.49\n",
      "Episode length: 1852.80 +/- 198.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.85e+03 |\n",
      "|    mean_reward      | -19.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 1689999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3392     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25905    |\n",
      "|    total_timesteps  | 6811544  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 1690385  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3396     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25924    |\n",
      "|    total_timesteps  | 6817686  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00387  |\n",
      "|    n_updates        | 1691921  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6820000, episode_reward=-19.80 +/- 0.98\n",
      "Episode length: 1379.60 +/- 200.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.38e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00494  |\n",
      "|    n_updates        | 1692499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3400     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25956    |\n",
      "|    total_timesteps  | 6826329  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00454  |\n",
      "|    n_updates        | 1694082  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6830000, episode_reward=-18.20 +/- 0.75\n",
      "Episode length: 2409.40 +/- 136.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.41e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00267  |\n",
      "|    n_updates        | 1694999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3404     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 25997    |\n",
      "|    total_timesteps  | 6836355  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 1696588  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6840000, episode_reward=-17.80 +/- 0.75\n",
      "Episode length: 2550.80 +/- 224.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.55e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 1697499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3408     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26035    |\n",
      "|    total_timesteps  | 6845533  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 1698883  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6850000, episode_reward=-17.60 +/- 1.50\n",
      "Episode length: 2747.20 +/- 260.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.75e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 1699999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3412     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26073    |\n",
      "|    total_timesteps  | 6854048  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00378  |\n",
      "|    n_updates        | 1701011  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6860000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1088.40 +/- 40.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.09e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00334  |\n",
      "|    n_updates        | 1702499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3416     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26101    |\n",
      "|    total_timesteps  | 6861662  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 1702915  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3420     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26126    |\n",
      "|    total_timesteps  | 6869975  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0099   |\n",
      "|    n_updates        | 1704993  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6870000, episode_reward=-15.80 +/- 1.72\n",
      "Episode length: 2216.80 +/- 191.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.22e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1704999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3424     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26161    |\n",
      "|    total_timesteps  | 6878629  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 1707157  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6880000, episode_reward=-18.00 +/- 1.79\n",
      "Episode length: 2032.40 +/- 142.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.03e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00863  |\n",
      "|    n_updates        | 1707499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3428     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26201    |\n",
      "|    total_timesteps  | 6888769  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 1709692  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6890000, episode_reward=-16.80 +/- 2.04\n",
      "Episode length: 1812.00 +/- 266.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.81e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000749 |\n",
      "|    n_updates        | 1709999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3432     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26236    |\n",
      "|    total_timesteps  | 6897830  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00323  |\n",
      "|    n_updates        | 1711957  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6900000, episode_reward=-16.20 +/- 1.60\n",
      "Episode length: 1972.60 +/- 244.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.97e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1712499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3436     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26265    |\n",
      "|    total_timesteps  | 6904694  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00606  |\n",
      "|    n_updates        | 1713673  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6910000, episode_reward=-19.60 +/- 0.49\n",
      "Episode length: 1681.20 +/- 232.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.68e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00432  |\n",
      "|    n_updates        | 1714999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3440     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26296    |\n",
      "|    total_timesteps  | 6912449  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00221  |\n",
      "|    n_updates        | 1715612  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3444     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26317    |\n",
      "|    total_timesteps  | 6919607  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 1717401  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6920000, episode_reward=-16.80 +/- 2.40\n",
      "Episode length: 2156.60 +/- 325.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.16e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 1717499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3448     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26350    |\n",
      "|    total_timesteps  | 6927468  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00284  |\n",
      "|    n_updates        | 1719366  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6930000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1132.20 +/- 93.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.13e+03 |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 1719999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3452     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26382    |\n",
      "|    total_timesteps  | 6936446  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00301  |\n",
      "|    n_updates        | 1721611  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6940000, episode_reward=-17.00 +/- 3.29\n",
      "Episode length: 2514.00 +/- 555.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.51e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 1722499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3456     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26413    |\n",
      "|    total_timesteps  | 6943089  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00099  |\n",
      "|    n_updates        | 1723272  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6950000, episode_reward=-19.80 +/- 0.40\n",
      "Episode length: 1223.40 +/- 100.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.22e+03 |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 1724999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3460     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26444    |\n",
      "|    total_timesteps  | 6951849  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 1725462  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3464     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26466    |\n",
      "|    total_timesteps  | 6959197  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00373  |\n",
      "|    n_updates        | 1727299  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6960000, episode_reward=-17.20 +/- 1.17\n",
      "Episode length: 2560.00 +/- 328.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.56e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0053   |\n",
      "|    n_updates        | 1727499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3468     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26500    |\n",
      "|    total_timesteps  | 6966440  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.001    |\n",
      "|    n_updates        | 1729109  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6970000, episode_reward=-17.40 +/- 2.58\n",
      "Episode length: 2193.80 +/- 268.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.19e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00606  |\n",
      "|    n_updates        | 1729999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3472     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26530    |\n",
      "|    total_timesteps  | 6973268  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00227  |\n",
      "|    n_updates        | 1730816  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6980000, episode_reward=-17.80 +/- 1.33\n",
      "Episode length: 1987.60 +/- 119.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.99e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000954 |\n",
      "|    n_updates        | 1732499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3476     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26566    |\n",
      "|    total_timesteps  | 6982540  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00311  |\n",
      "|    n_updates        | 1733134  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6990000, episode_reward=-17.40 +/- 1.50\n",
      "Episode length: 1807.40 +/- 155.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.81e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00085  |\n",
      "|    n_updates        | 1734999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3480     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26601    |\n",
      "|    total_timesteps  | 6991726  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 1735431  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3484     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26621    |\n",
      "|    total_timesteps  | 6998183  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 1737045  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7000000, episode_reward=-20.80 +/- 0.40\n",
      "Episode length: 1077.80 +/- 30.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.08e+03 |\n",
      "|    mean_reward      | -20.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000635 |\n",
      "|    n_updates        | 1737499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3488     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26642    |\n",
      "|    total_timesteps  | 7003653  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 1738413  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7010000, episode_reward=-18.20 +/- 1.47\n",
      "Episode length: 1619.40 +/- 303.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.62e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7010000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00399  |\n",
      "|    n_updates        | 1739999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3492     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26674    |\n",
      "|    total_timesteps  | 7011998  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00314  |\n",
      "|    n_updates        | 1740499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3496     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26694    |\n",
      "|    total_timesteps  | 7018581  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 1742145  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7020000, episode_reward=-18.60 +/- 1.50\n",
      "Episode length: 1803.20 +/- 334.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.8e+03  |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7020000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 1742499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3500     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26725    |\n",
      "|    total_timesteps  | 7026374  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000641 |\n",
      "|    n_updates        | 1744093  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7030000, episode_reward=-19.60 +/- 1.50\n",
      "Episode length: 1661.40 +/- 154.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.66e+03 |\n",
      "|    mean_reward      | -19.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7030000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00993  |\n",
      "|    n_updates        | 1744999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3504     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26755    |\n",
      "|    total_timesteps  | 7033923  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 1745980  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7040000, episode_reward=-16.80 +/- 1.33\n",
      "Episode length: 1983.40 +/- 142.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.98e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7040000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 1747499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3508     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26787    |\n",
      "|    total_timesteps  | 7041857  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00457  |\n",
      "|    n_updates        | 1747964  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7050000, episode_reward=-19.20 +/- 0.75\n",
      "Episode length: 1775.60 +/- 134.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.78e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 1749999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3512     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26826    |\n",
      "|    total_timesteps  | 7051981  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 1750495  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3516     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26847    |\n",
      "|    total_timesteps  | 7059165  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 1752291  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7060000, episode_reward=-17.00 +/- 2.61\n",
      "Episode length: 1861.40 +/- 222.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.86e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7060000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 1752499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3520     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26875    |\n",
      "|    total_timesteps  | 7065896  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00348  |\n",
      "|    n_updates        | 1753973  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7070000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 1096.00 +/- 77.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -21      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7070000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0052   |\n",
      "|    n_updates        | 1754999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3524     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26905    |\n",
      "|    total_timesteps  | 7074016  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 1756003  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7080000, episode_reward=-16.00 +/- 2.19\n",
      "Episode length: 2080.40 +/- 282.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.08e+03 |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7080000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 1757499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3528     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26939    |\n",
      "|    total_timesteps  | 7082301  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1758075  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7090000, episode_reward=-18.40 +/- 1.02\n",
      "Episode length: 1635.40 +/- 119.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.64e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7090000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 1759999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3532     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26974    |\n",
      "|    total_timesteps  | 7091659  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 1760414  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3536     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 26990    |\n",
      "|    total_timesteps  | 7097180  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 1761794  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7100000, episode_reward=-20.60 +/- 0.49\n",
      "Episode length: 1097.20 +/- 28.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.1e+03  |\n",
      "|    mean_reward      | -20.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 1762499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3540     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27016    |\n",
      "|    total_timesteps  | 7104060  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00342  |\n",
      "|    n_updates        | 1763514  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7110000, episode_reward=-16.00 +/- 0.63\n",
      "Episode length: 2603.80 +/- 105.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.6e+03  |\n",
      "|    mean_reward      | -16      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7110000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00344  |\n",
      "|    n_updates        | 1764999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3544     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27049    |\n",
      "|    total_timesteps  | 7111239  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 1765309  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3548     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27074    |\n",
      "|    total_timesteps  | 7119617  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 1767404  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7120000, episode_reward=-15.80 +/- 1.60\n",
      "Episode length: 2817.20 +/- 245.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.82e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7120000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1767499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3552     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27114    |\n",
      "|    total_timesteps  | 7128896  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00428  |\n",
      "|    n_updates        | 1769723  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7130000, episode_reward=-17.40 +/- 0.80\n",
      "Episode length: 2447.40 +/- 136.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.45e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7130000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 1769999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3556     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27153    |\n",
      "|    total_timesteps  | 7138206  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000948 |\n",
      "|    n_updates        | 1772051  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7140000, episode_reward=-16.40 +/- 0.80\n",
      "Episode length: 2265.60 +/- 275.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7140000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00301  |\n",
      "|    n_updates        | 1772499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3560     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27191    |\n",
      "|    total_timesteps  | 7147797  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 1774449  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7150000, episode_reward=-15.40 +/- 1.20\n",
      "Episode length: 2247.80 +/- 195.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.25e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 1774999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3564     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27223    |\n",
      "|    total_timesteps  | 7155321  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000692 |\n",
      "|    n_updates        | 1776330  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7160000, episode_reward=-17.40 +/- 0.80\n",
      "Episode length: 1909.60 +/- 122.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.91e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7160000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 1777499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3568     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27259    |\n",
      "|    total_timesteps  | 7164286  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00391  |\n",
      "|    n_updates        | 1778571  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7170000, episode_reward=-17.00 +/- 0.89\n",
      "Episode length: 2272.80 +/- 143.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7170000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00276  |\n",
      "|    n_updates        | 1779999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3572     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27299    |\n",
      "|    total_timesteps  | 7174578  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00233  |\n",
      "|    n_updates        | 1781144  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7180000, episode_reward=-17.00 +/- 1.67\n",
      "Episode length: 2162.60 +/- 172.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.16e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7180000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 1782499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3576     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27332    |\n",
      "|    total_timesteps  | 7182253  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 1783063  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7190000, episode_reward=-20.40 +/- 0.49\n",
      "Episode length: 1151.60 +/- 50.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.15e+03 |\n",
      "|    mean_reward      | -20.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7190000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 1784999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3580     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27366    |\n",
      "|    total_timesteps  | 7192005  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000874 |\n",
      "|    n_updates        | 1785501  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7200000, episode_reward=-18.80 +/- 1.47\n",
      "Episode length: 1954.40 +/- 240.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.95e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00462  |\n",
      "|    n_updates        | 1787499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3584     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27404    |\n",
      "|    total_timesteps  | 7201862  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1787965  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7210000, episode_reward=-18.20 +/- 0.75\n",
      "Episode length: 2342.80 +/- 85.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.34e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7210000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 1789999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3588     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27445    |\n",
      "|    total_timesteps  | 7211927  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 1790481  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7220000, episode_reward=-19.00 +/- 1.10\n",
      "Episode length: 2464.20 +/- 119.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.46e+03 |\n",
      "|    mean_reward      | -19      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7220000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00521  |\n",
      "|    n_updates        | 1792499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3592     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27486    |\n",
      "|    total_timesteps  | 7221985  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00528  |\n",
      "|    n_updates        | 1792996  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7230000, episode_reward=-17.20 +/- 2.04\n",
      "Episode length: 3154.60 +/- 356.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 3.15e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7230000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00628  |\n",
      "|    n_updates        | 1794999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3596     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27537    |\n",
      "|    total_timesteps  | 7234575  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 1796143  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7240000, episode_reward=-14.20 +/- 3.82\n",
      "Episode length: 2728.80 +/- 483.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.73e+03 |\n",
      "|    mean_reward      | -14.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7240000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00997  |\n",
      "|    n_updates        | 1797499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3600     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27582    |\n",
      "|    total_timesteps  | 7245581  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00748  |\n",
      "|    n_updates        | 1798895  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7250000, episode_reward=-17.60 +/- 1.50\n",
      "Episode length: 1952.60 +/- 266.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.95e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 1799999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3604     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27615    |\n",
      "|    total_timesteps  | 7253948  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 1800986  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7260000, episode_reward=-17.80 +/- 0.75\n",
      "Episode length: 1908.60 +/- 148.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.91e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7260000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00598  |\n",
      "|    n_updates        | 1802499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3608     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27656    |\n",
      "|    total_timesteps  | 7264568  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 1803641  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7270000, episode_reward=-17.40 +/- 2.15\n",
      "Episode length: 2257.60 +/- 310.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.26e+03 |\n",
      "|    mean_reward      | -17.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7270000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0085   |\n",
      "|    n_updates        | 1804999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3612     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27696    |\n",
      "|    total_timesteps  | 7274575  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00259  |\n",
      "|    n_updates        | 1806143  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7280000, episode_reward=-11.40 +/- 1.02\n",
      "Episode length: 2494.00 +/- 159.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.49e+03 |\n",
      "|    mean_reward      | -11.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7280000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00732  |\n",
      "|    n_updates        | 1807499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3616     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27738    |\n",
      "|    total_timesteps  | 7284965  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0034   |\n",
      "|    n_updates        | 1808741  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7290000, episode_reward=-13.20 +/- 1.33\n",
      "Episode length: 2502.40 +/- 199.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.5e+03  |\n",
      "|    mean_reward      | -13.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7290000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00097  |\n",
      "|    n_updates        | 1809999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.29e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3620     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27777    |\n",
      "|    total_timesteps  | 7294604  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 1811150  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7300000, episode_reward=-15.60 +/- 2.15\n",
      "Episode length: 2366.60 +/- 238.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.37e+03 |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 1812499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.31e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3624     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27818    |\n",
      "|    total_timesteps  | 7304747  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00427  |\n",
      "|    n_updates        | 1813686  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7310000, episode_reward=-14.60 +/- 1.85\n",
      "Episode length: 2821.60 +/- 289.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.82e+03 |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7310000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 1814999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.32e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3628     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27860    |\n",
      "|    total_timesteps  | 7314720  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 1816179  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7320000, episode_reward=-18.00 +/- 1.79\n",
      "Episode length: 2144.00 +/- 258.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7320000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00463  |\n",
      "|    n_updates        | 1817499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.32e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3632     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27896    |\n",
      "|    total_timesteps  | 7323596  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000679 |\n",
      "|    n_updates        | 1818398  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7330000, episode_reward=-15.80 +/- 2.23\n",
      "Episode length: 2270.60 +/- 224.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7330000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 1819999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3636     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27939    |\n",
      "|    total_timesteps  | 7334662  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00317  |\n",
      "|    n_updates        | 1821165  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7340000, episode_reward=-18.40 +/- 1.02\n",
      "Episode length: 3105.80 +/- 601.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 3.11e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7340000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 1822499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.44e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3640     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 27993    |\n",
      "|    total_timesteps  | 7348264  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0068   |\n",
      "|    n_updates        | 1824565  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7350000, episode_reward=-16.20 +/- 1.72\n",
      "Episode length: 2917.80 +/- 250.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.92e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0047   |\n",
      "|    n_updates        | 1824999  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7360000, episode_reward=-17.20 +/- 0.75\n",
      "Episode length: 2896.60 +/- 685.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.9e+03  |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7360000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 1827499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.51e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3644     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28060    |\n",
      "|    total_timesteps  | 7362289  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 1828072  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7370000, episode_reward=-15.80 +/- 1.33\n",
      "Episode length: 2645.40 +/- 228.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.65e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7370000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 1829999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.53e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3648     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28103    |\n",
      "|    total_timesteps  | 7372882  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 1830720  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7380000, episode_reward=-17.60 +/- 1.02\n",
      "Episode length: 2502.40 +/- 137.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.5e+03  |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7380000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00323  |\n",
      "|    n_updates        | 1832499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.56e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3652     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28150    |\n",
      "|    total_timesteps  | 7385019  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00889  |\n",
      "|    n_updates        | 1833754  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7390000, episode_reward=-15.00 +/- 1.67\n",
      "Episode length: 2435.20 +/- 131.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.44e+03 |\n",
      "|    mean_reward      | -15      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7390000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00493  |\n",
      "|    n_updates        | 1834999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.59e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3656     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28197    |\n",
      "|    total_timesteps  | 7397076  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0029   |\n",
      "|    n_updates        | 1836768  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7400000, episode_reward=-15.60 +/- 0.49\n",
      "Episode length: 2294.40 +/- 122.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.29e+03 |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 1837499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.6e+03  |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3660     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28238    |\n",
      "|    total_timesteps  | 7407365  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 1839341  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7410000, episode_reward=-16.60 +/- 0.80\n",
      "Episode length: 2635.40 +/- 236.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.64e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7410000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00572  |\n",
      "|    n_updates        | 1839999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.63e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3664     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28281    |\n",
      "|    total_timesteps  | 7418049  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00539  |\n",
      "|    n_updates        | 1842012  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7420000, episode_reward=-17.20 +/- 1.60\n",
      "Episode length: 2493.60 +/- 410.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.49e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7420000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 1842499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.65e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3668     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28325    |\n",
      "|    total_timesteps  | 7428911  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00643  |\n",
      "|    n_updates        | 1844727  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7430000, episode_reward=-18.80 +/- 0.40\n",
      "Episode length: 2655.40 +/- 283.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.66e+03 |\n",
      "|    mean_reward      | -18.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7430000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 1844999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.62e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3672     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28360    |\n",
      "|    total_timesteps  | 7436963  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00255  |\n",
      "|    n_updates        | 1846740  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7440000, episode_reward=-16.40 +/- 3.14\n",
      "Episode length: 2426.20 +/- 317.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.43e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7440000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 1847499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.64e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3676     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28400    |\n",
      "|    total_timesteps  | 7446651  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00743  |\n",
      "|    n_updates        | 1849162  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7450000, episode_reward=-18.00 +/- 1.67\n",
      "Episode length: 3187.60 +/- 395.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 3.19e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00515  |\n",
      "|    n_updates        | 1849999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.66e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3680     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28448    |\n",
      "|    total_timesteps  | 7458094  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00394  |\n",
      "|    n_updates        | 1852023  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7460000, episode_reward=-17.80 +/- 1.72\n",
      "Episode length: 2246.00 +/- 443.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.25e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7460000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 1852499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.67e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3684     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28490    |\n",
      "|    total_timesteps  | 7468568  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 1854641  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7470000, episode_reward=-16.20 +/- 1.17\n",
      "Episode length: 2425.20 +/- 443.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.43e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7470000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00372  |\n",
      "|    n_updates        | 1854999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.67e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3688     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28536    |\n",
      "|    total_timesteps  | 7478938  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00391  |\n",
      "|    n_updates        | 1857234  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7480000, episode_reward=-16.40 +/- 2.58\n",
      "Episode length: 2429.80 +/- 358.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.43e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7480000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 1857499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.66e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3692     |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 28575    |\n",
      "|    total_timesteps  | 7487873  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 1859468  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7490000, episode_reward=-13.60 +/- 1.50\n",
      "Episode length: 2479.40 +/- 200.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.48e+03 |\n",
      "|    mean_reward      | -13.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7490000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 1859999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.62e+03 |\n",
      "|    ep_rew_mean      | -19      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3696     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 28613    |\n",
      "|    total_timesteps  | 7496479  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00593  |\n",
      "|    n_updates        | 1861619  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7500000, episode_reward=-16.80 +/- 1.47\n",
      "Episode length: 2398.00 +/- 208.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.4e+03  |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 1862499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.6e+03  |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3700     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 28654    |\n",
      "|    total_timesteps  | 7505732  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 1863932  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7510000, episode_reward=-18.60 +/- 1.85\n",
      "Episode length: 2009.20 +/- 238.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.01e+03 |\n",
      "|    mean_reward      | -18.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7510000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00268  |\n",
      "|    n_updates        | 1864999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.6e+03  |\n",
      "|    ep_rew_mean      | -19.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3704     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 28689    |\n",
      "|    total_timesteps  | 7513948  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 1865986  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7520000, episode_reward=-17.00 +/- 1.41\n",
      "Episode length: 2449.60 +/- 240.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.45e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7520000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 1867499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.6e+03  |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3708     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 28732    |\n",
      "|    total_timesteps  | 7524080  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 1868519  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7530000, episode_reward=-15.40 +/- 1.20\n",
      "Episode length: 2423.00 +/- 213.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.42e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7530000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 1869999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.6e+03  |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3712     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 28776    |\n",
      "|    total_timesteps  | 7534079  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0036   |\n",
      "|    n_updates        | 1871019  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7540000, episode_reward=-17.20 +/- 2.23\n",
      "Episode length: 2273.80 +/- 327.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7540000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 1872499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.59e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3716     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 28816    |\n",
      "|    total_timesteps  | 7543815  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 1873453  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7550000, episode_reward=-16.40 +/- 2.58\n",
      "Episode length: 2587.40 +/- 413.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.59e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 1874999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.59e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3720     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 28859    |\n",
      "|    total_timesteps  | 7553697  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000731 |\n",
      "|    n_updates        | 1875924  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7560000, episode_reward=-17.80 +/- 1.60\n",
      "Episode length: 1995.40 +/- 138.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2e+03    |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7560000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 1877499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.59e+03 |\n",
      "|    ep_rew_mean      | -19.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3724     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 28899    |\n",
      "|    total_timesteps  | 7564026  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 1878506  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7570000, episode_reward=-16.80 +/- 1.60\n",
      "Episode length: 2137.40 +/- 51.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.14e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7570000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000978 |\n",
      "|    n_updates        | 1879999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.6e+03  |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3728     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 28940    |\n",
      "|    total_timesteps  | 7574630  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00791  |\n",
      "|    n_updates        | 1881157  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7580000, episode_reward=-18.20 +/- 1.17\n",
      "Episode length: 1840.60 +/- 106.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.84e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7580000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 1882499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.6e+03  |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3732     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 28975    |\n",
      "|    total_timesteps  | 7583608  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 1883401  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7590000, episode_reward=-16.80 +/- 0.75\n",
      "Episode length: 2279.00 +/- 43.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.28e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7590000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 1884999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.58e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3736     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29012    |\n",
      "|    total_timesteps  | 7592670  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00892  |\n",
      "|    n_updates        | 1885667  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7600000, episode_reward=-19.20 +/- 1.17\n",
      "Episode length: 2170.60 +/- 171.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.17e+03 |\n",
      "|    mean_reward      | -19.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 1887499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.57e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3740     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29061    |\n",
      "|    total_timesteps  | 7605126  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 1888781  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7610000, episode_reward=-16.80 +/- 1.72\n",
      "Episode length: 2870.80 +/- 243.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.87e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7610000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00365  |\n",
      "|    n_updates        | 1889999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.55e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3744     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29115    |\n",
      "|    total_timesteps  | 7617628  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 1891906  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7620000, episode_reward=-18.40 +/- 1.36\n",
      "Episode length: 2736.80 +/- 306.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.74e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7620000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 1892499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.57e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3748     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29166    |\n",
      "|    total_timesteps  | 7629591  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 1894897  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7630000, episode_reward=-17.80 +/- 2.04\n",
      "Episode length: 2793.40 +/- 272.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.79e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7630000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00487  |\n",
      "|    n_updates        | 1894999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7640000, episode_reward=-17.20 +/- 0.98\n",
      "Episode length: 2547.60 +/- 248.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.55e+03 |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7640000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 1897499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.57e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3752     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29230    |\n",
      "|    total_timesteps  | 7642214  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 1898053  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7650000, episode_reward=-16.20 +/- 2.56\n",
      "Episode length: 2499.40 +/- 225.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.5e+03  |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00733  |\n",
      "|    n_updates        | 1899999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.58e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3756     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29284    |\n",
      "|    total_timesteps  | 7655476  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.001    |\n",
      "|    n_updates        | 1901368  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7660000, episode_reward=-15.00 +/- 2.10\n",
      "Episode length: 2330.80 +/- 174.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.33e+03 |\n",
      "|    mean_reward      | -15      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7660000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 1902499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.59e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3760     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29327    |\n",
      "|    total_timesteps  | 7665895  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00843  |\n",
      "|    n_updates        | 1903973  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7670000, episode_reward=-16.40 +/- 2.80\n",
      "Episode length: 2782.20 +/- 425.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.78e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7670000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00312  |\n",
      "|    n_updates        | 1904999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.6e+03  |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3764     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29379    |\n",
      "|    total_timesteps  | 7678228  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 1907056  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7680000, episode_reward=-15.80 +/- 1.72\n",
      "Episode length: 2777.40 +/- 189.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.78e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7680000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 1907499  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7690000, episode_reward=-16.80 +/- 1.94\n",
      "Episode length: 2987.20 +/- 421.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.99e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7690000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00388  |\n",
      "|    n_updates        | 1909999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.63e+03 |\n",
      "|    ep_rew_mean      | -20.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3768     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29447    |\n",
      "|    total_timesteps  | 7692239  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00071  |\n",
      "|    n_updates        | 1910559  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7700000, episode_reward=-14.80 +/- 1.72\n",
      "Episode length: 2989.00 +/- 463.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.99e+03 |\n",
      "|    mean_reward      | -14.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 1912499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.66e+03 |\n",
      "|    ep_rew_mean      | -20.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3772     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29491    |\n",
      "|    total_timesteps  | 7702587  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 1913146  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7710000, episode_reward=-15.80 +/- 1.94\n",
      "Episode length: 2360.40 +/- 266.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.36e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7710000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 1914999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.68e+03 |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3776     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29538    |\n",
      "|    total_timesteps  | 7714790  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.002    |\n",
      "|    n_updates        | 1916197  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7720000, episode_reward=-12.80 +/- 1.60\n",
      "Episode length: 2989.00 +/- 169.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.99e+03 |\n",
      "|    mean_reward      | -12.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7720000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 1917499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.67e+03 |\n",
      "|    ep_rew_mean      | -20      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3780     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29583    |\n",
      "|    total_timesteps  | 7725516  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0031   |\n",
      "|    n_updates        | 1918878  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7730000, episode_reward=-17.60 +/- 1.62\n",
      "Episode length: 2252.40 +/- 204.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.25e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7730000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0021   |\n",
      "|    n_updates        | 1919999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.66e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3784     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29620    |\n",
      "|    total_timesteps  | 7734766  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 1921191  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7740000, episode_reward=-16.60 +/- 1.50\n",
      "Episode length: 2180.20 +/- 141.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.18e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7740000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 1922499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.63e+03 |\n",
      "|    ep_rew_mean      | -19.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3788     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29651    |\n",
      "|    total_timesteps  | 7741881  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00293  |\n",
      "|    n_updates        | 1922970  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7750000, episode_reward=-15.60 +/- 2.58\n",
      "Episode length: 3050.60 +/- 414.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 3.05e+03 |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 1924999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.67e+03 |\n",
      "|    ep_rew_mean      | -19.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3792     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29704    |\n",
      "|    total_timesteps  | 7755105  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00227  |\n",
      "|    n_updates        | 1926276  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7760000, episode_reward=-17.00 +/- 1.79\n",
      "Episode length: 2434.80 +/- 377.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.43e+03 |\n",
      "|    mean_reward      | -17      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7760000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000559 |\n",
      "|    n_updates        | 1927499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.68e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3796     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29744    |\n",
      "|    total_timesteps  | 7764769  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 1928692  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7770000, episode_reward=-16.20 +/- 3.06\n",
      "Episode length: 3126.00 +/- 342.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 3.13e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7770000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 1929999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.68e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3800     |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 29785    |\n",
      "|    total_timesteps  | 7773994  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00255  |\n",
      "|    n_updates        | 1930998  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7780000, episode_reward=-17.80 +/- 2.48\n",
      "Episode length: 2425.20 +/- 416.59\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.43e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7780000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000855 |\n",
      "|    n_updates        | 1932499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.71e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3804     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 29828    |\n",
      "|    total_timesteps  | 7784969  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 1933742  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7790000, episode_reward=-17.80 +/- 2.40\n",
      "Episode length: 2661.60 +/- 531.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.66e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7790000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000722 |\n",
      "|    n_updates        | 1934999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.73e+03 |\n",
      "|    ep_rew_mean      | -19.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3808     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 29875    |\n",
      "|    total_timesteps  | 7796845  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00555  |\n",
      "|    n_updates        | 1936711  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7800000, episode_reward=-16.80 +/- 1.72\n",
      "Episode length: 2854.00 +/- 564.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.85e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00471  |\n",
      "|    n_updates        | 1937499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.74e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3812     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 29922    |\n",
      "|    total_timesteps  | 7808153  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 1939538  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7810000, episode_reward=-18.40 +/- 1.36\n",
      "Episode length: 2415.20 +/- 321.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.42e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7810000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 1939999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.74e+03 |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3816     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 29962    |\n",
      "|    total_timesteps  | 7818080  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 1942019  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7820000, episode_reward=-17.80 +/- 0.75\n",
      "Episode length: 2172.80 +/- 191.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.17e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7820000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 1942499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.73e+03 |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3820     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 29999    |\n",
      "|    total_timesteps  | 7827083  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000536 |\n",
      "|    n_updates        | 1944270  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7830000, episode_reward=-16.20 +/- 1.47\n",
      "Episode length: 2459.20 +/- 428.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.46e+03 |\n",
      "|    mean_reward      | -16.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7830000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 1944999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.73e+03 |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3824     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30038    |\n",
      "|    total_timesteps  | 7836618  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 1946654  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7840000, episode_reward=-15.60 +/- 2.58\n",
      "Episode length: 2597.20 +/- 527.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.6e+03  |\n",
      "|    mean_reward      | -15.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7840000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 1947499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.74e+03 |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3828     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30084    |\n",
      "|    total_timesteps  | 7848156  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00707  |\n",
      "|    n_updates        | 1949538  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7850000, episode_reward=-16.60 +/- 1.74\n",
      "Episode length: 2660.40 +/- 264.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.66e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00699  |\n",
      "|    n_updates        | 1949999  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7860000, episode_reward=-17.80 +/- 2.14\n",
      "Episode length: 2475.40 +/- 376.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.48e+03 |\n",
      "|    mean_reward      | -17.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7860000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 1952499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.79e+03 |\n",
      "|    ep_rew_mean      | -18.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3832     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30149    |\n",
      "|    total_timesteps  | 7862609  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00455  |\n",
      "|    n_updates        | 1953152  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7870000, episode_reward=-13.20 +/- 2.32\n",
      "Episode length: 2854.00 +/- 359.13\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.85e+03 |\n",
      "|    mean_reward      | -13.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7870000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00473  |\n",
      "|    n_updates        | 1954999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.83e+03 |\n",
      "|    ep_rew_mean      | -18.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3836     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30200    |\n",
      "|    total_timesteps  | 7875405  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00593  |\n",
      "|    n_updates        | 1956351  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7880000, episode_reward=-15.80 +/- 2.14\n",
      "Episode length: 2358.00 +/- 327.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.36e+03 |\n",
      "|    mean_reward      | -15.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7880000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0068   |\n",
      "|    n_updates        | 1957499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.79e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3840     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30237    |\n",
      "|    total_timesteps  | 7884422  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 1958605  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=7890000, episode_reward=-16.80 +/- 1.60\n",
      "Episode length: 2661.00 +/- 293.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.66e+03 |\n",
      "|    mean_reward      | -16.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7890000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 1959999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.77e+03 |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3844     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30281    |\n",
      "|    total_timesteps  | 7894949  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 1961237  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7900000, episode_reward=-15.20 +/- 4.79\n",
      "Episode length: 3333.60 +/- 546.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 3.33e+03 |\n",
      "|    mean_reward      | -15.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00292  |\n",
      "|    n_updates        | 1962499  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7910000, episode_reward=-14.20 +/- 1.47\n",
      "Episode length: 3128.20 +/- 223.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 3.13e+03 |\n",
      "|    mean_reward      | -14.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7910000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 1964999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.83e+03 |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3848     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30363    |\n",
      "|    total_timesteps  | 7913068  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 1965766  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7920000, episode_reward=-15.40 +/- 2.42\n",
      "Episode length: 2919.60 +/- 310.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.92e+03 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7920000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00342  |\n",
      "|    n_updates        | 1967499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.83e+03 |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3852     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30414    |\n",
      "|    total_timesteps  | 7925574  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000887 |\n",
      "|    n_updates        | 1968893  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7930000, episode_reward=-18.00 +/- 0.00\n",
      "Episode length: 2670.80 +/- 246.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.67e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7930000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 1969999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.82e+03 |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3856     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30463    |\n",
      "|    total_timesteps  | 7937274  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00353  |\n",
      "|    n_updates        | 1971818  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7940000, episode_reward=-18.00 +/- 2.45\n",
      "Episode length: 2559.80 +/- 191.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.56e+03 |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7940000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000754 |\n",
      "|    n_updates        | 1972499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.82e+03 |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3860     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30509    |\n",
      "|    total_timesteps  | 7947985  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 1974496  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7950000, episode_reward=-16.40 +/- 1.74\n",
      "Episode length: 2558.60 +/- 160.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.56e+03 |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00233  |\n",
      "|    n_updates        | 1974999  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7960000, episode_reward=-18.20 +/- 1.83\n",
      "Episode length: 2082.20 +/- 227.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.08e+03 |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7960000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00228  |\n",
      "|    n_updates        | 1977499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.84e+03 |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3864     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30575    |\n",
      "|    total_timesteps  | 7962108  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00399  |\n",
      "|    n_updates        | 1978026  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7970000, episode_reward=-17.60 +/- 2.33\n",
      "Episode length: 1947.60 +/- 314.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.95e+03 |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7970000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 1979999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.79e+03 |\n",
      "|    ep_rew_mean      | -18.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3868     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30614    |\n",
      "|    total_timesteps  | 7971647  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000774 |\n",
      "|    n_updates        | 1980411  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.77e+03 |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3872     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30640    |\n",
      "|    total_timesteps  | 7979795  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 1982448  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7980000, episode_reward=-16.60 +/- 2.06\n",
      "Episode length: 2062.00 +/- 380.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.06e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7980000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.009    |\n",
      "|    n_updates        | 1982499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.74e+03 |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3876     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30677    |\n",
      "|    total_timesteps  | 7988344  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 1984585  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7990000, episode_reward=-18.40 +/- 1.36\n",
      "Episode length: 2415.00 +/- 33.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.42e+03 |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7990000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 1984999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.74e+03 |\n",
      "|    ep_rew_mean      | -18.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3880     |\n",
      "|    fps              | 260      |\n",
      "|    time_elapsed     | 30723    |\n",
      "|    total_timesteps  | 7999140  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00219  |\n",
      "|    n_updates        | 1987284  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8000000, episode_reward=-16.60 +/- 2.42\n",
      "Episode length: 2164.20 +/- 411.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.16e+03 |\n",
      "|    mean_reward      | -16.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000348 |\n",
      "|    n_updates        | 1987499  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f3f5cedfe80>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=8000000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(DQN_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:86\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[1;32m     84\u001b[0m episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((env\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (episode_counts \u001b[38;5;241m<\u001b[39m episode_count_targets)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m---> 86\u001b[0m     actions, states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisode_starts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n\u001b[1;32m     88\u001b[0m     current_rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rewards\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/dqn/dqn.py:248\u001b[0m, in \u001b[0;36mDQN.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    246\u001b[0m         action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample())\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     action, state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action, state\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/common/policies.py:335\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# TODO (GH/1): add support for RNN policies\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# if state is None:\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m#     state = self.initial_state\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# if episode_start is None:\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m#     episode_start = [False for _ in range(self.n_envs)]\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# Switch to eval mode (this affects batch norm / dropout)\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_training_mode(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 335\u001b[0m observation, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    338\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(observation, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/common/policies.py:254\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# Add batch dimension if needed\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     observation \u001b[38;5;241m=\u001b[39m observation\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 254\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[43mobs_as_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation, vectorized_env\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/common/utils.py:451\u001b[0m, in \u001b[0;36mobs_as_tensor\u001b[0;34m(obs, device)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03mMoves the observation to the given device.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m:return: PyTorch tensor of the observation on a desired device.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: th\u001b[38;5;241m.\u001b[39mas_tensor(_obs)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m (key, _obs) \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Changing Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, policy_kwargs={'net_arch': net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Using an Alternate Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 93.9 GiB for an array with shape (1000000, 1, 3, 210, 160) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/dqn/dqn.py:138\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, tensorboard_log, create_eval_env, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/dqn/dqn.py:141\u001b[0m, in \u001b[0;36mDQN._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_aliases()\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_schedule \u001b[38;5;241m=\u001b[39m get_linear_fn(\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_initial_eps,\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_final_eps,\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_fraction,\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:205\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;241m=\u001b[39m HerReplayBuffer(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer_kwargs,\n\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_class(  \u001b[38;5;66;03m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space,\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_schedule,\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_kwargs,  \u001b[38;5;66;03m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[1;32m    220\u001b[0m )\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:201\u001b[0m, in \u001b[0;36mReplayBuffer.__init__\u001b[0;34m(self, buffer_size, observation_space, action_space, device, n_envs, optimize_memory_usage, handle_timeout_termination)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReplayBuffer does not support optimize_memory_usage = True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand handle_timeout_termination = True simultaneously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_memory_usage \u001b[38;5;241m=\u001b[39m optimize_memory_usage\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_envs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimize_memory_usage:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# `observations` contains also the next observation\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_observations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 93.9 GiB for an array with shape (1000000, 1, 3, 210, 160) and data type uint8"
     ]
    }
   ],
   "source": [
    "model = DQN('MlpPolicy', env, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_path = os.path.join('Training', 'Saved Models', 'DQN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(dqn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(dqn_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
